{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Giv45HDjRw3j"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjtMVPuWUICf"
      },
      "outputs": [],
      "source": [
        "x = np.array([1, 2, 3, 4, 5, 6])\n",
        "x = x.reshape(2, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8fjk9I8UT-Z",
        "outputId": "2ef677e0-4e68-410b-fb45-34d2453c6667"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te0-fhsBUUR3"
      },
      "outputs": [],
      "source": [
        "y1 = x.reshape(3, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f893m_OkUZwI",
        "outputId": "aaa121b9-33fc-44e0-c3e8-9f7b44b5fea5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4],\n",
              "       [5, 6]])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92_X9qOOUaKg"
      },
      "outputs": [],
      "source": [
        "data = np.array([[0,0],[1,0],[0, 1],[1, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0qLMbnufN9J"
      },
      "outputs": [],
      "source": [
        "And = np.array([[0],[0],[0],[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jj6UEMcfxkT"
      },
      "outputs": [],
      "source": [
        "W = np.array([0.5, 0.5]).reshape(2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiEtMaTko0x6",
        "outputId": "264b6d87-4ea8-4f67-8edf-d22e02286b98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5],\n",
              "       [0.5]])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DXCo1yLf7j1",
        "outputId": "73a4fa4f-1db6-45d1-ac89-700e3a62cf00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(np.dot(data, W) < 0.6, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJn6SCZQAYMQ",
        "outputId": "bfd20585-237c-49e1-b04f-e76158535b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.10526315789473684\n",
            "0.05263157894736842 0.05263157894736842 0.15789473684210525\n",
            "0.05263157894736842 0.05263157894736842 0.21052631578947367\n",
            "0.05263157894736842 0.05263157894736842 0.2631578947368421\n",
            "0.05263157894736842 0.05263157894736842 0.3157894736842105\n",
            "0.05263157894736842 0.05263157894736842 0.3684210526315789\n",
            "0.05263157894736842 0.05263157894736842 0.42105263157894735\n",
            "0.05263157894736842 0.05263157894736842 0.47368421052631576\n",
            "0.05263157894736842 0.05263157894736842 0.5263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.5789473684210527\n",
            "0.05263157894736842 0.05263157894736842 0.631578947368421\n",
            "0.05263157894736842 0.05263157894736842 0.6842105263157894\n",
            "0.05263157894736842 0.05263157894736842 0.7894736842105263\n",
            "0.05263157894736842 0.05263157894736842 0.8421052631578947\n",
            "0.05263157894736842 0.05263157894736842 0.894736842105263\n",
            "0.05263157894736842 0.05263157894736842 1.0\n",
            "0.10526315789473684 0.10526315789473684 0.15789473684210525\n",
            "0.10526315789473684 0.10526315789473684 0.15789473684210525\n",
            "0.10526315789473684 0.10526315789473684 0.21052631578947367\n",
            "0.10526315789473684 0.10526315789473684 0.2631578947368421\n",
            "0.10526315789473684 0.10526315789473684 0.3157894736842105\n",
            "0.10526315789473684 0.10526315789473684 0.3684210526315789\n",
            "0.10526315789473684 0.10526315789473684 0.42105263157894735\n",
            "0.10526315789473684 0.10526315789473684 0.47368421052631576\n",
            "0.10526315789473684 0.10526315789473684 0.5263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.5789473684210527\n",
            "0.10526315789473684 0.10526315789473684 0.631578947368421\n",
            "0.10526315789473684 0.10526315789473684 0.6842105263157894\n",
            "0.10526315789473684 0.10526315789473684 0.7368421052631579\n",
            "0.10526315789473684 0.10526315789473684 0.7894736842105263\n",
            "0.10526315789473684 0.10526315789473684 0.8421052631578947\n",
            "0.10526315789473684 0.10526315789473684 0.894736842105263\n",
            "0.10526315789473684 0.10526315789473684 0.9473684210526315\n",
            "0.10526315789473684 0.10526315789473684 1.0\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.2631578947368421\n",
            "0.15789473684210525 0.15789473684210525 0.3157894736842105\n",
            "0.15789473684210525 0.15789473684210525 0.3684210526315789\n",
            "0.15789473684210525 0.15789473684210525 0.42105263157894735\n",
            "0.15789473684210525 0.15789473684210525 0.47368421052631576\n",
            "0.15789473684210525 0.15789473684210525 0.5263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.5789473684210527\n",
            "0.15789473684210525 0.15789473684210525 0.631578947368421\n",
            "0.15789473684210525 0.15789473684210525 0.6842105263157894\n",
            "0.15789473684210525 0.15789473684210525 0.7368421052631579\n",
            "0.15789473684210525 0.15789473684210525 0.7894736842105263\n",
            "0.15789473684210525 0.15789473684210525 0.8421052631578947\n",
            "0.15789473684210525 0.15789473684210525 0.894736842105263\n",
            "0.15789473684210525 0.15789473684210525 0.9473684210526315\n",
            "0.15789473684210525 0.15789473684210525 1.0\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.3157894736842105\n",
            "0.21052631578947367 0.21052631578947367 0.3684210526315789\n",
            "0.21052631578947367 0.21052631578947367 0.42105263157894735\n",
            "0.21052631578947367 0.21052631578947367 0.47368421052631576\n",
            "0.21052631578947367 0.21052631578947367 0.5263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.5789473684210527\n",
            "0.21052631578947367 0.21052631578947367 0.631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.6842105263157894\n",
            "0.21052631578947367 0.21052631578947367 0.7368421052631579\n",
            "0.21052631578947367 0.21052631578947367 0.7894736842105263\n",
            "0.21052631578947367 0.21052631578947367 0.8421052631578947\n",
            "0.21052631578947367 0.21052631578947367 0.894736842105263\n",
            "0.21052631578947367 0.21052631578947367 0.9473684210526315\n",
            "0.21052631578947367 0.21052631578947367 1.0\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3684210526315789\n",
            "0.2631578947368421 0.2631578947368421 0.42105263157894735\n",
            "0.2631578947368421 0.2631578947368421 0.47368421052631576\n",
            "0.2631578947368421 0.2631578947368421 0.5263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.5789473684210527\n",
            "0.2631578947368421 0.2631578947368421 0.631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.6842105263157894\n",
            "0.2631578947368421 0.2631578947368421 0.7368421052631579\n",
            "0.2631578947368421 0.2631578947368421 0.7894736842105263\n",
            "0.2631578947368421 0.2631578947368421 0.8421052631578947\n",
            "0.2631578947368421 0.2631578947368421 0.894736842105263\n",
            "0.2631578947368421 0.2631578947368421 0.9473684210526315\n",
            "0.2631578947368421 0.2631578947368421 1.0\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.42105263157894735\n",
            "0.3157894736842105 0.3157894736842105 0.47368421052631576\n",
            "0.3157894736842105 0.3157894736842105 0.5263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.5789473684210527\n",
            "0.3157894736842105 0.3157894736842105 0.631578947368421\n",
            "0.3157894736842105 0.3157894736842105 0.6842105263157894\n",
            "0.3157894736842105 0.3157894736842105 0.7368421052631579\n",
            "0.3157894736842105 0.3157894736842105 0.7894736842105263\n",
            "0.3157894736842105 0.3157894736842105 0.8421052631578947\n",
            "0.3157894736842105 0.3157894736842105 0.894736842105263\n",
            "0.3157894736842105 0.3157894736842105 0.9473684210526315\n",
            "0.3157894736842105 0.3157894736842105 1.0\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.47368421052631576\n",
            "0.3684210526315789 0.3684210526315789 0.5263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.5789473684210527\n",
            "0.3684210526315789 0.3684210526315789 0.631578947368421\n",
            "0.3684210526315789 0.3684210526315789 0.6842105263157894\n",
            "0.3684210526315789 0.3684210526315789 0.7368421052631579\n",
            "0.3684210526315789 0.3684210526315789 0.7894736842105263\n",
            "0.3684210526315789 0.3684210526315789 0.8421052631578947\n",
            "0.3684210526315789 0.3684210526315789 0.894736842105263\n",
            "0.3684210526315789 0.3684210526315789 0.9473684210526315\n",
            "0.3684210526315789 0.3684210526315789 1.0\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.5263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.5789473684210527\n",
            "0.42105263157894735 0.42105263157894735 0.631578947368421\n",
            "0.42105263157894735 0.42105263157894735 0.6842105263157894\n",
            "0.42105263157894735 0.42105263157894735 0.7368421052631579\n",
            "0.42105263157894735 0.42105263157894735 0.7894736842105263\n",
            "0.42105263157894735 0.42105263157894735 0.8421052631578947\n",
            "0.42105263157894735 0.42105263157894735 0.894736842105263\n",
            "0.42105263157894735 0.42105263157894735 0.9473684210526315\n",
            "0.42105263157894735 0.42105263157894735 1.0\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5789473684210527\n",
            "0.47368421052631576 0.47368421052631576 0.631578947368421\n",
            "0.47368421052631576 0.47368421052631576 0.6842105263157894\n",
            "0.47368421052631576 0.47368421052631576 0.7368421052631579\n",
            "0.47368421052631576 0.47368421052631576 0.7894736842105263\n",
            "0.47368421052631576 0.47368421052631576 0.8421052631578947\n",
            "0.47368421052631576 0.47368421052631576 0.894736842105263\n",
            "0.47368421052631576 0.47368421052631576 0.9473684210526315\n",
            "0.47368421052631576 0.47368421052631576 1.0\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.631578947368421\n",
            "0.5263157894736842 0.5263157894736842 0.6842105263157894\n",
            "0.5263157894736842 0.5263157894736842 0.7368421052631579\n",
            "0.5263157894736842 0.5263157894736842 0.7894736842105263\n",
            "0.5263157894736842 0.5263157894736842 0.8421052631578947\n",
            "0.5263157894736842 0.5263157894736842 0.894736842105263\n",
            "0.5263157894736842 0.5263157894736842 0.9473684210526315\n",
            "0.5263157894736842 0.5263157894736842 1.0\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.6842105263157894\n",
            "0.5789473684210527 0.5789473684210527 0.7368421052631579\n",
            "0.5789473684210527 0.5789473684210527 0.7894736842105263\n",
            "0.5789473684210527 0.5789473684210527 0.8421052631578947\n",
            "0.5789473684210527 0.5789473684210527 0.894736842105263\n",
            "0.5789473684210527 0.5789473684210527 0.9473684210526315\n",
            "0.5789473684210527 0.5789473684210527 1.0\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.7368421052631579\n",
            "0.631578947368421 0.631578947368421 0.7894736842105263\n",
            "0.631578947368421 0.631578947368421 0.8421052631578947\n",
            "0.631578947368421 0.631578947368421 0.894736842105263\n",
            "0.631578947368421 0.631578947368421 0.9473684210526315\n",
            "0.631578947368421 0.631578947368421 1.0\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7894736842105263\n",
            "0.6842105263157894 0.6842105263157894 0.8421052631578947\n",
            "0.6842105263157894 0.6842105263157894 0.894736842105263\n",
            "0.6842105263157894 0.6842105263157894 0.9473684210526315\n",
            "0.6842105263157894 0.6842105263157894 1.0\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.8421052631578947\n",
            "0.7368421052631579 0.7368421052631579 0.894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.9473684210526315\n",
            "0.7368421052631579 0.7368421052631579 1.0\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.9473684210526315\n",
            "0.7894736842105263 0.7894736842105263 1.0\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.9473684210526315\n",
            "0.8421052631578947 0.8421052631578947 1.0\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n"
          ]
        }
      ],
      "source": [
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 < theta,0,1) == And.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WptuRnw6gBNN"
      },
      "outputs": [],
      "source": [
        "Or = np.array([[0],[1],[1],[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuMcHh8agcAY",
        "outputId": "a3649238-25be-471e-a600-d4ad075afa30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "W_or = np.array([0.5, 0.5])\n",
        "np.where(np.dot(data, W_or) < 0.4, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dt4OIuJtefI",
        "outputId": "b30aadad-f480-44f1-8ca4-4703d97dee9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n"
          ]
        }
      ],
      "source": [
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 < theta,0,1) == Or.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7-i5IdRim7n"
      },
      "outputs": [],
      "source": [
        "Nand = np.array([[1],[1],[1],[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7GA7keXg15J",
        "outputId": "1d9666ca-5269-4d35-8e7c-cf9f388dde4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.10526315789473684\n",
            "0.05263157894736842 0.05263157894736842 0.15789473684210525\n",
            "0.05263157894736842 0.05263157894736842 0.21052631578947367\n",
            "0.05263157894736842 0.05263157894736842 0.2631578947368421\n",
            "0.05263157894736842 0.05263157894736842 0.3157894736842105\n",
            "0.05263157894736842 0.05263157894736842 0.3684210526315789\n",
            "0.05263157894736842 0.05263157894736842 0.42105263157894735\n",
            "0.05263157894736842 0.05263157894736842 0.47368421052631576\n",
            "0.05263157894736842 0.05263157894736842 0.5263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.5789473684210527\n",
            "0.05263157894736842 0.05263157894736842 0.631578947368421\n",
            "0.05263157894736842 0.05263157894736842 0.6842105263157894\n",
            "0.05263157894736842 0.05263157894736842 0.7368421052631579\n",
            "0.05263157894736842 0.05263157894736842 0.7894736842105263\n",
            "0.05263157894736842 0.05263157894736842 0.8421052631578947\n",
            "0.05263157894736842 0.05263157894736842 0.894736842105263\n",
            "0.05263157894736842 0.05263157894736842 0.9473684210526315\n",
            "0.05263157894736842 0.05263157894736842 1.0\n",
            "0.10526315789473684 0.10526315789473684 0.10526315789473684\n",
            "0.10526315789473684 0.10526315789473684 0.10526315789473684\n",
            "0.10526315789473684 0.10526315789473684 0.15789473684210525\n",
            "0.10526315789473684 0.10526315789473684 0.21052631578947367\n",
            "0.10526315789473684 0.10526315789473684 0.2631578947368421\n",
            "0.10526315789473684 0.10526315789473684 0.3157894736842105\n",
            "0.10526315789473684 0.10526315789473684 0.3684210526315789\n",
            "0.10526315789473684 0.10526315789473684 0.42105263157894735\n",
            "0.10526315789473684 0.10526315789473684 0.47368421052631576\n",
            "0.10526315789473684 0.10526315789473684 0.5263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.5789473684210527\n",
            "0.10526315789473684 0.10526315789473684 0.631578947368421\n",
            "0.10526315789473684 0.10526315789473684 0.6842105263157894\n",
            "0.10526315789473684 0.10526315789473684 0.7368421052631579\n",
            "0.10526315789473684 0.10526315789473684 0.7894736842105263\n",
            "0.10526315789473684 0.10526315789473684 0.8421052631578947\n",
            "0.10526315789473684 0.10526315789473684 0.894736842105263\n",
            "0.10526315789473684 0.10526315789473684 0.9473684210526315\n",
            "0.10526315789473684 0.10526315789473684 1.0\n",
            "0.15789473684210525 0.15789473684210525 0.15789473684210525\n",
            "0.15789473684210525 0.15789473684210525 0.15789473684210525\n",
            "0.15789473684210525 0.15789473684210525 0.15789473684210525\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.2631578947368421\n",
            "0.15789473684210525 0.15789473684210525 0.3157894736842105\n",
            "0.15789473684210525 0.15789473684210525 0.3684210526315789\n",
            "0.15789473684210525 0.15789473684210525 0.42105263157894735\n",
            "0.15789473684210525 0.15789473684210525 0.47368421052631576\n",
            "0.15789473684210525 0.15789473684210525 0.5263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.5789473684210527\n",
            "0.15789473684210525 0.15789473684210525 0.631578947368421\n",
            "0.15789473684210525 0.15789473684210525 0.6842105263157894\n",
            "0.15789473684210525 0.15789473684210525 0.7368421052631579\n",
            "0.15789473684210525 0.15789473684210525 0.7894736842105263\n",
            "0.15789473684210525 0.15789473684210525 0.8421052631578947\n",
            "0.15789473684210525 0.15789473684210525 0.894736842105263\n",
            "0.15789473684210525 0.15789473684210525 0.9473684210526315\n",
            "0.15789473684210525 0.15789473684210525 1.0\n",
            "0.21052631578947367 0.21052631578947367 0.21052631578947367\n",
            "0.21052631578947367 0.21052631578947367 0.21052631578947367\n",
            "0.21052631578947367 0.21052631578947367 0.21052631578947367\n",
            "0.21052631578947367 0.21052631578947367 0.21052631578947367\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.3157894736842105\n",
            "0.21052631578947367 0.21052631578947367 0.3684210526315789\n",
            "0.21052631578947367 0.21052631578947367 0.42105263157894735\n",
            "0.21052631578947367 0.21052631578947367 0.47368421052631576\n",
            "0.21052631578947367 0.21052631578947367 0.5263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.5789473684210527\n",
            "0.21052631578947367 0.21052631578947367 0.631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.6842105263157894\n",
            "0.21052631578947367 0.21052631578947367 0.7368421052631579\n",
            "0.21052631578947367 0.21052631578947367 0.7894736842105263\n",
            "0.21052631578947367 0.21052631578947367 0.8421052631578947\n",
            "0.21052631578947367 0.21052631578947367 0.894736842105263\n",
            "0.21052631578947367 0.21052631578947367 0.9473684210526315\n",
            "0.21052631578947367 0.21052631578947367 1.0\n",
            "0.2631578947368421 0.2631578947368421 0.2631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.2631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.2631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.2631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.2631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3684210526315789\n",
            "0.2631578947368421 0.2631578947368421 0.42105263157894735\n",
            "0.2631578947368421 0.2631578947368421 0.47368421052631576\n",
            "0.2631578947368421 0.2631578947368421 0.5263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.5789473684210527\n",
            "0.2631578947368421 0.2631578947368421 0.631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.6842105263157894\n",
            "0.2631578947368421 0.2631578947368421 0.7368421052631579\n",
            "0.2631578947368421 0.2631578947368421 0.7894736842105263\n",
            "0.2631578947368421 0.2631578947368421 0.8421052631578947\n",
            "0.2631578947368421 0.2631578947368421 0.894736842105263\n",
            "0.2631578947368421 0.2631578947368421 0.9473684210526315\n",
            "0.2631578947368421 0.2631578947368421 1.0\n",
            "0.3157894736842105 0.3157894736842105 0.3157894736842105\n",
            "0.3157894736842105 0.3157894736842105 0.3157894736842105\n",
            "0.3157894736842105 0.3157894736842105 0.3157894736842105\n",
            "0.3157894736842105 0.3157894736842105 0.3157894736842105\n",
            "0.3157894736842105 0.3157894736842105 0.3157894736842105\n",
            "0.3157894736842105 0.3157894736842105 0.3157894736842105\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.42105263157894735\n",
            "0.3157894736842105 0.3157894736842105 0.47368421052631576\n",
            "0.3157894736842105 0.3157894736842105 0.5263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.5789473684210527\n",
            "0.3157894736842105 0.3157894736842105 0.631578947368421\n",
            "0.3157894736842105 0.3157894736842105 0.6842105263157894\n",
            "0.3157894736842105 0.3157894736842105 0.7368421052631579\n",
            "0.3157894736842105 0.3157894736842105 0.7894736842105263\n",
            "0.3157894736842105 0.3157894736842105 0.8421052631578947\n",
            "0.3157894736842105 0.3157894736842105 0.894736842105263\n",
            "0.3157894736842105 0.3157894736842105 0.9473684210526315\n",
            "0.3157894736842105 0.3157894736842105 1.0\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.47368421052631576\n",
            "0.3684210526315789 0.3684210526315789 0.5263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.5789473684210527\n",
            "0.3684210526315789 0.3684210526315789 0.631578947368421\n",
            "0.3684210526315789 0.3684210526315789 0.6842105263157894\n",
            "0.3684210526315789 0.3684210526315789 0.7368421052631579\n",
            "0.3684210526315789 0.3684210526315789 0.7894736842105263\n",
            "0.3684210526315789 0.3684210526315789 0.8421052631578947\n",
            "0.3684210526315789 0.3684210526315789 0.894736842105263\n",
            "0.3684210526315789 0.3684210526315789 0.9473684210526315\n",
            "0.3684210526315789 0.3684210526315789 1.0\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.5263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.5789473684210527\n",
            "0.42105263157894735 0.42105263157894735 0.631578947368421\n",
            "0.42105263157894735 0.42105263157894735 0.6842105263157894\n",
            "0.42105263157894735 0.42105263157894735 0.7368421052631579\n",
            "0.42105263157894735 0.42105263157894735 0.7894736842105263\n",
            "0.42105263157894735 0.42105263157894735 0.8421052631578947\n",
            "0.42105263157894735 0.42105263157894735 0.894736842105263\n",
            "0.42105263157894735 0.42105263157894735 0.9473684210526315\n",
            "0.42105263157894735 0.42105263157894735 1.0\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5789473684210527\n",
            "0.47368421052631576 0.47368421052631576 0.631578947368421\n",
            "0.47368421052631576 0.47368421052631576 0.6842105263157894\n",
            "0.47368421052631576 0.47368421052631576 0.7368421052631579\n",
            "0.47368421052631576 0.47368421052631576 0.7894736842105263\n",
            "0.47368421052631576 0.47368421052631576 0.8421052631578947\n",
            "0.47368421052631576 0.47368421052631576 0.894736842105263\n",
            "0.47368421052631576 0.47368421052631576 0.9473684210526315\n",
            "0.47368421052631576 0.47368421052631576 1.0\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.631578947368421\n",
            "0.5263157894736842 0.5263157894736842 0.6842105263157894\n",
            "0.5263157894736842 0.5263157894736842 0.7368421052631579\n",
            "0.5263157894736842 0.5263157894736842 0.7894736842105263\n",
            "0.5263157894736842 0.5263157894736842 0.8421052631578947\n",
            "0.5263157894736842 0.5263157894736842 0.894736842105263\n",
            "0.5263157894736842 0.5263157894736842 0.9473684210526315\n",
            "0.5263157894736842 0.5263157894736842 1.0\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.6842105263157894\n",
            "0.5789473684210527 0.5789473684210527 0.7368421052631579\n",
            "0.5789473684210527 0.5789473684210527 0.7894736842105263\n",
            "0.5789473684210527 0.5789473684210527 0.8421052631578947\n",
            "0.5789473684210527 0.5789473684210527 0.894736842105263\n",
            "0.5789473684210527 0.5789473684210527 0.9473684210526315\n",
            "0.5789473684210527 0.5789473684210527 1.0\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.7368421052631579\n",
            "0.631578947368421 0.631578947368421 0.7894736842105263\n",
            "0.631578947368421 0.631578947368421 0.8421052631578947\n",
            "0.631578947368421 0.631578947368421 0.894736842105263\n",
            "0.631578947368421 0.631578947368421 0.9473684210526315\n",
            "0.631578947368421 0.631578947368421 1.0\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7894736842105263\n",
            "0.6842105263157894 0.6842105263157894 0.8421052631578947\n",
            "0.6842105263157894 0.6842105263157894 0.894736842105263\n",
            "0.6842105263157894 0.6842105263157894 0.9473684210526315\n",
            "0.6842105263157894 0.6842105263157894 1.0\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.8421052631578947\n",
            "0.7368421052631579 0.7368421052631579 0.894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.9473684210526315\n",
            "0.7368421052631579 0.7368421052631579 1.0\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.9473684210526315\n",
            "0.7894736842105263 0.7894736842105263 1.0\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.9473684210526315\n",
            "0.8421052631578947 0.8421052631578947 1.0\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 1.0\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n"
          ]
        }
      ],
      "source": [
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 > theta,0,1) == Nand.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAUtytFyjMIS"
      },
      "outputs": [],
      "source": [
        "w1, w2, theta = 0.05263157894736836, 1.0, 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCpp9PSXp13A",
        "outputId": "fe169560-f691-4b70-e349-6e93bfc38e67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(np.dot(data, np.array([w1,w2]).reshape(2,1)) > theta, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVqMeVdCn8_j"
      },
      "outputs": [],
      "source": [
        "Nor = np.array([[1],[0],[0],[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3BqpveqpCsB",
        "outputId": "e0a740c8-65f7-4f45-dacb-a8b242444a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n"
          ]
        }
      ],
      "source": [
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 > theta,0,1) == Nor.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwtiMLoTpHYz"
      },
      "outputs": [],
      "source": [
        "w1, w2, theta = 0.5263157894736842, 0.5263157894736842, 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfAFGyetpNea",
        "outputId": "06c85462-9d36-4c13-d4b5-6df0897600ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(np.dot(data, np.array([w1,w2]).reshape(2,1)) > theta, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMnKAq0VpbsV"
      },
      "outputs": [],
      "source": [
        "XNor = np.array([[1],[0],[0],[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wesU7Lnorww7"
      },
      "outputs": [],
      "source": [
        "w11, w21, theta1 = -0.15789473684210525, -0.15789473684210525, -0.15789473684210525 # Nand\n",
        "w12, w22, theta2 = 0.9473684210526315, 0.9473684210526315, 0.05263157894736842 #Or"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP-mrPhwtq1o"
      },
      "outputs": [],
      "source": [
        "W1 = np.array([[w11, w12],[w21, w22]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_3e2UJnuG-l",
        "outputId": "def49923-fae0-4391-891a-8aacee2dbb2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.15789474,  0.94736842],\n",
              "       [-0.15789474,  0.94736842]])"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQLZjvXHuJjs"
      },
      "outputs": [],
      "source": [
        "b1 = np.array([theta1, theta2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwYJIPu_udZ1",
        "outputId": "7ada0ca1-3e60-4947-9d2e-25a4a48b8037"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.15789474,  0.05263158])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7-ei_vWueFN",
        "outputId": "7b9d9336-fb61-46b7-8bf5-9ecffe4a77b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 1]])"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l1 = np.where(np.dot(data, W1) < b1, 0, 1)\n",
        "l1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oxRUHkTu5Jp"
      },
      "outputs": [],
      "source": [
        "w1, w2, b2 = 0.15789473684210525, 0.15789473684210525, 0.21052631578947367 #And"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTtGvVYFAui2"
      },
      "outputs": [],
      "source": [
        "W2 = np.array([w1, w2]).reshape(2,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFZ1YcCnBVUD",
        "outputId": "d24b5e6f-060a-4474-c5a0-d4369f8e5241"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(np.dot(l1, W2) < b2, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WBK44SjBk6e"
      },
      "outputs": [],
      "source": [
        "Nor = np.array([[1],[0],[0],[0]])\n",
        "And = np.array([[0],[0],[0],[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6xLMozzDIDM",
        "outputId": "40816cd5-7aa8-419e-8bc1-9679cf58d0ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.10526315789473684\n",
            "0.05263157894736842 0.05263157894736842 0.15789473684210525\n",
            "0.05263157894736842 0.05263157894736842 0.21052631578947367\n",
            "0.05263157894736842 0.05263157894736842 0.2631578947368421\n",
            "0.05263157894736842 0.05263157894736842 0.3157894736842105\n",
            "0.05263157894736842 0.05263157894736842 0.3684210526315789\n",
            "0.05263157894736842 0.05263157894736842 0.42105263157894735\n",
            "0.05263157894736842 0.05263157894736842 0.47368421052631576\n",
            "0.05263157894736842 0.05263157894736842 0.5263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.5789473684210527\n",
            "0.05263157894736842 0.05263157894736842 0.631578947368421\n",
            "0.05263157894736842 0.05263157894736842 0.6842105263157894\n",
            "0.05263157894736842 0.05263157894736842 0.7894736842105263\n",
            "0.05263157894736842 0.05263157894736842 0.8421052631578947\n",
            "0.05263157894736842 0.05263157894736842 0.894736842105263\n",
            "0.05263157894736842 0.05263157894736842 1.0\n",
            "0.10526315789473684 0.10526315789473684 0.15789473684210525\n",
            "0.10526315789473684 0.10526315789473684 0.15789473684210525\n",
            "0.10526315789473684 0.10526315789473684 0.21052631578947367\n",
            "0.10526315789473684 0.10526315789473684 0.2631578947368421\n",
            "0.10526315789473684 0.10526315789473684 0.3157894736842105\n",
            "0.10526315789473684 0.10526315789473684 0.3684210526315789\n",
            "0.10526315789473684 0.10526315789473684 0.42105263157894735\n",
            "0.10526315789473684 0.10526315789473684 0.47368421052631576\n",
            "0.10526315789473684 0.10526315789473684 0.5263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.5789473684210527\n",
            "0.10526315789473684 0.10526315789473684 0.631578947368421\n",
            "0.10526315789473684 0.10526315789473684 0.6842105263157894\n",
            "0.10526315789473684 0.10526315789473684 0.7368421052631579\n",
            "0.10526315789473684 0.10526315789473684 0.7894736842105263\n",
            "0.10526315789473684 0.10526315789473684 0.8421052631578947\n",
            "0.10526315789473684 0.10526315789473684 0.894736842105263\n",
            "0.10526315789473684 0.10526315789473684 0.9473684210526315\n",
            "0.10526315789473684 0.10526315789473684 1.0\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.2631578947368421\n",
            "0.15789473684210525 0.15789473684210525 0.3157894736842105\n",
            "0.15789473684210525 0.15789473684210525 0.3684210526315789\n",
            "0.15789473684210525 0.15789473684210525 0.42105263157894735\n",
            "0.15789473684210525 0.15789473684210525 0.47368421052631576\n",
            "0.15789473684210525 0.15789473684210525 0.5263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.5789473684210527\n",
            "0.15789473684210525 0.15789473684210525 0.631578947368421\n",
            "0.15789473684210525 0.15789473684210525 0.6842105263157894\n",
            "0.15789473684210525 0.15789473684210525 0.7368421052631579\n",
            "0.15789473684210525 0.15789473684210525 0.7894736842105263\n",
            "0.15789473684210525 0.15789473684210525 0.8421052631578947\n",
            "0.15789473684210525 0.15789473684210525 0.894736842105263\n",
            "0.15789473684210525 0.15789473684210525 0.9473684210526315\n",
            "0.15789473684210525 0.15789473684210525 1.0\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.3157894736842105\n",
            "0.21052631578947367 0.21052631578947367 0.3684210526315789\n",
            "0.21052631578947367 0.21052631578947367 0.42105263157894735\n",
            "0.21052631578947367 0.21052631578947367 0.47368421052631576\n",
            "0.21052631578947367 0.21052631578947367 0.5263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.5789473684210527\n",
            "0.21052631578947367 0.21052631578947367 0.631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.6842105263157894\n",
            "0.21052631578947367 0.21052631578947367 0.7368421052631579\n",
            "0.21052631578947367 0.21052631578947367 0.7894736842105263\n",
            "0.21052631578947367 0.21052631578947367 0.8421052631578947\n",
            "0.21052631578947367 0.21052631578947367 0.894736842105263\n",
            "0.21052631578947367 0.21052631578947367 0.9473684210526315\n",
            "0.21052631578947367 0.21052631578947367 1.0\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3684210526315789\n",
            "0.2631578947368421 0.2631578947368421 0.42105263157894735\n",
            "0.2631578947368421 0.2631578947368421 0.47368421052631576\n",
            "0.2631578947368421 0.2631578947368421 0.5263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.5789473684210527\n",
            "0.2631578947368421 0.2631578947368421 0.631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.6842105263157894\n",
            "0.2631578947368421 0.2631578947368421 0.7368421052631579\n",
            "0.2631578947368421 0.2631578947368421 0.7894736842105263\n",
            "0.2631578947368421 0.2631578947368421 0.8421052631578947\n",
            "0.2631578947368421 0.2631578947368421 0.894736842105263\n",
            "0.2631578947368421 0.2631578947368421 0.9473684210526315\n",
            "0.2631578947368421 0.2631578947368421 1.0\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.42105263157894735\n",
            "0.3157894736842105 0.3157894736842105 0.47368421052631576\n",
            "0.3157894736842105 0.3157894736842105 0.5263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.5789473684210527\n",
            "0.3157894736842105 0.3157894736842105 0.631578947368421\n",
            "0.3157894736842105 0.3157894736842105 0.6842105263157894\n",
            "0.3157894736842105 0.3157894736842105 0.7368421052631579\n",
            "0.3157894736842105 0.3157894736842105 0.7894736842105263\n",
            "0.3157894736842105 0.3157894736842105 0.8421052631578947\n",
            "0.3157894736842105 0.3157894736842105 0.894736842105263\n",
            "0.3157894736842105 0.3157894736842105 0.9473684210526315\n",
            "0.3157894736842105 0.3157894736842105 1.0\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.47368421052631576\n",
            "0.3684210526315789 0.3684210526315789 0.5263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.5789473684210527\n",
            "0.3684210526315789 0.3684210526315789 0.631578947368421\n",
            "0.3684210526315789 0.3684210526315789 0.6842105263157894\n",
            "0.3684210526315789 0.3684210526315789 0.7368421052631579\n",
            "0.3684210526315789 0.3684210526315789 0.7894736842105263\n",
            "0.3684210526315789 0.3684210526315789 0.8421052631578947\n",
            "0.3684210526315789 0.3684210526315789 0.894736842105263\n",
            "0.3684210526315789 0.3684210526315789 0.9473684210526315\n",
            "0.3684210526315789 0.3684210526315789 1.0\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.5263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.5789473684210527\n",
            "0.42105263157894735 0.42105263157894735 0.631578947368421\n",
            "0.42105263157894735 0.42105263157894735 0.6842105263157894\n",
            "0.42105263157894735 0.42105263157894735 0.7368421052631579\n",
            "0.42105263157894735 0.42105263157894735 0.7894736842105263\n",
            "0.42105263157894735 0.42105263157894735 0.8421052631578947\n",
            "0.42105263157894735 0.42105263157894735 0.894736842105263\n",
            "0.42105263157894735 0.42105263157894735 0.9473684210526315\n",
            "0.42105263157894735 0.42105263157894735 1.0\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5789473684210527\n",
            "0.47368421052631576 0.47368421052631576 0.631578947368421\n",
            "0.47368421052631576 0.47368421052631576 0.6842105263157894\n",
            "0.47368421052631576 0.47368421052631576 0.7368421052631579\n",
            "0.47368421052631576 0.47368421052631576 0.7894736842105263\n",
            "0.47368421052631576 0.47368421052631576 0.8421052631578947\n",
            "0.47368421052631576 0.47368421052631576 0.894736842105263\n",
            "0.47368421052631576 0.47368421052631576 0.9473684210526315\n",
            "0.47368421052631576 0.47368421052631576 1.0\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.631578947368421\n",
            "0.5263157894736842 0.5263157894736842 0.6842105263157894\n",
            "0.5263157894736842 0.5263157894736842 0.7368421052631579\n",
            "0.5263157894736842 0.5263157894736842 0.7894736842105263\n",
            "0.5263157894736842 0.5263157894736842 0.8421052631578947\n",
            "0.5263157894736842 0.5263157894736842 0.894736842105263\n",
            "0.5263157894736842 0.5263157894736842 0.9473684210526315\n",
            "0.5263157894736842 0.5263157894736842 1.0\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.6842105263157894\n",
            "0.5789473684210527 0.5789473684210527 0.7368421052631579\n",
            "0.5789473684210527 0.5789473684210527 0.7894736842105263\n",
            "0.5789473684210527 0.5789473684210527 0.8421052631578947\n",
            "0.5789473684210527 0.5789473684210527 0.894736842105263\n",
            "0.5789473684210527 0.5789473684210527 0.9473684210526315\n",
            "0.5789473684210527 0.5789473684210527 1.0\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.7368421052631579\n",
            "0.631578947368421 0.631578947368421 0.7894736842105263\n",
            "0.631578947368421 0.631578947368421 0.8421052631578947\n",
            "0.631578947368421 0.631578947368421 0.894736842105263\n",
            "0.631578947368421 0.631578947368421 0.9473684210526315\n",
            "0.631578947368421 0.631578947368421 1.0\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7894736842105263\n",
            "0.6842105263157894 0.6842105263157894 0.8421052631578947\n",
            "0.6842105263157894 0.6842105263157894 0.894736842105263\n",
            "0.6842105263157894 0.6842105263157894 0.9473684210526315\n",
            "0.6842105263157894 0.6842105263157894 1.0\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.8421052631578947\n",
            "0.7368421052631579 0.7368421052631579 0.894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.9473684210526315\n",
            "0.7368421052631579 0.7368421052631579 1.0\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.9473684210526315\n",
            "0.7894736842105263 0.7894736842105263 1.0\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.9473684210526315\n",
            "0.8421052631578947 0.8421052631578947 1.0\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n"
          ]
        }
      ],
      "source": [
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 < theta,0,1) == And.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNVpkpnMDOLW",
        "outputId": "358ba6a4-4ebe-488c-96ad-f68e038ee2ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n"
          ]
        }
      ],
      "source": [
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 > theta,0,1) == Nor.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCHqp3uHDQ7k"
      },
      "outputs": [],
      "source": [
        "w11, w12, theta1 = -0.15789473684210525, -0.15789473684210525, -0.21052631578947367\n",
        "w21, w22, theta2 = 0.21052631578947367, 0.21052631578947367, 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8GPO8EHDg6K"
      },
      "outputs": [],
      "source": [
        "W1 = np.array([[w11, w12],[w21, w22]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyi6M2-YDow7",
        "outputId": "19a6e787-aaf7-4244-db24-349574c1f184"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.15789474, -0.15789474],\n",
              "       [ 0.21052632,  0.21052632]])"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91XJLvWODpRb",
        "outputId": "e3387314-fbb4-4d14-d0fa-e2e08b111dc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.21052632,  0.        ])"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "theta = np.array([theta1, theta2])\n",
        "theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoHxi9_RDvfc",
        "outputId": "9515e83d-ed6b-4e5c-cae7-f988e340ce1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [1, 1]])"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l1 = np.where(np.dot(data, W1) < theta, 0, 1)\n",
        "l1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbfQJ789D8eb",
        "outputId": "9203ec6d-be13-4efe-e20f-1c663fa0ce7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n"
          ]
        }
      ],
      "source": [
        "Or = np.array([[0],[1],[1],[1]])\n",
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 < theta,0,1) == Or.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ_m4HyhEJN-"
      },
      "outputs": [],
      "source": [
        "w31, w32, theta3 = 0.21052631578947367, 0.21052631578947367, 0.05263157894736842"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aR0otoNEVLO"
      },
      "outputs": [],
      "source": [
        "W3 = np.array([w31, w32]).reshape(2,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztzZC82hEXSW",
        "outputId": "31615c18-5c88-4718-be1d-a7fe3671247b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.21052632],\n",
              "       [0.21052632]])"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPeYt6e_EYwA",
        "outputId": "81a32db0-e1e1-498a-c7e0-eb61a0fd4b2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(np.dot(l1, W3) < theta, 0, 1) # ?????  ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhi9hw4IEe4I"
      },
      "outputs": [],
      "source": [
        "def make_w(method):\n",
        "  method_dict ={\n",
        "      'And': [0, 0, 0, 1],\n",
        "      'Nor' : [1, 0, 0, 0],\n",
        "      'Or' : [0, 1, 1, 1],\n",
        "      'Nand' : [1, 1, 1, 0]\n",
        "  }\n",
        "  data = np.array([[0,0],[1,0],[0, 1],[1, 1]])\n",
        "  for w1 in np.linspace(0, 1, 20):\n",
        "    for w2 in np.linspace(0, 1, 20):\n",
        "      for theta in np.linspace(-1, 1, 20):\n",
        "        if method in ['Nor', 'Nand']:\n",
        "           if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 > theta,0,1) == method_dict.get(method)) == 4:\n",
        "            return -w1, -w2, -theta\n",
        "        else:\n",
        "          if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 < theta,0,1) == method_dict.get(method)) == 4:\n",
        "            return w1, w2, theta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDrvPhbbHJyK"
      },
      "outputs": [],
      "source": [
        "w11, w21, b11 = make_w('Nor')\n",
        "w12, w22, b21 = make_w('And')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdZr9MpaHL1y"
      },
      "outputs": [],
      "source": [
        "X = np.array([[0,0],[1,0],[0, 1],[1, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERFfsyjpISz4"
      },
      "outputs": [],
      "source": [
        "W1 = np.array([[w11, w12], [w21, w22]])\n",
        "b1 = np.array([b11, b21])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMi18MnSIhHM"
      },
      "outputs": [],
      "source": [
        "l1 = np.where(np.dot(X, W1) < b1, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgL6NgCxI06V"
      },
      "outputs": [],
      "source": [
        "w1, w2, b2 = make_w('Or')\n",
        "W2 = np.array([w1, w2]).reshape(2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHtpUEovI92e",
        "outputId": "04cc6ab0-8dbe-41b0-f8a2-685323a55be9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = np.where(np.dot(l1, W2) < b2, 0, 1)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItCzsPqNJFgA"
      },
      "outputs": [],
      "source": [
        "W1 = np.random.randn(2, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4-JnaeaSqUH"
      },
      "outputs": [],
      "source": [
        "b1 = np.zeros(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3l6a88GISvoQ"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "oyRAlhRbS8XZ",
        "outputId": "ec413dde-a27f-4eb5-a88a-4e85fd3118ad"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = np.linspace(-5, 5)\n",
        "y = sigmoid(x)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLORlFZsTPK5",
        "outputId": "b5f02620-46d4-4932-9b0d-4750104d74a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5       , 0.5       ],\n",
              "       [0.43595063, 0.36512572],\n",
              "       [0.25382917, 0.31556397],\n",
              "       [0.20818414, 0.20958661]])"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sigmoid(np.dot(X, W1) + b1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxR7UWMNT57-"
      },
      "outputs": [],
      "source": [
        "W2 = np.random.randn(2, 1)\n",
        "b2 = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzWpEq4vTgkN",
        "outputId": "3f4e6ee3-8b03-454f-8ebb-d0aed533dcf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.62512794],\n",
              "       [0.60001201],\n",
              "       [0.57316437],\n",
              "       [0.55322703]])"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = sigmoid(np.dot(sigmoid(np.dot(X, W1) + b1), W2) + b2)\n",
        "y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKqGBr_6UApH",
        "outputId": "d8db34d6-f1a8-41f3-8029-ec73d6ca1ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 1)"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tiQ2NmZUONY"
      },
      "outputs": [],
      "source": [
        "y = np.array([0, 0, 0, 1]).reshape(4, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zykjbLqWL8H",
        "outputId": "43e20299-4738-4cd9-b64e-71824d495d85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHyIw22YUt4W"
      },
      "outputs": [],
      "source": [
        "W1 = np.random.randn(2, 1)\n",
        "b1 = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L_OTx1nUWGq"
      },
      "outputs": [],
      "source": [
        "y_hat = sigmoid(np.dot(X, W1) + b1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiWc1rsqUr7U",
        "outputId": "3d829949-bc3a-4754-ec04-076c6f0c916d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5       ],\n",
              "       [0.24235118],\n",
              "       [0.61990956],\n",
              "       [0.34283907]])"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfysDwE2U3Im"
      },
      "outputs": [],
      "source": [
        "def loss(y_hat):\n",
        "  loss_val = np.sum(-((1-y)*np.log(1-y_hat) + y*np.log(y_hat)))\n",
        "  return loss_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZDRQkj8VhHS"
      },
      "outputs": [],
      "source": [
        "fx = loss(y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5wHAo6aYvN5",
        "outputId": "95b7b38e-391b-4bc3-8660-8aa4e1db66fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1.13983214])"
            ]
          },
          "execution_count": 244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzIMGCK4cUsw"
      },
      "outputs": [],
      "source": [
        "tmp = W1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMFDiANEWFKF",
        "outputId": "7d592ae1-3c80-4f35-ba7a-cdd52cf244fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1.13982214])"
            ]
          },
          "execution_count": 246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " h = 1e-5\n",
        " W1[0] += h\n",
        " W1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZgSKsffYrYf",
        "outputId": "1dc00aa5-08be-4129-e620-be7aa071a22d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3.0085226548584343, 3.008518506781375)"
            ]
          },
          "execution_count": 247,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = sigmoid(np.dot(X, W1) + b1)\n",
        "fxh  = loss(y_hat)\n",
        "fx, fxh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1CUTFwBck8y"
      },
      "outputs": [],
      "source": [
        "dW1 = (fxh - fx)/h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVDBer3Wctzi",
        "outputId": "70949785-6042-4fb0-b8a5-f318d663f034"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-0.4148077059173971"
            ]
          },
          "execution_count": 249,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dW1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq2w5x97curB"
      },
      "outputs": [],
      "source": [
        "W1[0] = tmp\n",
        "tmp = W1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpIHpcpvdFw8"
      },
      "outputs": [],
      "source": [
        "W1[1] += h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPTg8E6VdI9_",
        "outputId": "98c6f60b-7784-4568-be5c-2104e189c77d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3.0085226548584343, 3.0085181343131993)"
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = sigmoid(np.dot(X, W1) + b1)\n",
        "fxh  = loss(y_hat)\n",
        "fx, fxh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fEsrqHYdhY5"
      },
      "outputs": [],
      "source": [
        "dW2 = (fxh - fx)/h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAAB_ZbGdkao"
      },
      "outputs": [],
      "source": [
        "W1[1] = tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWjW3ZVRdmrW"
      },
      "outputs": [],
      "source": [
        "tmp = b1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4SNcw9jdqk3"
      },
      "outputs": [],
      "source": [
        "b1 += h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1nPsNlrdxEo",
        "outputId": "7c862a37-0254-4635-8db4-e8ae115d0ad2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3.0085226548584343, 3.0085251854429673)"
            ]
          },
          "execution_count": 257,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = sigmoid(np.dot(X, W1) + b1)\n",
        "fxh  = loss(y_hat)\n",
        "fx, fxh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg6ktX4NdyxK"
      },
      "outputs": [],
      "source": [
        "db = (fxh - fx)/h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toUdliJsd2UB"
      },
      "outputs": [],
      "source": [
        "b1 = tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC02LBY2eGIK",
        "outputId": "33b19d28-0353-49ad-c62d-17fc3b2ca13c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.0085181343131993"
            ]
          },
          "execution_count": 262,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = sigmoid(np.dot(X, W1) + b1)\n",
        "loss(y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcNAJPDteTjj"
      },
      "outputs": [],
      "source": [
        "dW = np.array([dW1, dW2]).reshape(2,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMvbqv47eaUN"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "W1 -= dW*lr\n",
        "b1 -= db*lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOcTU33wetV3",
        "outputId": "890f7323-3448-44a1-f104-c9b7bb5b1176"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.0081508579615344"
            ]
          },
          "execution_count": 266,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = sigmoid(np.dot(X, W1) + b1)\n",
        "loss(y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLFQkJo_eujX",
        "outputId": "3777036c-3f1b-42c8-9617-6b91bb34d325"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.00036727635166489137"
            ]
          },
          "execution_count": 267,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "3.0085181343131993 - 3.0081508579615344"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lat5k573j_c7"
      },
      "outputs": [],
      "source": [
        "W = np.random.randn(2, 1)\n",
        "b = np.zeros(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "1dndYBYgez5_"
      },
      "outputs": [],
      "source": [
        "def gradient(W, b):\n",
        "  cols = W.shape[1]\n",
        "  rows = W.shape[0]\n",
        "  dW = np.zeros_like(W)\n",
        "  #dW = np.zeros((W.shape[0], W.shape[1]))\n",
        "  db = np.zeros_like(b)\n",
        "  h = 1e-5\n",
        "  for col in range(cols):\n",
        "    for row in range(rows):\n",
        "      y_hat = sigmoid(np.dot(X, W) + b)\n",
        "      fx = loss(y_hat)\n",
        "      tmp = W[row, col]\n",
        "      W[row, col] += h\n",
        "      y_hat = sigmoid(np.dot(X, W) + b)\n",
        "      fxh = loss(y_hat)\n",
        "      dv = (fxh - fx)/h\n",
        "      dW[row, col] = dv\n",
        "      W[row, col] = tmp\n",
        "  for idx in range(len(b)):\n",
        "    y_hat = sigmoid(np.dot(X, W) + b)\n",
        "    fx = loss(y_hat)\n",
        "    tmp = b[idx]\n",
        "    b[idx] += h\n",
        "    y_hat = sigmoid(np.dot(X, W) + b)\n",
        "    fxh = loss(y_hat)\n",
        "    db[idx] = (fxh-fx)/h\n",
        "    b[idx] = tmp\n",
        "  return dW, db\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlkT1NhlfgVc",
        "outputId": "3bf57a7e-5645-4a80-c380-f30b95e5d52f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[1.91427868],\n",
              "        [2.10145994]]),\n",
              " array([-3.28211037]))"
            ]
          },
          "execution_count": 306,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W = np.random.randn(2, 1)\n",
        "b = np.zeros(1)\n",
        "lr = 1e-4\n",
        "for _ in range(1000):\n",
        "  W -=  gradient(W, b)[0]*lr\n",
        "  b -= gradient(W, b)[1]*lr\n",
        "W, b\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjXIt03kniKU",
        "outputId": "beb5b86b-2587-439e-fc74-ce63d00181c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.03619003],\n",
              "       [0.2029704 ],\n",
              "       [0.23493527],\n",
              "       [0.67560096]])"
            ]
          },
          "execution_count": 307,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sigmoid(np.dot(X, W) + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoUYY4oCl3CH",
        "outputId": "1e7e189d-e3d9-4480-e150-f4e65d2926de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 311,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(sigmoid(np.dot(X, W) + b) > 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OYe0Umi6nF3f"
      },
      "outputs": [],
      "source": [
        "  y = np.array([[0],[1],[1],[1]]).reshape(4,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LCG78py0oA1m"
      },
      "outputs": [],
      "source": [
        "X = np.array([[0,0],[1,0],[0, 1],[1, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "y2lsecQYhI1u"
      },
      "outputs": [],
      "source": [
        "y1 = np.array([0, 0, 0, 1]).reshape(4, 1)\n",
        "y2 = np.array([1, 1, 1, 0]).reshape(4, 1)\n",
        "y3 = np.array([0, 1, 1, 1]).reshape(4, 1)\n",
        "y4 = np.array([1, 0, 0, 0]).reshape(4, 1)\n",
        "y5 = np.array([0, 1, 1, 0]).reshape(4, 1)\n",
        "y6 = np.array([1, 0, 0, 1]).reshape(4, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oZGqZlnVh430"
      },
      "outputs": [],
      "source": [
        "\n",
        "W = np.random.randn(X.shape[1], y1.shape[1])\n",
        "b = np.zeros(y1.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IUGKO1y4ielB"
      },
      "outputs": [],
      "source": [
        "y_hat = np.dot(X, W) + b\n",
        "y_hat = sigmoid(y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hZSMMw4jh8CF"
      },
      "outputs": [],
      "source": [
        "def loss(y_hat, y):\n",
        "  return -np.sum((1-y)*np.log(1-y_hat) + y*np.log(y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4iYnekQjGPU",
        "outputId": "4effa706-1cf1-4ff2-93a3-5b4d1dc6560e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.563921468779761"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss(y_hat, y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siqwxFG6jmdG",
        "outputId": "d1446dcd-c720-416c-d40f-7562ace8dde5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.5609579 ]\n",
            " [1.95802586]]\n",
            "[[0.79771473]\n",
            " [0.84754294]]\n"
          ]
        }
      ],
      "source": [
        "# (fxh - fx)/h ---> gradient\n",
        "print(W)\n",
        "y_hat = np.dot(X, W) + b\n",
        "y_hat = sigmoid(y_hat)\n",
        "fx = loss(y_hat, y1)\n",
        "h = 1e-5\n",
        "tmp = W[0, 0]\n",
        "W[0, 0] += h\n",
        "y_hat = np.dot(X, W) + b\n",
        "y_hat = sigmoid(y_hat)\n",
        "fxh = loss(y_hat, y1)\n",
        "dW1 = (fxh-fx)/h\n",
        "\n",
        "W[0, 0] = tmp\n",
        "tmp = W[1, 0]\n",
        "W[1,0] += h\n",
        "y_hat = np.dot(X, W) + b\n",
        "y_hat = sigmoid(y_hat)\n",
        "fxh = loss(y_hat, y1)\n",
        "dW2 = (fxh-fx)/h\n",
        "dW = np.array([dW1, dW2]).reshape(2,1)\n",
        "print(dW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIoF3TviqCRs",
        "outputId": "41286c7c-2af6-4345-8c59-d0e4e7f1885a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.563929944209187"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss(y_hat, y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mStvCy4zq_tw",
        "outputId": "c045c3d3-2d77-485c-8cff-2eda0322a3b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.562575388671844"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = np.dot(X, W-(1e-3)*dW) + b\n",
        "y_hat = sigmoid(y_hat)\n",
        "loss(y_hat, y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lo3ipUQzrVPM"
      },
      "outputs": [],
      "source": [
        "def predict(x, W, b):\n",
        "  return sigmoid(np.dot(X, W) + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrHE0quBr34l",
        "outputId": "5b42f81d-ee82-4060-df90-d5c0b4e36120"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5       ],\n",
              "       [0.82649076],\n",
              "       [0.87632023],\n",
              "       [0.97122339]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(X, W, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "R_Cn3wXAr44l"
      },
      "outputs": [],
      "source": [
        "def loss(y_hat, y):\n",
        "  return -np.sum((1-y)*np.log(1-y_hat) + y*np.log(y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1UJk0cXXslL8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def gradient(x, y, W, b):\n",
        "  h = 1e-5\n",
        "  dW = np.zeros_like(W)\n",
        "  db = np.zeros_like(b)\n",
        "  cols = range(W.shape[1])\n",
        "  rows = range(W.shape[0])\n",
        "  for col in cols:\n",
        "    for row in rows:\n",
        "      y_hat = predict(x, W, b)\n",
        "      fx = loss(y_hat, y)\n",
        "      tmp = W[row, col]\n",
        "      W[row, col] += h\n",
        "      y_hat = predict(x, W, b)\n",
        "      fxh = loss(y_hat, y)\n",
        "      dW[row,col] = (fxh - fx)/h\n",
        "      W[row, col] = tmp\n",
        "  for i in range(db.size):\n",
        "    y_hat = predict(x, W, b)\n",
        "    fx = loss(y_hat, y)\n",
        "    tmp = b[i]\n",
        "    b[i] += h\n",
        "    y_hat = predict(x, W, b)\n",
        "    fxh = loss(y_hat, y)\n",
        "    db[i] = (fxh-fx)/h\n",
        "    b[i] = tmp\n",
        "    y_hat = predict(x, W, b)\n",
        "    fx = loss(y_hat, y)\n",
        "\n",
        "  return dW, db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJyO9pFW185x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i3sbGSR15gw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "btu7xEtz2EdR"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "W = np.random.randn(X.shape[1], y2.shape[1])\n",
        "b = np.zeros(y2.shape[1])\n",
        "for i in range(10000):\n",
        "    W = W - gradient(X, y2, W, b)[0]*lr\n",
        "    b = b - gradient(X ,y2, W, b)[1]*lr\n",
        "    y_hat = predict(X, W, b)\n",
        "    # if i % 100 == 0:\n",
        "    #   print(f'loss =====> {loss(y_hat, y1)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHegvgSW6faX",
        "outputId": "e0c09224-342b-4563-8112-0233480f5e74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH_Atwq36fuH",
        "outputId": "be3b1df5-9291-421d-85b9-9a0af8acf434"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "np.where(predict(X, W, b)>0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "q5gZYprJwMx6"
      },
      "outputs": [],
      "source": [
        "def descent_gradient(x, y, lr = 1e-3, epochs=10000):\n",
        "  W = np.random.randn(x.shape[1], y.shape[1])\n",
        "  b = np.zeros(y.shape[1])\n",
        "  for i in range(epochs):\n",
        "    W -= gradient(x, y, W, b)[0]*lr\n",
        "    b -= gradient(x ,y, W, b)[1]*lr\n",
        "    y_hat = predict(x, W, b)\n",
        "    if i % 100 == 0:\n",
        "      print(f'loss =====> {loss(y_hat, y)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScAAEhoWyYbS",
        "outputId": "ee279980-c7cb-4eb2-a720-0f443c0ca82b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss =====> 3.3904775195402994\n",
            "loss =====> 3.320029612937298\n",
            "loss =====> 3.252277681247807\n",
            "loss =====> 3.1870272901174985\n",
            "loss =====> 3.124110184678475\n",
            "loss =====> 3.0633803714208665\n",
            "loss =====> 3.004710667358\n",
            "loss =====> 2.9479896893615085\n",
            "loss =====> 2.8931192525833245\n",
            "loss =====> 2.84001214379008\n",
            "loss =====> 2.7885902336187076\n",
            "loss =====> 2.7387828911949557\n",
            "loss =====> 2.6905256651255973\n",
            "loss =====> 2.6437591963474665\n",
            "loss =====> 2.598428330456219\n",
            "loss =====> 2.5544813997281377\n",
            "loss =====> 2.5118696479032447\n",
            "loss =====> 2.4705467737572544\n",
            "loss =====> 2.4304685724198194\n",
            "loss =====> 2.3915926562266305\n",
            "loss =====> 2.3538782395242857\n",
            "loss =====> 2.317285974292945\n",
            "loss =====> 2.281777825604206\n",
            "loss =====> 2.2473169778833997\n",
            "loss =====> 2.213867764605316\n",
            "loss =====> 2.18139561549975\n",
            "loss =====> 2.14986701656565\n",
            "loss =====> 2.1192494791966916\n",
            "loss =====> 2.0895115155819948\n",
            "loss =====> 2.060622618207851\n",
            "loss =====> 2.032553241857708\n",
            "loss =====> 2.0052747869338456\n",
            "loss =====> 1.9787595832698694\n",
            "loss =====> 1.952980873874763\n",
            "loss =====> 1.9279127982416577\n",
            "loss =====> 1.903530375018644\n",
            "loss =====> 1.8798094839403903\n",
            "loss =====> 1.8567268470020153\n",
            "loss =====> 1.8342600089157504\n",
            "loss =====> 1.812387316919542\n",
            "loss =====> 1.7910879000360453\n",
            "loss =====> 1.7703416478881677\n",
            "loss =====> 1.7501291891836908\n",
            "loss =====> 1.73043186997866\n",
            "loss =====> 1.7112317318252044\n",
            "loss =====> 1.6925114899041118\n",
            "loss =====> 1.674254511231501\n",
            "loss =====> 1.656444793021427\n",
            "loss =====> 1.6390669412753127\n",
            "loss =====> 1.6221061496635378\n",
            "loss =====> 1.6055481787516324\n",
            "loss =====> 1.589379335617429\n",
            "loss =====> 1.5735864538980628\n",
            "loss =====> 1.5581568742975342\n",
            "loss =====> 1.5430784255815406\n",
            "loss =====> 1.5283394060772388\n",
            "loss =====> 1.5139285656922592\n",
            "loss =====> 1.4998350884666767\n",
            "loss =====> 1.4860485756600696\n",
            "loss =====> 1.4725590293771413\n",
            "loss =====> 1.4593568367328698\n",
            "loss =====> 1.4464327545552456\n",
            "loss =====> 1.4337778946182929\n",
            "loss =====> 1.4213837093991297\n",
            "loss =====> 1.409241978352131\n",
            "loss =====> 1.397344794689971\n",
            "loss =====> 1.3856845526594197\n",
            "loss =====> 1.3742539353026764\n",
            "loss =====> 1.3630459026904946\n",
            "loss =====> 1.3520536806139671\n",
            "loss =====> 1.3412707497227643\n",
            "loss =====> 1.3306908350979114\n",
            "loss =====> 1.3203078962406791\n",
            "loss =====> 1.3101161174694473\n",
            "loss =====> 1.3001098987076602\n",
            "loss =====> 1.290283846650452\n",
            "loss =====> 1.2806327662953887\n",
            "loss =====> 1.2711516528266968\n",
            "loss =====> 1.261835683835984\n",
            "loss =====> 1.25268021187063\n",
            "loss =====> 1.2436807572945312\n",
            "loss =====> 1.2348330014505582\n",
            "loss =====> 1.2261327801124784\n",
            "loss =====> 1.2175760772133915\n",
            "loss =====> 1.2091590188425239\n",
            "loss =====> 1.2008778674959384\n",
            "loss =====> 1.1927290165737072\n",
            "loss =====> 1.1847089851110757\n",
            "loss =====> 1.1768144127349045\n",
            "loss =====> 1.169042054836321\n",
            "loss =====> 1.1613887779489265\n",
            "loss =====> 1.1538515553254036\n",
            "loss =====> 1.1464274627030193\n",
            "loss =====> 1.139113674249889\n",
            "loss =====> 1.131907458684967\n",
            "loss =====> 1.1248061755636216\n",
            "loss =====> 1.1178072717213206\n",
            "loss =====> 1.1109082778695427\n",
            "loss =====> 1.1041068053358978\n",
            "loss =====> 1.0974005429435212\n"
          ]
        }
      ],
      "source": [
        "descent_gradient(X, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUZhXqfTxpPt",
        "outputId": "0907afe9-b0ad-44b2-d80b-160d3ad6daf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "np.where(predict(X, W, b)>0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "na7oxvG1ytpK"
      },
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "  def __init__(self, x, y):\n",
        "    self.x = x\n",
        "    if y.ndim == 1:\n",
        "      y = y.reshape(-1, 1)\n",
        "    self.y = y\n",
        "    self.W = np.random.randn(x.shape[1], y.shape[1])\n",
        "    self.b = np.zeros(y.shape[1])\n",
        "\n",
        "  def predict_proba(self):\n",
        "\n",
        "    self.y_hat = np.dot(self.x, self.W) + self.b\n",
        "    self.y_hat = sigmoid(self.y_hat)\n",
        "    return self.y_hat\n",
        "\n",
        "\n",
        "  def loss(self):\n",
        "    result = self.predict_proba()\n",
        "    return -np.sum((1-self.y)*np.log(1-result)+self.y*np.log(result))\n",
        "\n",
        "  def gradient(self):\n",
        "    h = 1e-5\n",
        "    self.dW = np.zeros_like(self.W)\n",
        "    self.db = np.zeros_like(self.b)\n",
        "    cols = range(self.W.shape[1])\n",
        "    rows = range(self.W.shape[0])\n",
        "    for col in cols:\n",
        "      for row in rows:\n",
        "        fx = self.loss()\n",
        "        tmp = self.W[row, col]\n",
        "        self.W[row, col] += h\n",
        "        fxh = self.loss()\n",
        "        self.dW[row, col] = (fxh-fx)/h\n",
        "        self.W[row, col] = tmp\n",
        "    for i in range(self.b.size):\n",
        "      fx = self.loss()\n",
        "      tmp = self.b[i]\n",
        "      self.b[i] += h\n",
        "      fxh = self.loss()\n",
        "      self.db[i] = (fxh-fx)/h\n",
        "      self.b[i] = tmp\n",
        "    return self.dW, self.db\n",
        "\n",
        "\n",
        "\n",
        "  def descent_gradient(self):\n",
        "    lr = 1e-3\n",
        "    dW, db = self.gradient()\n",
        "    self.W -= dW*lr\n",
        "    self.b -= db*lr\n",
        "\n",
        "  def fit(self, epoches=10000, lr=1e-3):\n",
        "    for epoche in range(epoches):\n",
        "      self.descent_gradient()\n",
        "      if epoche % 100 == 0:\n",
        "        print(self.loss())\n",
        "\n",
        "  def predict(self, x):\n",
        "    return np.where(sigmoid(np.dot(x, self.W)+self.b) > 0.5, 1, 0)\n",
        "\n",
        "  def score(self, x ,y):\n",
        "    if y.ndim == 1:\n",
        "      y = y.reshape(-1, 1)\n",
        "    return np.sum(self.predict(x) == y)/x.shape[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6tJO-CHbHcgp"
      },
      "outputs": [],
      "source": [
        "and_ = Perceptron(X, y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTdnI455M6Ea",
        "outputId": "b4c8c972-071a-4ed4-c879-5135be2a2cac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-0.0804938 ],\n",
              "        [ 0.17480522]]),\n",
              " array([1.06218765]))"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "and_.gradient()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYlL-y9lHlie",
        "outputId": "d5eb4c3d-9cac-4acd-a116-3bc5a629e354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8419929822030636\n",
            "2.736523030108265\n",
            "2.6491217789506787\n",
            "2.5753136828997\n",
            "2.5117719041660527\n",
            "2.4560377716503234\n",
            "2.4062978586595416\n",
            "2.3612138824093796\n",
            "2.319795875593391\n",
            "2.2813088344497094\n",
            "2.245204463191538\n",
            "2.2110714065781867\n",
            "2.1785989767371055\n",
            "2.147550687326747\n",
            "2.1177449071342425\n",
            "2.089040685602767\n",
            "2.061327342407885\n",
            "2.034516803082148\n",
            "2.008537943346431\n",
            "1.983332406716669\n",
            "1.9588515054163218\n",
            "1.9350539196809584\n",
            "1.911903986667809\n",
            "1.8893704255306798\n",
            "1.8674253856160619\n",
            "1.8460437343093155\n",
            "1.8252025227814275\n",
            "1.8048805838944104\n",
            "1.7850582283357657\n",
            "1.7657170137964613\n",
            "1.7468395684906985\n",
            "1.7284094551218794\n",
            "1.7104110649760174\n",
            "1.6928295344748832\n",
            "1.6756506785018395\n",
            "1.6588609362772562\n",
            "1.6424473266533406\n",
            "1.626397410510109\n",
            "1.6106992585349205\n",
            "1.5953414231162892\n",
            "1.5803129134111087\n",
            "1.5656031728945592\n",
            "1.551202058874749\n",
            "1.5370998235968925\n",
            "1.5232870966529133\n",
            "1.509754868487695\n",
            "1.4964944748469757\n",
            "1.483497582047529\n",
            "1.4707561729824894\n",
            "1.4582625337909623\n",
            "1.4460092411392502\n",
            "1.4339891500709694\n",
            "1.422195382390644\n",
            "1.410621315550827\n",
            "1.3992605720176927\n",
            "1.3881070090933187\n",
            "1.3771547091733325\n",
            "1.366397970422014\n",
            "1.3558312978474767\n",
            "1.3454493947602753\n",
            "1.3352471546000024\n",
            "1.3252196531147042\n",
            "1.3153621408787353\n",
            "1.3056700361351523\n",
            "1.2961389179491587\n",
            "1.2867645196594029\n",
            "1.2775427226150593\n",
            "1.268469550185774\n",
            "1.2595411620332428\n",
            "1.250753848633349\n",
            "1.2421040260368577\n",
            "1.233588230859712\n",
            "1.2252031154911078\n",
            "1.2169454435113\n",
            "1.2088120853084523\n",
            "1.200800013886641\n",
            "1.192906300855328\n",
            "1.185128112593406\n",
            "1.1774627065783982\n",
            "1.1699074278749968\n",
            "1.162459705774492\n",
            "1.1551170505782384\n",
            "1.1478770505194738\n",
            "1.140737368816558\n",
            "1.1336957408514847\n",
            "1.1267499714685516\n",
            "1.119897932387261\n",
            "1.1131375597243651\n",
            "1.1064668516200744\n",
            "1.0998838659639962\n",
            "1.0933867182157149\n",
            "1.086973579316184\n",
            "1.0806426736856365\n",
            "1.0743922773042622\n",
            "1.0682207158716506\n",
            "1.062126363041727\n",
            "1.0561076387296948\n",
            "1.0501630074875659\n",
            "1.0442909769457964\n",
            "1.0384900963173744\n"
          ]
        }
      ],
      "source": [
        "and_.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxr4V4TSHn-F",
        "outputId": "5c461d4e-37d7-4df5-b562-66f9a1e34130"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "and_.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7QeczI5dCt_",
        "outputId": "d24f0ccb-0c29-443d-c6b6-6e971e784c67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "and_.score(X, y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "xQxcu94-Lhry"
      },
      "outputs": [],
      "source": [
        "nand_ = Perceptron(X, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI2wcSVnLncx",
        "outputId": "92832cb4-88ef-4c3e-e424-d28c38101e98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.0692602747513043\n",
            "2.810635498753689\n",
            "2.609400047557525\n",
            "2.453318384203718\n",
            "2.33182432935389\n",
            "2.2363525530126336\n",
            "2.160250388709887\n",
            "2.0984940407393795\n",
            "2.047356395142244\n",
            "2.0041010099746193\n",
            "1.9667295760757049\n",
            "1.9337856275871594\n",
            "1.904207171021988\n",
            "1.8772182550618162\n",
            "1.852250096084088\n",
            "1.828884039104162\n",
            "1.8068104066488835\n",
            "1.7857988145397896\n",
            "1.765676733294363\n",
            "1.7463139734429132\n",
            "1.7276114303293755\n",
            "1.7094928973683494\n",
            "1.6918990952109438\n",
            "1.6747833055293921\n",
            "1.6581081700349962\n",
            "1.6418433379928188\n",
            "1.625963733216846\n",
            "1.6104482744453357\n",
            "1.59527892828355\n",
            "1.580440006591507\n",
            "1.5659176438830522\n",
            "1.5516994075135422\n",
            "1.5377740059742746\n",
            "1.5241310697792203\n",
            "1.5107609861421025\n",
            "1.4976547735682115\n",
            "1.4848039861099245\n",
            "1.4722006397022234\n",
            "1.4598371549651616\n",
            "1.4477063123128666\n",
            "1.4358012162845886\n",
            "1.4241152668064965\n",
            "1.4126421356860006\n",
            "1.4013757470724437\n",
            "1.3903102609452982\n",
            "1.379440058928028\n",
            "1.3687597319057834\n",
            "1.358264069056764\n",
            "1.347948048004671\n",
            "1.3378068258727418\n",
            "1.3278357310748845\n",
            "1.318030255718051\n",
            "1.3083860485206542\n",
            "1.298898908174436\n",
            "1.2895647770932817\n",
            "1.2803797355042286\n",
            "1.2713399958467775\n",
            "1.262441897450854\n",
            "1.2536819014725056\n",
            "1.2450565860661975\n",
            "1.2365626417794804\n",
            "1.2281968671551633\n",
            "1.219956164528471\n",
            "1.2118375360101026\n",
            "1.2038380796434303\n",
            "1.1959549857285805\n",
            "1.188185533304695\n",
            "1.1805270867823139\n",
            "1.172977092719885\n",
            "1.1655330767366436\n",
            "1.1581926405563536\n",
            "1.1509534591752564\n",
            "1.1438132781496901\n",
            "1.1367699109966811\n",
            "1.129821236703166\n",
            "1.1229651973390589\n",
            "1.1161997957691165\n",
            "1.109523093459327\n",
            "1.1029332083738923\n",
            "1.0964283129579662\n",
            "1.0900066322033144\n",
            "1.0836664417926776\n",
            "1.0774060663194795\n",
            "1.071223877578969\n",
            "1.065118292928854\n",
            "1.0590877737152304\n",
            "1.0531308237614057\n",
            "1.0472459879168108\n",
            "1.0414318506633249\n",
            "1.0356870347766742\n",
            "1.0300102000400329\n",
            "1.0244000420082062\n",
            "1.0188552908195194\n",
            "1.0133747100539283\n",
            "1.0079570956351795\n",
            "1.002601274774831\n",
            "0.9973061049566778\n",
            "0.99207047295986\n",
            "0.98689329391858\n",
            "0.9817735104177456\n"
          ]
        }
      ],
      "source": [
        "nand_.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzhoaYPdLo_N",
        "outputId": "1a4e9d58-7d34-44d3-d237-ad4d72b4e387"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nand_.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "0X_jFsD_LqM-"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "SQqBmvpNdlz6"
      },
      "outputs": [],
      "source": [
        "X = load_breast_cancer()['data']\n",
        "y = load_breast_cancer()['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1NqmvONd0wb",
        "outputId": "de8b9aaf-832f-446c-faac-bdc37d17f123"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8531468531468531"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tree_model = DecisionTreeClassifier()\n",
        "tree_model.fit(X_train, y_train)\n",
        "tree_model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "xJ8_3l1wzILa"
      },
      "outputs": [],
      "source": [
        "X = np.array([[0,0],[1,0],[0, 1],[1, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "zxivgFNUeMEc"
      },
      "outputs": [],
      "source": [
        "class MultiLayer:\n",
        "  def __init__(self, x, y):\n",
        "    self.Activation = {\n",
        "        'sigmoid':sigmoid,\n",
        "    }\n",
        "    self.x = x\n",
        "    if y.ndim == 1:\n",
        "      y = y.reshape(-1, 1)\n",
        "    self.y = y\n",
        "    self.W1 = np.random.randn(2,2)\n",
        "    self.b1 = np.zeros(2)\n",
        "    self.W2 = np.random.randn(2,1)\n",
        "    self.b2 = np.zeros(1)\n",
        "\n",
        "  def predict_proba(self):\n",
        "\n",
        "    x = (self.x-self.x.min(0))/self.x.max(0)\n",
        "    self.y_hat = np.dot(x, self.W1) + self.b1\n",
        "    self.y_hat = self.Activation['sigmoid'](self.y_hat)\n",
        "    self.y_hat = np.dot(self.y_hat, self.W2) + self.b2\n",
        "    self.y_hat = self.Activation['sigmoid'](self.y_hat)\n",
        "    return self.y_hat\n",
        "\n",
        "\n",
        "  def loss(self):\n",
        "    result = self.predict_proba()\n",
        "    return -np.sum((1-self.y)*np.log(1-result)+self.y*np.log(result))\n",
        "\n",
        "  def gradient(self):\n",
        "    h = 1e-5\n",
        "    self.dW1 = np.zeros_like(self.W1)\n",
        "    self.dW2 = np.zeros_like(self.W2)\n",
        "    self.db1 = np.zeros_like(self.b1)\n",
        "    self.db2 = np.zeros_like(self.b2)\n",
        "    for row in range(self.W1.shape[0]):\n",
        "      for col in range(self.W1.shape[1]):\n",
        "        fx = self.loss()\n",
        "        tmp = self.W1[row,col]\n",
        "        self.W1[row,col] += h\n",
        "        fxh = self.loss()\n",
        "        self.dW1[row,col] = (fxh-fx)/h\n",
        "        self.W1[row,col] = tmp\n",
        "\n",
        "    for row in range(self.W2.shape[0]):\n",
        "      for col in range(self.W2.shape[1]):\n",
        "        fx = self.loss()\n",
        "        tmp = self.W2[row,col]\n",
        "        self.W2[row,col] += h\n",
        "        fxh = self.loss()\n",
        "        self.dW2[row,col] = (fxh-fx)/h\n",
        "        self.W2[row,col] = tmp\n",
        "\n",
        "    for i in range(self.b1.size):\n",
        "      fx = self.loss()\n",
        "      tmp = self.b1[i]\n",
        "      self.b1[i] += h\n",
        "      fxh = self.loss()\n",
        "      self.db1[i] = (fxh-fx)/h\n",
        "      self.b1[i] = tmp\n",
        "\n",
        "    for i in range(self.b2.size):\n",
        "      fx = self.loss()\n",
        "      tmp = self.b2[i]\n",
        "      self.b2[i] += h\n",
        "      fxh = self.loss()\n",
        "      self.db2[i] = (fxh-fx)/h\n",
        "      self.b2[i] = tmp\n",
        "\n",
        "    return self.dW1, self.dW2, self.db1, self.db2\n",
        "\n",
        "\n",
        "  def descent_gradient(self):\n",
        "    dW1, dW2, db1, db2 = self.gradient()\n",
        "    self.W1 -= dW1*1e-3\n",
        "    self.W2 -= dW2*1e-3\n",
        "    self.b1 -= db1*1e-3\n",
        "    self.b2 -= db2*1e-3\n",
        "\n",
        "\n",
        "  def fit(self, epochs=1000):\n",
        "    self.history = []\n",
        "    for _ in range(epochs):\n",
        "      self.descent_gradient()\n",
        "      self.history.append(self.descent_gradient())\n",
        "\n",
        "  def predict(self, x):\n",
        "    x = (x-x.min(0))/x.max(0)\n",
        "    result = np.dot(x, self.W1) + self.b1\n",
        "    result = self.Activation['sigmoid'](result)\n",
        "    result = np.dot(result, self.W2) + self.b2\n",
        "    result = self.Activation['sigmoid'](result)\n",
        "    return np.where(result > 0.5, 1, 0)\n",
        "\n",
        "  def score(self, x, y):\n",
        "    return np.sum(self.predict(x) == y)/x.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QvPN5NqvfCt7"
      },
      "outputs": [],
      "source": [
        "model = MultiLayer(X, y5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "y7j91LjtxuKQ"
      },
      "outputs": [],
      "source": [
        "model.fit(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MBamtu_4u-2",
        "outputId": "ea7d8577-4b83-4b8d-f995-1b7cc9d66036"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(X, y5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0oSFpz11W-p",
        "outputId": "bdf5eb16-3774-43f5-aa7f-52a008ff7b2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt_2b1g41e3b",
        "outputId": "b00feb57-942e-4512-f379-a38a867a6cc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-0.03424537,  0.00397677],\n",
              "        [-0.0559335 ,  0.00291456]]),\n",
              " array([[-0.0410735 ],\n",
              "        [ 0.01374139]]),\n",
              " array([0.00055935, 0.00247074]),\n",
              " array([0.03096127]))"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.gradient()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDhRiiIe5Rqw",
        "outputId": "de8ea50b-f050-4dd9-f7d3-a04959ac21a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.6885624976398272"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h8YKlIvX5U6-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(Dense(10, activation='sigmoid', input_shape=(100,)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1010 (3.95 KB)\n",
            "Trainable params: 1010 (3.95 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(Dense(250, activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                1010      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 250)               2750      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3760 (14.69 KB)\n",
            "Trainable params: 3760 (14.69 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<keras.src.layers.core.dense.Dense at 0x20ce60c9d10>,\n",
              " <keras.src.layers.core.dense.Dense at 0x20ce79621d0>]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense/kernel:0' shape=(100, 10) dtype=float32, numpy=\n",
              " array([[ 3.37091684e-02,  2.19384879e-01,  8.87590945e-02,\n",
              "         -2.68568844e-02, -4.82946783e-02, -2.04167962e-02,\n",
              "          1.45337999e-01, -1.68928146e-01,  2.02397555e-01,\n",
              "         -7.30796009e-02],\n",
              "        [ 1.38451010e-01,  1.33597940e-01, -2.09814757e-01,\n",
              "         -4.88116890e-02,  5.18701077e-02, -1.48471773e-01,\n",
              "          2.16540337e-01, -1.78644150e-01,  6.27817214e-02,\n",
              "          4.74732518e-02],\n",
              "        [ 2.10342079e-01, -5.50450236e-02, -5.03012538e-02,\n",
              "         -7.45198876e-02,  2.24905133e-01,  2.01874971e-02,\n",
              "          1.18953079e-01,  6.95732236e-03,  7.07140565e-03,\n",
              "          1.42148286e-01],\n",
              "        [-1.66094184e-01, -2.16126665e-01, -1.94315791e-01,\n",
              "          1.09314948e-01, -2.26435959e-01, -4.32715416e-02,\n",
              "         -1.25482261e-01,  2.06176281e-01,  7.07326531e-02,\n",
              "          9.72098708e-02],\n",
              "        [-7.16869235e-02,  1.60155863e-01, -1.31971061e-01,\n",
              "         -1.59498304e-01, -8.79688561e-02,  1.00891113e-01,\n",
              "          1.03126198e-01, -1.84610039e-02,  7.54588544e-02,\n",
              "         -5.31985909e-02],\n",
              "        [ 3.92016470e-02, -1.67502612e-02,  1.34267986e-01,\n",
              "          9.73861217e-02,  1.60358042e-01,  8.21006298e-03,\n",
              "          1.98199660e-01, -9.37580615e-02,  1.78804964e-01,\n",
              "         -1.09226011e-01],\n",
              "        [ 1.55877769e-01,  1.12000436e-01, -9.78230536e-02,\n",
              "         -1.07682824e-01, -2.23847941e-01, -3.09310108e-02,\n",
              "         -7.28570968e-02, -1.36027321e-01, -1.25775546e-01,\n",
              "          3.23348641e-02],\n",
              "        [-1.40995204e-01, -2.89642364e-02, -1.75397843e-02,\n",
              "         -1.71326458e-01, -5.23821712e-02,  1.37184858e-01,\n",
              "          8.28786790e-02,  5.39154410e-02, -1.59195393e-01,\n",
              "         -8.26452672e-02],\n",
              "        [ 2.02407628e-01,  1.67214960e-01,  8.00541341e-02,\n",
              "          2.32750416e-01, -1.03445157e-01, -2.20441669e-01,\n",
              "          7.56848752e-02, -1.08299851e-02,  2.32119560e-02,\n",
              "          1.10886455e-01],\n",
              "        [ 2.10641623e-02,  3.00187171e-02,  9.89879370e-02,\n",
              "          2.03370452e-01, -2.14312524e-01, -2.10983038e-01,\n",
              "          5.07133007e-02,  5.51347733e-02,  1.10610723e-02,\n",
              "         -6.99858814e-02],\n",
              "        [ 5.24847209e-03,  1.42475814e-01, -3.20886523e-02,\n",
              "         -1.69173390e-01, -1.74913198e-01,  1.85811847e-01,\n",
              "         -8.51659477e-03, -1.15456946e-01, -4.97679263e-02,\n",
              "         -4.18127775e-02],\n",
              "        [ 1.82398766e-01,  2.28096813e-01,  2.24409699e-02,\n",
              "         -9.08897966e-02,  7.30333924e-02,  2.18849182e-02,\n",
              "          1.31070614e-04,  2.80494988e-02, -1.63132876e-01,\n",
              "         -3.16905677e-02],\n",
              "        [ 5.79194129e-02, -4.33217734e-02, -2.32147768e-01,\n",
              "         -1.25835121e-01, -1.54717237e-01, -2.06573084e-01,\n",
              "         -4.76938039e-02, -1.76112354e-03,  1.94885820e-01,\n",
              "         -1.92306429e-01],\n",
              "        [ 1.69291466e-01,  6.31593764e-02, -1.69709548e-01,\n",
              "         -4.23775017e-02,  1.78504288e-01,  6.81096613e-02,\n",
              "         -5.18499017e-02, -2.32102439e-01,  5.05588353e-02,\n",
              "          1.15970075e-01],\n",
              "        [-1.08868249e-01, -2.21798718e-01, -2.32573301e-02,\n",
              "          9.00633037e-02,  1.15499824e-01,  1.22174710e-01,\n",
              "         -3.72583270e-02, -2.10500598e-01, -1.85539097e-01,\n",
              "         -4.19061631e-02],\n",
              "        [ 1.74041986e-01, -3.40590328e-02, -1.16396867e-01,\n",
              "         -9.30525064e-02, -1.24260753e-01, -1.14923172e-01,\n",
              "         -9.29739922e-02,  9.49257612e-02, -2.30251998e-02,\n",
              "         -7.90826827e-02],\n",
              "        [ 1.21378124e-01, -1.94009840e-02,  2.06564456e-01,\n",
              "          2.24053025e-01,  1.27840072e-01,  8.36855769e-02,\n",
              "          6.12973869e-02,  8.56043994e-02,  8.00922811e-02,\n",
              "          1.04779035e-01],\n",
              "        [-1.46627888e-01, -1.08685888e-01,  8.43009353e-02,\n",
              "         -1.74417838e-01, -1.36242151e-01,  9.23936069e-03,\n",
              "         -1.35884210e-01,  2.00887054e-01, -2.82606930e-02,\n",
              "         -7.46691823e-02],\n",
              "        [ 5.58480620e-02, -1.68347552e-01,  9.47303176e-02,\n",
              "         -5.82383573e-03,  1.28590137e-01,  7.43984878e-02,\n",
              "         -4.27705795e-02, -1.21030770e-01, -2.12219134e-01,\n",
              "          3.17923725e-02],\n",
              "        [-2.00024143e-01,  2.30065286e-02,  1.63698733e-01,\n",
              "         -1.72558382e-01,  5.92868030e-02, -6.72224164e-02,\n",
              "         -1.92068607e-01, -1.42693460e-01,  2.79825032e-02,\n",
              "         -1.83876693e-01],\n",
              "        [ 1.19843006e-01, -1.43689245e-01,  1.50474846e-01,\n",
              "         -1.19418152e-01,  2.14376658e-01, -1.98735267e-01,\n",
              "         -8.11100006e-03,  2.13242352e-01,  8.91014338e-02,\n",
              "         -2.24552214e-01],\n",
              "        [ 1.41158760e-01, -1.45032644e-01, -7.33854175e-02,\n",
              "          1.44375354e-01, -1.78062320e-01,  1.60307586e-01,\n",
              "         -1.26194447e-01,  6.80473447e-02, -1.88969150e-01,\n",
              "          1.82361305e-01],\n",
              "        [ 2.02541500e-01, -1.42955571e-01, -2.24722162e-01,\n",
              "         -1.91952229e-01, -1.89426422e-01,  1.13638699e-01,\n",
              "         -2.22331822e-01,  1.52932167e-01, -1.33061320e-01,\n",
              "          2.30006754e-01],\n",
              "        [ 1.96418822e-01, -1.72491223e-01, -1.42316103e-01,\n",
              "         -1.56508878e-01,  1.85354352e-01, -2.03486383e-01,\n",
              "         -1.08122945e-01, -2.04849273e-01,  6.95159733e-02,\n",
              "         -1.76076621e-01],\n",
              "        [ 1.89272285e-01, -6.76882565e-02, -1.84375063e-01,\n",
              "          1.02068931e-02,  8.06289315e-02, -1.63265571e-01,\n",
              "         -1.02837548e-01,  1.89733326e-01,  6.97812438e-02,\n",
              "         -2.17901707e-01],\n",
              "        [ 1.33972466e-01,  7.32391477e-02,  6.18638098e-02,\n",
              "          4.49425280e-02, -2.04265654e-01,  4.21516597e-02,\n",
              "         -6.98457211e-02,  2.09311545e-01,  1.29964918e-01,\n",
              "         -1.15168244e-02],\n",
              "        [ 8.25180113e-02,  3.41110826e-02,  1.56737894e-01,\n",
              "          3.33668888e-02, -8.37317407e-02, -8.87244940e-04,\n",
              "         -2.03449294e-01, -4.13978100e-03,  1.43432260e-01,\n",
              "          7.07291067e-03],\n",
              "        [-1.48853183e-01,  5.83216548e-02,  1.17797911e-01,\n",
              "          9.84514952e-02,  2.07414329e-01, -8.73728245e-02,\n",
              "         -2.19032615e-01, -1.93658903e-01,  1.28601611e-01,\n",
              "         -1.35781378e-01],\n",
              "        [ 1.21283561e-01,  6.87948763e-02, -7.60853440e-02,\n",
              "          1.57276511e-01,  1.56877041e-01, -8.26183110e-02,\n",
              "          1.93502605e-01,  6.20118082e-02, -1.58435762e-01,\n",
              "          4.54030335e-02],\n",
              "        [ 1.71253502e-01,  1.39616996e-01, -1.29393786e-01,\n",
              "         -2.28264123e-01, -6.53634965e-02, -2.19703928e-01,\n",
              "          1.35276884e-01,  1.91918761e-01, -1.19379893e-01,\n",
              "         -1.73916638e-01],\n",
              "        [-2.04943374e-01, -4.83564287e-02,  2.00338811e-01,\n",
              "         -3.58650386e-02,  6.39405251e-02, -2.16249719e-01,\n",
              "         -1.29678115e-01, -1.82538703e-01, -1.67275608e-01,\n",
              "          1.37169361e-01],\n",
              "        [ 1.30814701e-01, -1.33349434e-01,  2.31526613e-01,\n",
              "         -1.02771670e-02, -1.62704855e-01, -4.57770973e-02,\n",
              "         -7.14366287e-02,  1.41482890e-01,  1.67886883e-01,\n",
              "         -2.32751757e-01],\n",
              "        [-1.60696372e-01,  1.82060987e-01, -2.16339082e-02,\n",
              "         -1.34849906e-01, -1.75001949e-01, -2.41923034e-02,\n",
              "          2.02430427e-01, -7.84399509e-02,  7.57321715e-03,\n",
              "         -2.03962862e-01],\n",
              "        [-2.20704108e-01, -2.10485622e-01, -5.07795066e-02,\n",
              "         -9.11455452e-02, -2.17992812e-01,  3.92812490e-03,\n",
              "         -6.49383068e-02, -1.81681022e-01, -1.69578969e-01,\n",
              "         -1.06776640e-01],\n",
              "        [-5.46095818e-02, -1.62861198e-01,  1.42385602e-01,\n",
              "         -8.57602507e-02,  2.19909132e-01,  1.28270000e-01,\n",
              "         -1.33461863e-01, -2.13205993e-01,  2.03339726e-01,\n",
              "         -1.25276804e-01],\n",
              "        [-6.51300848e-02, -9.72548127e-02,  1.99265242e-01,\n",
              "         -2.12333009e-01,  1.23701245e-01, -2.86039710e-02,\n",
              "          6.20804131e-02, -7.84590989e-02, -1.80848405e-01,\n",
              "         -2.67869383e-02],\n",
              "        [-8.19144249e-02,  1.82780713e-01, -7.67048150e-02,\n",
              "         -8.95058066e-02, -2.01547295e-01,  3.87637019e-02,\n",
              "          2.79295444e-02, -1.99160904e-01,  1.20140612e-03,\n",
              "         -1.69260636e-01],\n",
              "        [-1.80252984e-01, -8.62007588e-02,  1.85866952e-01,\n",
              "          1.81565583e-01, -1.58118099e-01,  1.60304993e-01,\n",
              "          9.17284191e-02, -2.22173393e-01,  1.00083947e-02,\n",
              "          1.40961230e-01],\n",
              "        [ 1.65198147e-01,  2.37696171e-02, -8.03579837e-02,\n",
              "         -4.67985421e-02,  1.05001271e-01,  1.50088519e-02,\n",
              "          2.57914960e-02, -7.90998340e-02,  1.71601146e-01,\n",
              "         -2.19940752e-01],\n",
              "        [ 2.95800865e-02, -2.23618135e-01, -1.38864294e-01,\n",
              "         -9.99459475e-02, -1.50844842e-01, -5.59954643e-02,\n",
              "         -1.47439122e-01, -9.34326649e-03,  1.92376077e-02,\n",
              "          1.59672379e-01],\n",
              "        [-7.88820684e-02,  2.30380386e-01, -4.95306104e-02,\n",
              "          2.54949331e-02,  1.83717489e-01,  2.21698314e-01,\n",
              "          1.71978503e-01,  1.94694221e-01, -1.32442534e-01,\n",
              "         -1.85725421e-01],\n",
              "        [ 1.77034438e-01, -2.43326724e-02, -5.98385632e-02,\n",
              "         -9.89488363e-02,  2.58423984e-02,  1.42943710e-01,\n",
              "         -5.26748896e-02,  1.01684123e-01,  6.37871921e-02,\n",
              "          5.93822598e-02],\n",
              "        [ 1.36934876e-01, -1.31455958e-02, -1.46676615e-01,\n",
              "          1.04248106e-01, -9.26880538e-03,  2.33161747e-01,\n",
              "         -1.49804860e-01,  1.32133871e-01,  6.22448325e-03,\n",
              "          1.40647918e-01],\n",
              "        [ 1.94327205e-01, -1.07650027e-01, -7.70406425e-02,\n",
              "         -6.95339590e-02, -1.54427856e-01,  2.18853652e-01,\n",
              "          8.00592601e-02, -1.95729688e-01,  9.29921865e-02,\n",
              "         -1.23272441e-01],\n",
              "        [ 3.79033685e-02, -1.05663657e-01,  2.04443961e-01,\n",
              "         -1.48980647e-01, -2.54741758e-02, -1.12096891e-01,\n",
              "          1.66614324e-01, -6.83095604e-02,  2.02994764e-01,\n",
              "          1.53256446e-01],\n",
              "        [-1.03429571e-01,  2.77127326e-03,  5.26850224e-02,\n",
              "         -1.37333691e-01, -2.27349311e-01,  1.82104886e-01,\n",
              "          1.44743711e-01, -2.04685509e-01, -8.09425414e-02,\n",
              "          1.06949538e-01],\n",
              "        [ 7.60752261e-02,  2.06565857e-03,  3.88605893e-02,\n",
              "         -3.45581770e-02,  2.18883395e-01,  2.13191241e-01,\n",
              "          1.02037549e-01, -1.32635802e-01,  1.32227719e-01,\n",
              "         -1.41796872e-01],\n",
              "        [ 1.41877264e-01,  1.65720433e-01,  4.34579253e-02,\n",
              "          7.79764950e-02,  2.11195916e-01,  4.14673984e-03,\n",
              "         -2.59949714e-02,  1.92484260e-03, -1.47052109e-03,\n",
              "         -6.13772422e-02],\n",
              "        [ 9.47352350e-02,  1.19527340e-01,  2.01567888e-01,\n",
              "         -1.01946741e-01, -1.91308096e-01,  1.57825947e-01,\n",
              "         -1.20496780e-01, -1.80439353e-02,  8.51111114e-02,\n",
              "         -1.64465308e-01],\n",
              "        [-8.12240243e-02, -8.45963806e-02,  6.28108382e-02,\n",
              "         -1.73187539e-01, -4.73189503e-02, -1.22411199e-01,\n",
              "          8.95975232e-02,  6.29538894e-02,  1.40685946e-01,\n",
              "          1.74168169e-01],\n",
              "        [ 1.37804270e-01, -1.28051072e-01, -1.20533414e-01,\n",
              "          1.84613466e-02, -2.20684946e-01,  3.93311083e-02,\n",
              "          1.08094603e-01, -2.29881763e-01, -2.98351049e-04,\n",
              "         -1.28413439e-02],\n",
              "        [-2.01129109e-01, -1.09225065e-01,  1.97492480e-01,\n",
              "         -1.35327220e-01, -8.96275789e-02,  5.33965826e-02,\n",
              "          2.13120908e-01,  1.47630513e-01, -1.27205461e-01,\n",
              "         -1.01176366e-01],\n",
              "        [ 2.81991661e-02,  4.26920056e-02,  4.39094901e-02,\n",
              "         -2.08515242e-01, -2.33036339e-01,  7.47244060e-03,\n",
              "          3.44773233e-02, -1.46190897e-01, -2.37115920e-02,\n",
              "          2.35099196e-02],\n",
              "        [ 1.28790081e-01, -1.72056347e-01,  1.39355302e-01,\n",
              "          1.14646941e-01,  1.83530033e-01, -5.19057512e-02,\n",
              "          9.37972963e-03, -1.40271217e-01, -5.01978546e-02,\n",
              "          6.09164238e-02],\n",
              "        [ 1.19226784e-01, -1.88009515e-01,  1.38548791e-01,\n",
              "         -8.82629156e-02, -1.10957846e-01, -1.54878944e-02,\n",
              "         -8.90206397e-02, -1.87358752e-01, -1.37636542e-01,\n",
              "          2.13050932e-01],\n",
              "        [-1.70070812e-01,  2.12898403e-01, -1.17692493e-01,\n",
              "          1.78838044e-01,  2.16409206e-01,  1.54199451e-01,\n",
              "          1.95047349e-01, -3.79192829e-02, -2.28345394e-02,\n",
              "          9.56956446e-02],\n",
              "        [-1.32383227e-01,  1.31766200e-01, -1.67970136e-01,\n",
              "          1.30955577e-01,  5.36893010e-02,  2.04975843e-01,\n",
              "          2.13515699e-01, -2.11067557e-01,  2.20974505e-01,\n",
              "          2.12881595e-01],\n",
              "        [ 2.41161883e-03, -1.79222524e-01,  1.63496554e-01,\n",
              "          2.04229683e-01,  1.45847052e-01,  4.30395603e-02,\n",
              "         -1.55078381e-01,  8.22609961e-02, -1.06243268e-01,\n",
              "         -2.33440161e-01],\n",
              "        [ 1.36552602e-02, -9.42730606e-02, -2.96966881e-02,\n",
              "          1.13027900e-01, -9.31639820e-02,  3.64387929e-02,\n",
              "         -3.70449573e-02, -1.86017245e-01, -3.59012932e-02,\n",
              "          2.32289076e-01],\n",
              "        [-1.80246681e-02,  4.01932597e-02,  8.76449943e-02,\n",
              "         -1.28659278e-01, -1.75766468e-01, -3.98289710e-02,\n",
              "          1.29765540e-01,  3.14644575e-02, -1.72863752e-02,\n",
              "         -1.01362467e-01],\n",
              "        [ 2.59327590e-02,  1.61740035e-02, -1.35093018e-01,\n",
              "         -2.14246705e-01, -1.49161056e-01,  1.40988857e-01,\n",
              "          1.45934135e-01,  3.19218934e-02,  2.11673498e-01,\n",
              "          1.76331699e-02],\n",
              "        [-2.30270326e-02, -2.06654161e-01, -1.77529946e-01,\n",
              "          1.35604739e-01, -6.20756745e-02, -1.57471687e-01,\n",
              "         -1.49014771e-01,  1.19056612e-01, -1.48729414e-01,\n",
              "         -1.92002013e-01],\n",
              "        [-1.37356743e-01,  1.07418269e-01, -1.05673850e-01,\n",
              "          4.71078455e-02, -1.48790091e-01, -7.29764849e-02,\n",
              "          2.32824415e-01,  1.30835980e-01, -3.84739339e-02,\n",
              "          1.60805136e-02],\n",
              "        [-1.03911713e-01,  7.24009573e-02,  3.30180526e-02,\n",
              "          7.61771202e-02, -2.90288925e-02,  8.47887695e-02,\n",
              "         -2.19081238e-01,  7.25922287e-02, -9.81911123e-02,\n",
              "         -1.79943442e-03],\n",
              "        [-6.90909475e-02,  1.21896476e-01,  1.17395431e-01,\n",
              "          2.00885326e-01,  7.03629553e-02, -1.25821978e-02,\n",
              "         -1.75965279e-02,  8.68362188e-02, -8.21938366e-02,\n",
              "          3.52822542e-02],\n",
              "        [ 1.91967994e-01, -5.63948154e-02, -1.25053674e-01,\n",
              "          2.62203813e-02,  4.48251367e-02,  1.07296556e-01,\n",
              "          8.15111697e-02, -5.96109927e-02, -6.22313023e-02,\n",
              "         -1.86440498e-01],\n",
              "        [ 1.17017835e-01, -6.65117353e-02, -3.01301479e-04,\n",
              "         -5.70268780e-02,  1.01706982e-01,  9.30141509e-02,\n",
              "         -7.82664418e-02,  4.06340957e-02, -1.28620982e-01,\n",
              "         -2.01171651e-01],\n",
              "        [-1.85212523e-01,  9.55647230e-02,  1.47141844e-01,\n",
              "          1.57276362e-01, -1.92791983e-01, -2.05975175e-01,\n",
              "          5.70634007e-02, -1.94616139e-01,  7.30499625e-03,\n",
              "         -7.59576112e-02],\n",
              "        [-2.20698535e-01,  5.27590215e-02, -2.98118442e-02,\n",
              "          2.24468201e-01,  2.26535469e-01, -3.13542783e-03,\n",
              "         -1.84255838e-01,  1.88065410e-01,  1.21947199e-01,\n",
              "          3.15098166e-02],\n",
              "        [ 8.36029947e-02,  1.38679475e-01,  1.56668305e-01,\n",
              "          4.56622839e-02, -1.91670984e-01,  8.50725770e-02,\n",
              "          3.68673205e-02, -9.58113372e-03, -1.92085594e-01,\n",
              "          1.00792110e-01],\n",
              "        [-1.55305624e-01,  2.04655945e-01, -8.37942660e-02,\n",
              "         -1.68234795e-01,  2.08778501e-01,  1.99439824e-01,\n",
              "         -5.83780706e-02, -1.63234830e-01,  1.82966024e-01,\n",
              "         -1.09912798e-01],\n",
              "        [ 2.10855305e-01, -2.29284674e-01,  3.43628824e-02,\n",
              "         -1.77512348e-01,  1.48581415e-01,  6.90334439e-02,\n",
              "         -2.21184641e-02,  2.14150429e-01, -8.84892046e-02,\n",
              "          2.09030479e-01],\n",
              "        [ 1.85687929e-01, -1.01160169e-01, -1.28458500e-01,\n",
              "         -1.15869664e-01, -6.86089545e-02,  2.00989008e-01,\n",
              "          1.78341687e-01,  1.61975682e-01,  1.62968546e-01,\n",
              "         -1.82134166e-01],\n",
              "        [ 3.27938795e-02,  2.31903553e-01,  1.88939273e-02,\n",
              "         -1.31162554e-01,  1.46637350e-01,  1.86297446e-01,\n",
              "          4.99573350e-03, -5.48813045e-02, -1.49337903e-01,\n",
              "          2.46309638e-02],\n",
              "        [-2.62140781e-02, -1.94008917e-01,  1.77668989e-01,\n",
              "         -3.87426019e-02, -2.21088976e-01,  1.08100057e-01,\n",
              "         -1.17981538e-01,  7.25644827e-03,  8.05998147e-02,\n",
              "         -1.29811302e-01],\n",
              "        [ 4.46678996e-02,  1.73638225e-01,  1.97731465e-01,\n",
              "         -8.85307938e-02,  7.71848559e-02, -1.45599097e-01,\n",
              "          9.03399885e-02,  1.12747252e-01, -1.44649655e-01,\n",
              "          9.54319239e-02],\n",
              "        [ 2.01428801e-01,  1.96202040e-01,  1.92994207e-01,\n",
              "          8.24865103e-02, -1.98520333e-01, -9.20803398e-02,\n",
              "         -1.30090714e-02, -3.49816978e-02, -1.68242976e-01,\n",
              "         -1.14429824e-01],\n",
              "        [-9.62935388e-03, -1.77833691e-01,  1.12238646e-01,\n",
              "         -6.24167174e-02, -4.28239107e-02,  5.73123097e-02,\n",
              "         -3.97267342e-02,  1.52494341e-01, -8.96592587e-02,\n",
              "          1.41767025e-01],\n",
              "        [-1.95988998e-01, -8.18234980e-02, -2.09376648e-01,\n",
              "         -3.09041739e-02,  1.11931860e-01,  2.24305481e-01,\n",
              "         -2.11891890e-01,  2.04532534e-01, -1.29587561e-01,\n",
              "          9.83348191e-02],\n",
              "        [ 4.76978123e-02, -4.94515300e-02,  5.15591204e-02,\n",
              "         -2.06984416e-01, -1.79444581e-01,  1.24339610e-01,\n",
              "         -2.25240499e-01,  8.90366733e-02, -2.15671673e-01,\n",
              "         -1.44579858e-02],\n",
              "        [ 1.41838968e-01,  4.13466692e-02, -1.60215676e-01,\n",
              "         -1.86856240e-02,  5.17886877e-02, -1.42400742e-01,\n",
              "         -1.30431265e-01, -1.22227781e-01,  6.28347397e-02,\n",
              "         -1.27208710e-01],\n",
              "        [-5.36786765e-02,  1.32415414e-01, -4.22222167e-02,\n",
              "         -1.98327109e-01, -2.22375020e-01,  6.47093356e-02,\n",
              "          1.66661382e-01,  3.01316381e-02,  2.80178189e-02,\n",
              "         -4.88572866e-02],\n",
              "        [-1.44474864e-01,  2.08779573e-01,  1.37632132e-01,\n",
              "         -2.15024084e-01,  2.11797118e-01,  9.03264582e-02,\n",
              "          2.74270773e-02,  9.30139124e-02, -7.10915178e-02,\n",
              "         -1.56313822e-01],\n",
              "        [-2.12956965e-02,  1.44971877e-01,  1.45193517e-01,\n",
              "         -2.22045779e-01, -2.22939193e-01,  2.80246437e-02,\n",
              "         -5.74077964e-02, -6.15837127e-02,  1.79299325e-01,\n",
              "          2.15528697e-01],\n",
              "        [ 1.90861017e-01,  1.21159285e-01, -1.91308379e-01,\n",
              "          1.99037939e-01, -6.52679503e-02, -1.21245541e-01,\n",
              "          1.67658985e-01, -9.05006230e-02, -1.77602112e-01,\n",
              "         -2.32128382e-01],\n",
              "        [-1.02622613e-01,  1.01765215e-01, -2.20791578e-01,\n",
              "         -1.72136247e-01, -8.29156041e-02, -6.47224784e-02,\n",
              "          7.59713650e-02,  2.21532166e-01,  1.05863631e-01,\n",
              "         -1.86341256e-02],\n",
              "        [-2.29222149e-01,  1.22946501e-03, -2.30081379e-01,\n",
              "         -3.40151489e-02,  1.02817774e-01, -1.58929944e-01,\n",
              "          1.09057397e-01, -1.87185362e-01,  1.83486521e-01,\n",
              "          1.80641204e-01],\n",
              "        [-6.79951906e-03, -2.10030302e-01,  1.07621908e-01,\n",
              "          2.13573277e-01,  6.50964379e-02, -8.96080881e-02,\n",
              "         -1.66834146e-01, -1.52194366e-01,  2.24559724e-01,\n",
              "         -3.91066074e-02],\n",
              "        [-1.07952550e-01, -3.42195630e-02,  3.01857591e-02,\n",
              "         -4.97189164e-03, -1.96355611e-01, -1.14640191e-01,\n",
              "         -1.63768560e-01,  1.95028633e-01,  1.47906989e-01,\n",
              "         -1.39038518e-01],\n",
              "        [-1.14724331e-01, -2.14705646e-01, -7.27747977e-02,\n",
              "         -3.66583467e-02, -5.80713153e-03, -6.92076087e-02,\n",
              "         -1.09506041e-01, -4.46863472e-03,  2.21180409e-01,\n",
              "          2.07228750e-01],\n",
              "        [ 2.19167203e-01,  4.34500575e-02,  2.32902050e-01,\n",
              "         -1.63501158e-01, -1.82829350e-02, -9.55441892e-02,\n",
              "         -1.61206156e-01, -3.01271230e-02, -1.35559291e-02,\n",
              "         -2.01713771e-01],\n",
              "        [ 4.28215265e-02, -1.56210810e-01, -2.06893817e-01,\n",
              "          2.02419221e-01,  1.40582651e-01,  1.79784685e-01,\n",
              "         -3.73304933e-02, -1.49897844e-01,  9.94609594e-02,\n",
              "          1.85573280e-01],\n",
              "        [ 2.30357021e-01,  2.01888353e-01, -8.65926594e-02,\n",
              "         -2.09022343e-01, -1.06660321e-01,  9.67729390e-02,\n",
              "         -1.77271634e-01, -1.57101169e-01,  1.07297659e-01,\n",
              "          1.79670483e-01],\n",
              "        [-2.84596980e-02, -1.38343766e-01,  8.62970948e-02,\n",
              "         -2.94475704e-02,  1.27551317e-01, -1.25440121e-01,\n",
              "         -1.41352415e-01, -1.20744064e-01, -3.19005549e-02,\n",
              "          9.65204239e-02],\n",
              "        [ 9.26904976e-02,  1.14845932e-02,  7.39483535e-02,\n",
              "         -1.35698065e-01, -3.37997675e-02,  1.23974204e-01,\n",
              "         -1.44935519e-01,  1.19601011e-01, -1.00240961e-01,\n",
              "          1.02021635e-01],\n",
              "        [ 1.28218442e-01,  1.07464045e-01, -7.87660778e-02,\n",
              "          4.53737378e-02, -3.70585918e-02, -6.42331392e-02,\n",
              "          1.78715885e-01, -1.15848005e-01,  5.72059453e-02,\n",
              "         -6.56432509e-02],\n",
              "        [ 1.96988612e-01,  2.02825934e-01,  1.03608876e-01,\n",
              "         -7.98638612e-02,  1.59670711e-01,  3.83320153e-02,\n",
              "         -2.31198549e-01,  2.01672405e-01, -4.39842790e-02,\n",
              "          1.26999676e-01],\n",
              "        [-6.74193650e-02, -1.12542294e-01,  8.68990719e-02,\n",
              "          1.91311449e-01,  1.68859661e-02, -1.65712327e-01,\n",
              "         -9.52147692e-02,  7.35645592e-02,  1.60058856e-01,\n",
              "         -9.75640714e-02],\n",
              "        [-1.35393083e-01, -1.65024072e-01, -2.59223580e-02,\n",
              "          1.75464690e-01,  1.69522732e-01,  5.85085452e-02,\n",
              "         -2.30260402e-01,  3.10553610e-02,  1.46951288e-01,\n",
              "         -1.61080629e-01],\n",
              "        [ 1.43017769e-01,  8.87628198e-02, -1.19645558e-01,\n",
              "          9.05621052e-02,  8.73140693e-02,  1.00668609e-01,\n",
              "         -6.04141057e-02, -2.33133793e-01, -2.06073388e-01,\n",
              "         -2.27938220e-01]], dtype=float32)>,\n",
              " <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[0].weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x20cecf5ffd0>"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_categorical(y_train).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(-1, 28*28)\n",
        "y_train = to_categorical(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(Dense(100, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4783 - accuracy: 0.8718\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3086 - accuracy: 0.9071\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2745 - accuracy: 0.9153\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2449 - accuracy: 0.9243\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2362 - accuracy: 0.9273\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2300 - accuracy: 0.9272\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2107 - accuracy: 0.9342\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2044 - accuracy: 0.9361\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1926 - accuracy: 0.9399\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1817 - accuracy: 0.9438\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1741 - accuracy: 0.9458\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1696 - accuracy: 0.9465\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1669 - accuracy: 0.9469\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1607 - accuracy: 0.9491\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1536 - accuracy: 0.9519\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1470 - accuracy: 0.9539\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1392 - accuracy: 0.9567\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1382 - accuracy: 0.9567\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1334 - accuracy: 0.9580\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1313 - accuracy: 0.9588\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1308 - accuracy: 0.9591\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1283 - accuracy: 0.9598\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1304 - accuracy: 0.9589\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1252 - accuracy: 0.9604\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1168 - accuracy: 0.9625\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1190 - accuracy: 0.9625\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1231 - accuracy: 0.9604\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1187 - accuracy: 0.9624\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1119 - accuracy: 0.9649\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1109 - accuracy: 0.9650\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1120 - accuracy: 0.9645\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1167 - accuracy: 0.9627\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1158 - accuracy: 0.9631\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1082 - accuracy: 0.9658\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1029 - accuracy: 0.9667\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1073 - accuracy: 0.9663\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1086 - accuracy: 0.9659\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1071 - accuracy: 0.9658\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1035 - accuracy: 0.9669\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1019 - accuracy: 0.9676\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1001 - accuracy: 0.9678\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0996 - accuracy: 0.9679\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0955 - accuracy: 0.9694\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0938 - accuracy: 0.9698\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0944 - accuracy: 0.9699\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0950 - accuracy: 0.9701\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0905 - accuracy: 0.9712\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0918 - accuracy: 0.9698\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0953 - accuracy: 0.9698\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0927 - accuracy: 0.9707\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0901 - accuracy: 0.9709\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0880 - accuracy: 0.9714\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0889 - accuracy: 0.9715\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0878 - accuracy: 0.9713\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0874 - accuracy: 0.9716\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0877 - accuracy: 0.9716\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0871 - accuracy: 0.9716\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0871 - accuracy: 0.9719\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9736\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0806 - accuracy: 0.9739\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0813 - accuracy: 0.9735\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0814 - accuracy: 0.9741\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0821 - accuracy: 0.9730\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0848 - accuracy: 0.9719\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0847 - accuracy: 0.9726\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0864 - accuracy: 0.9719\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0870 - accuracy: 0.9710\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0843 - accuracy: 0.9721\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0848 - accuracy: 0.9726\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0792 - accuracy: 0.9746\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0763 - accuracy: 0.9750\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9762\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0750 - accuracy: 0.9755\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0757 - accuracy: 0.9750\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0759 - accuracy: 0.9747\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0750 - accuracy: 0.9754\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0742 - accuracy: 0.9761\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0742 - accuracy: 0.9762\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0732 - accuracy: 0.9761\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0679 - accuracy: 0.9777\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0707 - accuracy: 0.9768\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0737 - accuracy: 0.9754\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0757 - accuracy: 0.9759\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0685 - accuracy: 0.9776\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0682 - accuracy: 0.9768\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0695 - accuracy: 0.9775\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0714 - accuracy: 0.9767\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0719 - accuracy: 0.9760\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0731 - accuracy: 0.9759\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0741 - accuracy: 0.9754\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0715 - accuracy: 0.9766\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0691 - accuracy: 0.9776\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0673 - accuracy: 0.9773\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0687 - accuracy: 0.9772\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0669 - accuracy: 0.9778\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0651 - accuracy: 0.9793\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0699 - accuracy: 0.9768\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0726 - accuracy: 0.9759\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0710 - accuracy: 0.9765\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0709 - accuracy: 0.9767\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x20cffa83550>"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1 = Sequential(\n",
        "    [\n",
        "        Dense(256, activation='sigmoid', input_shape=(784,)),\n",
        "        Dense(100, activation='sigmoid'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def linear(x):\n",
        "    return x\n",
        "\n",
        "def relu(x):\n",
        "    return np.where(x > 0, x, 0)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return (1-np.exp(x))/(1+np.exp(x))\n",
        "\n",
        "def softmax(x):\n",
        "    x -= np.max(x,1).reshape(x.shape[0], -1)\n",
        "    return np.exp(x)/np.sum(np.exp(x),1).reshape(x.shape[0], -1)\n",
        "# def softmax(x):\n",
        "#     exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "#     softmax_values = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "    \n",
        "#     return softmax_values\n",
        "\n",
        "def rmse(y_hat, y):\n",
        "    return np.mean(np.square(y_hat - y))\n",
        "\n",
        "def binary_crossentropy(y_hat, y):\n",
        "    epsilon = 1e-7\n",
        "    return -np.mean((1-y)*np.log(1-y_hat+epsilon) + y*np.log(y_hat+epsilon))\n",
        "\n",
        "def categorical_crossentropy(y_hat, y):\n",
        "    epsilon = 1e-7\n",
        "    return -np.mean(y*np.log(y_hat+epsilon))\n",
        "\n",
        "def make_onehot(x):\n",
        "    result = np.zeros((x.size, np.max(x)+1))\n",
        "    for idx, val in enumerate(x):\n",
        "        result[idx, val] = 1\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.09003057, 0.24472847, 0.66524096],\n",
              "       [1.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([[1,2,3],[1000,5,6]])\n",
        "softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 's' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[191], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# s = time()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m e \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m----> 4\u001b[0m (e \u001b[38;5;241m-\u001b[39m \u001b[43ms\u001b[49m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m\n",
            "\u001b[1;31mNameError\u001b[0m: name 's' is not defined"
          ]
        }
      ],
      "source": [
        "from time import time\n",
        "# s = time()\n",
        "e = time()\n",
        "(e - s)/1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SequentialModel:\n",
        "    def __init__(self,x,y,output_shape,activation='linear'):\n",
        "        self.activation_dic = {\n",
        "            'linear':linear,\n",
        "            'sigmoid':sigmoid,\n",
        "            'relu':relu,\n",
        "            'softmax':softmax\n",
        "        }\n",
        "        self.loss_func_dic = {\n",
        "            'rmse':rmse,\n",
        "            'binary_crossentropy':binary_crossentropy,\n",
        "            'categorical_crossentropy':categorical_crossentropy\n",
        "        }\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.activation = [activation]\n",
        "        self.W = [[np.random.randn(self.x.shape[1],output_shape),\n",
        "                  np.zeros(output_shape)]]\n",
        "        self.dW = [[np.zeros((self.x.shape[1],output_shape)),\n",
        "                  np.zeros(output_shape)]]\n",
        "    def add(self,output,activation='linear'):\n",
        "        self.input = self.W[-1][0].shape[1]\n",
        "        self.W.append([np.random.randn(self.input,output),np.zeros(output)])\n",
        "        self.dW.append([np.zeros((self.input,output)),np.zeros(output)])\n",
        "        self.activation.append(activation)\n",
        "    \n",
        "    def predict(self):\n",
        "        self.y_hat = self.x.copy()\n",
        "        for i in range(len(self.W)):\n",
        "            self.y_hat = np.dot(self.y_hat,self.W[i][0]) + self.W[i][1]\n",
        "            self.y_hat = self.activation_dic[self.activation[i]](self.y_hat)\n",
        "        return self.y_hat\n",
        "    \n",
        "    def compile(self,loss):\n",
        "        self.loss_func = self.loss_func_dic[loss]\n",
        "    \n",
        "    def summary(self):\n",
        "        print(\"-------------------------\")\n",
        "        print(\" Output Shape     Param #\")\n",
        "        print(\"=========================\")\n",
        "        self.total_params = 0\n",
        "        for W in self.W:\n",
        "            print(f'(None, {W[0].shape[1]})   {W[0].shape[0]*W[0].shape[1] + W[0].shape[1]:^}\\n')\n",
        "            self.total_params += (W[0].shape[0]*W[0].shape[1] + W[0].shape[1])\n",
        "        print(\"=========================\")\n",
        "        print(f\"total parameters = {self.total_params}\")\n",
        "        \n",
        "    def loss(self):\n",
        "        s = time()\n",
        "        y_hat = self.predict()\n",
        "        y = self.y\n",
        "        self.loss_val = self.loss_func(y_hat, y)\n",
        "        e = time()\n",
        "        self.predict_elapse = (e-s)\n",
        "        self.forword_elapse = self.predict_elapse*self.total_params*2\n",
        "        return self.loss_val\n",
        "    \n",
        "    def gradient(self):\n",
        "        h = 1e-5\n",
        "        weight = 0\n",
        "        bias = 1\n",
        "        \n",
        "        for layer in range(len(self.W)):\n",
        "            rows = self.W[layer][weight].shape[0]\n",
        "            cols = self.W[layer][weight].shape[1]\n",
        "            for row in range(rows):\n",
        "                for col in range(cols):\n",
        "                    fx = self.loss()\n",
        "                    self.W[layer][weight][row,col] += h\n",
        "                    fxh = self.loss()\n",
        "                    self.dW[layer][weight][row, col] = (fxh-fx)/h\n",
        "                    self.W[layer][weight][row,col] -= h\n",
        "            for b_idx in range(self.W[layer][bias].size):\n",
        "                fx = self.loss()\n",
        "                self.W[layer][bias][b_idx] += h\n",
        "                fxh = self.loss()\n",
        "                self.dW[layer][bias][b_idx] = (fxh-fx)/h\n",
        "                self.W[layer][bias][b_idx] -= h    \n",
        "        \n",
        "    \n",
        "    def descent_gradient(self,lr=1e-3):\n",
        "        self.lr = lr\n",
        "        weight = 0\n",
        "        bias = 1\n",
        "        layers = range(len(self.W))\n",
        "        self.gradient()\n",
        "        for layer in layers:\n",
        "            self.W[layer][weight] -= self.dW[layer][weight]*self.lr\n",
        "            self.W[layer][bias] -= self.dW[layer][bias]*self.lr\n",
        "        \n",
        "    def fit(self,lr,epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"{epoch+1}  =============================\")\n",
        "            self.descent_gradient(lr)\n",
        "            print(f\"{epoch+1} loss ============================= {self.loss()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SequentialModel(np.random.randn(100, 20), np.random.randn(100, 5), output_shape=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(300, 'sigmoid')\n",
        "model.add(150, 'relu')\n",
        "model.add(5, 'softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile('categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1410648524107128"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1410648524107128"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.loss_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Dense(100, activation='relu', input_shape=(10,)))\n",
        "model1.add(Dense(40))\n",
        "model1.add(Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 100)               1100      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 40)                4040      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 3)                 123       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5263 (20.56 KB)\n",
            "Trainable params: 5263 (20.56 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = np.random.randint(0, 4, 100)\n",
        "y_one = make_onehot(y)\n",
        "model = SequentialModel(np.random.randn(100, 10), y_one, 100)\n",
        "model.add(40, activation='relu')\n",
        "model.add(4, activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile('categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------\n",
            " Output Shape     Param #\n",
            "=========================\n",
            "(None, 100)   1100\n",
            "\n",
            "(None, 40)   4040\n",
            "\n",
            "(None, 4)   164\n",
            "\n",
            "=========================\n",
            "total parameters = 5304\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(epochs=2, lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.04229098158027"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test,y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.cumprod(X_train.shape[1:])[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_ = X_train.reshape(-1, 28*28)\n",
        "X_test_ = X_test.reshape(-1, 28*28)\n",
        "y_train_ = to_categorical(y_train)\n",
        "y_test_ = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1 = Sequential()\n",
        "input_layer = Dense(256, activation='relu', input_shape=(784,))\n",
        "layer1 = Dense(128, activation='relu')\n",
        "output_layer = Dense(10, activation='softmax')\n",
        "model1.add(input_layer)\n",
        "model1.add(layer1)\n",
        "model1.add(output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.9083 - accuracy: 0.8745\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4271 - accuracy: 0.9223\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3995 - accuracy: 0.9310\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3806 - accuracy: 0.9360\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4013 - accuracy: 0.9361\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3992 - accuracy: 0.9377\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4013 - accuracy: 0.9406\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4111 - accuracy: 0.9357\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4285 - accuracy: 0.9378\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4366 - accuracy: 0.9359\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x18e1b1dc2d0>"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.fit(X_train_, y_train_, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.9299\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6904891133308411, 0.9298999905586243]"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.evaluate(X_test_, y_test_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235146 (918.54 KB)\n",
            "Trainable params: 235146 (918.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = SequentialModel(X_train_, y_train_, 256,activation='relu' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.add(128, activation='relu')\n",
        "model2.add(10, activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.compile(loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[190], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[169], line 89\u001b[0m, in \u001b[0;36mSequentialModel.fit\u001b[1;34m(self, lr, epochs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m,lr,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 89\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescent_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[169], line 82\u001b[0m, in \u001b[0;36mSequentialModel.descent_gradient\u001b[1;34m(self, lr)\u001b[0m\n\u001b[0;32m     80\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     81\u001b[0m layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW))\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[layer][weight] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdW[layer][weight]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr\n",
            "Cell \u001b[1;32mIn[169], line 64\u001b[0m, in \u001b[0;36mSequentialModel.gradient\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rows):\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cols):\n\u001b[1;32m---> 64\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[layer][weight][row,col] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m h\n\u001b[0;32m     66\u001b[0m         fxh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss()\n",
            "Cell \u001b[1;32mIn[169], line 49\u001b[0m, in \u001b[0;36mSequentialModel.loss\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 49\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_func(y_hat, y)\n",
            "Cell \u001b[1;32mIn[169], line 31\u001b[0m, in \u001b[0;36mSequentialModel.predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW)):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[i][\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[i][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_dic\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat\n",
            "Cell \u001b[1;32mIn[148], line 5\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrelu\u001b[39m(x):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model2.fit(lr=1e-3, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = SequentialModel(X_train_, y_train_, 256,activation='relu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.add(128,activation='relu')\n",
        "model2.add(10,activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.compile(loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------\n",
            " Output Shape     Param #\n",
            "=========================\n",
            "(None, 256)   200960\n",
            "\n",
            "(None, 128)   32896\n",
            "\n",
            "(None, 10)   1290\n",
            "\n",
            "=========================\n",
            "total parameters = 235146\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.4893041917071164"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7061557769775391"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.predict_elapse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "332099.4126663208"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.forword_elapse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.random.randn(100000, 1000)\n",
        "w = np.random.randn(1000, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = np.random.randint(0, 1, 100000).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100000, 1)"
            ]
          },
          "execution_count": 226,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss(x, y):\n",
        "    epsilon = 1e-7\n",
        "    y_hat = np.dot(x, w)\n",
        "    y_hat = sigmoid(y_hat)\n",
        "    y_hat += epsilon\n",
        "    return -np.mean((1-y)*np.log(1-y_hat)+y*np.log(y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_87364\\2501666218.py:6: RuntimeWarning: invalid value encountered in log\n",
            "  return -np.mean((1-y)*np.log(1-y_hat)+y*np.log(y_hat))\n"
          ]
        }
      ],
      "source": [
        "s = time()\n",
        "dW = np.zeros_like(w)\n",
        "h = 1e-5\n",
        "rows = range(w.shape[0])\n",
        "cols = range(w.shape[1])\n",
        "\n",
        "for row in rows:\n",
        "    for col in cols:\n",
        "        fx = loss(x, y)\n",
        "        w[row, col] += h\n",
        "        fxh = loss(x, y)\n",
        "        dW[row, col] = (fxh-fx)/h\n",
        "        w[row, col] -= h\n",
        "e = time()\n",
        "elapse = e - s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "84.93325901031494"
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elapse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 1)"
            ]
          },
          "execution_count": 230,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dW.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_87364\\4257694624.py:2: RuntimeWarning: divide by zero encountered in log\n",
            "  output = -((1-y)*np.log(1-sigmoid(np.dot(x, w))) + y*np.log(sigmoid(np.dot(x, w))))\n"
          ]
        }
      ],
      "source": [
        "s = time()\n",
        "epsilon = 1e-7\n",
        "y_hat = sigmoid(np.dot(x, w))\n",
        "output = -((1-y)*np.log(1-y_hat+epsilon) + y*np.log(y_hat+epsilon))\n",
        "output = (sigmoid(output*1)*(1-sigmoid(output*1)))\n",
        "dX = np.dot(x.T, output)\n",
        "dW = np.dot(output, w.T)\n",
        "e = time()\n",
        "elapse_back = e - s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.412905216217041"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elapse_back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "205.6967450991714"
            ]
          },
          "execution_count": 238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elapse / elapse_back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 1.        ],\n",
              "       [0.21194156, 0.21194156, 0.57611688]])"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = np.array([[1,1,10000],[0,0,1]])\n",
        "softmax(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def linear(x):\n",
        "    return x\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.where(x>0,x,0)\n",
        "\n",
        "def tanh(x):\n",
        "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "\n",
        "# def softmax(x):\n",
        "#     x -= np.max(x,1).reshape(x.shape[0], -1)\n",
        "#     return np.exp(x)/np.sum(np.exp(x),1).reshape(x.shape[0], -1)\n",
        "# def softmax(x):\n",
        "#     exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "#     softmax_values = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "#     return softmax_values\n",
        "# def softmax(x):\n",
        "#     m = np.max(x,1).reshape(-1,1)\n",
        "#     c = x - m\n",
        "#     return np.exp(c)/np.sum(np.exp(c),1).reshape(-1,1)\n",
        "\n",
        "\n",
        "def rmse(y,y_hat):\n",
        "    return np.sqrt(np.mean(np.square(y-y_hat))) \n",
        "\n",
        "def binary_crossentropy(y,y_hat):\n",
        "    epsilon = 1e-7\n",
        "    return -np.mean((1-y)*np.log(1-y_hat+epsilon)+y*np.log(y_hat+epsilon))\n",
        "\n",
        "def categorical_crossentropy(y,y_hat):\n",
        "    epsilon = 1e-7\n",
        "    return -np.mean(y*np.log(y_hat+epsilon))\n",
        "\n",
        "def make_onehot(x):\n",
        "    result = np.zeros((x.size, np.max(x)+1))\n",
        "    for idx, val in enumerate(x):\n",
        "        result[idx, val] = 1\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "        \n",
        "    def forward(self,x):\n",
        "        return sigmoid(x)\n",
        "    \n",
        "    def backward(self,out):\n",
        "        dout = sigmoid(out)*(1-sigmoid(out))\n",
        "        return dout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReLU:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "    \n",
        "    def forward(self,x):\n",
        "        out = relu(x)\n",
        "        self.out = np.where(out>0,1,0)\n",
        "        return out\n",
        "        \n",
        "    def backward(self,out):\n",
        "        dout = self.out*out\n",
        "        return dout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Affine:\n",
        "    def __init__(self,w,b):\n",
        "        self.x = None\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "    \n",
        "    def forward(self,x):\n",
        "        self.x = x\n",
        "        self.out = np.dot(self.x,self.w) + self.b\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self,out):\n",
        "        self.dout = np.dot(out,self.w.T)#4,2\n",
        "        self.dW = np.dot(self.x.T,out)#2,5\n",
        "        self.db = np.sum(out,axis=0)#5\n",
        "        return self.dout    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Tanh:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "    \n",
        "    def forward(self,x):\n",
        "        return tanh(x)\n",
        "    \n",
        "    def backward(self,out):\n",
        "        dout = 1 - tanh(out)**2\n",
        "        return dout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.special import softmax as sx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "        self.y = None\n",
        "        self.y_hat = None\n",
        "        \n",
        "    def forward(self,x):\n",
        "        self.y_hat = sx(x, axis=1)\n",
        "        return self.y_hat\n",
        "    \n",
        "    def backward(self,y):\n",
        "        self.y = y\n",
        "        self.dout = (self.y_hat - self.y)/len(self.y)\n",
        "        return self.dout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigdiff(x):\n",
        "    return sigmoid(x)*(1-sigmoid(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = Sigmoid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.random.randn(3, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.56267131, 0.4013676 ],\n",
              "       [0.50809525, 0.42446157],\n",
              "       [0.47748601, 0.29274697]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "out = np.dot(s.forward(x), np.random.randn(2, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.24149717, 0.22191635],\n",
              "       [0.23967271, 0.22859352],\n",
              "       [0.24586912, 0.22795343]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.backward(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.array([[-5, 6], [2, 0], [-2, 3]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[0, 6],\n",
              "        [2, 0],\n",
              "        [0, 3]]),\n",
              " array([[0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1]]))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r = ReLU()\n",
        "r.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "dx = np.array([[100, -5], [-7, -7], [7, 10]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0, -5],\n",
              "       [-7,  0],\n",
              "       [ 0, 10]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r.backward(dx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "aff = Affine(np.random.randn(2, 5), np.zeros(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.38943362,  0.28096509,  1.66746912, -2.53166792,  1.29685724],\n",
              "       [ 0.27396675, -0.12862694, -0.36546848,  0.73702316, -0.60270728],\n",
              "       [ 0.14347556,  0.40175305,  5.2967082 , -6.70867056,  1.78850131],\n",
              "       [-0.9121753 ,  0.3823106 ,  0.6792196 , -1.75893874,  1.8006003 ]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aff.forward(np.random.randn(4, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 3.06397093,  1.53188906],\n",
              "       [ 1.89635172, -2.07023843],\n",
              "       [ 0.66255773,  2.3849432 ],\n",
              "       [-0.60099146, -4.89483662]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aff.backward(np.random.randn(4, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4, 2), (2, 5), (5,))"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aff.dout.shape, aff.dW.shape, aff.db.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net:\n",
        "    def __init__(self,input_shape):\n",
        "        self.x = None\n",
        "        self.y = None\n",
        "        self.input_shape = input_shape\n",
        "        self.layers = []\n",
        "        self.activation_dic = {\n",
        "            'relu':ReLU,\n",
        "            'sigmoid':Sigmoid,\n",
        "            'softmax':SoftmaxWithLoss,\n",
        "            'tanh':Tanh\n",
        "        }\n",
        "        self.grad = None\n",
        "        \n",
        "    def add(self,output_shape,activation):\n",
        "        if len(self.layers) == 0:\n",
        "            w = np.random.randn(self.input_shape,output_shape)\n",
        "            b = np.zeros(output_shape)\n",
        "            activation = self.activation_dic.get(activation)\n",
        "            self.layers.append([w,b,activation])\n",
        "        else:\n",
        "            input_shape = self.layers[-1][0].shape[1]\n",
        "            w = np.random.randn(input_shape,output_shape)\n",
        "            b = np.zeros(output_shape)\n",
        "            activation = self.activation_dic.get(activation)\n",
        "            self.layers.append([w,b,activation])\n",
        "    \n",
        "    def _build(self):\n",
        "        self.W = {}\n",
        "        for i, layer in enumerate(self.layers,1):\n",
        "            w = layer[0]\n",
        "            b = layer[1]\n",
        "            activation = layer[2]\n",
        "            self.W['Affine_'+str(i)] = Affine(w,b)\n",
        "            self.W['Activation_'+str(i)] = activation()\n",
        "        return f'Building Success!!'\n",
        "    \n",
        "    def compile(self,lr,loss,metrics):\n",
        "        loss_func_dic = {\n",
        "            'rmse':rmse,\n",
        "            'binary_crossentorpy':binary_crossentropy,\n",
        "            'categorical_crossentropy':categorical_crossentropy\n",
        "        } \n",
        "        \n",
        "        metrics_dic ={\n",
        "            'accuracy':'accuracy',\n",
        "            'rmse':'rmse'\n",
        "        }\n",
        "        \n",
        "        self.loss_func = loss_func_dic[loss]\n",
        "        self.metrics = metrics_dic[metrics]\n",
        "        self.lr = lr\n",
        "        \n",
        "    \n",
        "    def predict(self,x):\n",
        "        if self.grad == None:\n",
        "            self._build()\n",
        "        self.y_hat = x\n",
        "        for k, v in self.W.items():\n",
        "            self.y_hat = v.forward(self.y_hat)\n",
        "        return self.y_hat\n",
        "    \n",
        "    def gradient(self,x,y):\n",
        "        self.y_hat = self.predict(x)\n",
        "        self.y = y\n",
        "        self.grad = {}\n",
        "        last_layer = list(self.W.keys())[-1]\n",
        "        out = self.W.get(last_layer).backward(self.y)\n",
        "        for key in list(self.W.keys())[::-1]:\n",
        "            out = self.W.get(key).backward(out)\n",
        "        \n",
        "        idx = 1\n",
        "        for key in self.W.keys():\n",
        "            if 'Affine' in key:\n",
        "                self.grad['W'+str(idx)] = self.W.get(key).dW\n",
        "                self.grad['b'+str(idx)] = self.W.get(key).db\n",
        "                idx += 1\n",
        "                \n",
        "        return self.grad\n",
        "        \n",
        "    def loss(self,x,y):\n",
        "        y_hat = self.predict(x)\n",
        "        loss_val = categorical_crossentropy(y,y_hat)\n",
        "        accuracy = np.sum(np.argmax(y_hat,1) == np.argmax(y,1))/len(y)\n",
        "        return [accuracy, loss_val]        \n",
        "    \n",
        "    def summary(self):\n",
        "        total_parameters = 0\n",
        "        if self.grad == None:\n",
        "            self._build()\n",
        "        print(\"==============================================\")\n",
        "        print(\"-------------Output Shape---------param #------\")\n",
        "        for idx, layer in enumerate(self.layers,1):\n",
        "            print(f'----Affine_{idx}------(None, {layer[0].shape[1]}),-------{np.prod(layer[0].shape)}----')\n",
        "            total_parameters += np.prod(layer[0].shape) + layer[0].shape[1]\n",
        "        print(\"==============================================\")\n",
        "        print(f\"Total Parmerter # ---- {total_parameters}\")\n",
        "    \n",
        "    def fit(self,x,y,epochs=10):\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            self.grad = self.gradient(x,y)\n",
        "            print(f'{epoch+1} ====================> accuracy : {self.loss(x,y)[0]} loss : {self.loss(x,y)[1]}')\n",
        "            for idx, _ in enumerate(self.layers,1):\n",
        "                self.W.get('Affine_'+str(idx)).w -= self.lr*self.grad['W'+str(idx)]\n",
        "                self.W.get('Affine_'+str(idx)).b -= self.lr*self.grad['b'+str(idx)]\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Net(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(100, activation='Relu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[array([[ 4.50796424e-01, -5.00929339e-01,  2.05825472e+00,\n",
              "          -3.80416321e-01, -1.20361746e+00, -1.04143371e+00,\n",
              "           3.45821278e-01,  7.24775494e-01, -6.39350169e-01,\n",
              "           3.18077223e-01, -1.33124096e+00, -2.88492404e-01,\n",
              "           3.21537676e-01, -2.28877113e-02, -8.39977121e-01,\n",
              "           1.18586716e+00, -8.40727375e-01,  7.86241628e-01,\n",
              "           2.43817777e-01, -9.75119155e-01,  4.27529387e-01,\n",
              "          -5.10860857e-01, -5.82651088e-02,  4.12936912e-01,\n",
              "          -6.05740690e-01, -8.63884275e-01, -9.13760874e-01,\n",
              "           1.29221210e+00,  3.26497394e-01,  1.77356315e+00,\n",
              "          -4.81318687e-01,  1.26198024e-01, -5.01955485e-01,\n",
              "           1.38014738e+00,  1.44837732e+00,  1.08275830e-01,\n",
              "           8.93125771e-01,  1.18508747e+00, -1.13657461e+00,\n",
              "          -8.68016149e-01, -6.19008931e-01, -7.92826412e-01,\n",
              "          -4.99150532e-01,  1.71336134e+00,  3.18261551e-01,\n",
              "          -1.85403023e+00, -9.01099647e-01, -7.88068883e-01,\n",
              "           8.41074354e-01,  2.72980614e-01, -6.65741589e-01,\n",
              "          -2.30075048e+00,  1.04472660e+00,  9.04476057e-01,\n",
              "           4.92809224e-01,  7.68232100e-02,  4.91132593e-01,\n",
              "           1.42418669e+00, -1.70899439e+00, -2.44435102e-01,\n",
              "          -1.30888292e+00, -3.22853663e-01,  4.42702255e-01,\n",
              "          -1.99976829e+00,  9.48789253e-01,  4.52543339e-01,\n",
              "          -1.73096696e+00,  1.67797903e-01,  2.27028205e-01,\n",
              "           2.00604077e+00,  7.39723270e-01,  1.59512080e+00,\n",
              "          -7.84946509e-01, -1.82326759e+00,  9.39864346e-01,\n",
              "          -1.28294237e+00, -8.18123536e-01, -4.88809277e-01,\n",
              "          -2.34981944e-01, -1.50403048e+00,  2.20903582e-01,\n",
              "           2.92921377e-01, -5.90718982e-01,  9.55667022e-02,\n",
              "           3.57904680e-01, -1.80559899e-01, -2.14231840e+00,\n",
              "          -5.09110706e-01, -5.39365112e-01,  4.04602641e-01,\n",
              "          -8.27804480e-01,  4.73763137e-01,  2.12331764e-01,\n",
              "          -1.33853853e+00, -1.53705133e+00,  1.32166334e-01,\n",
              "           5.54221034e-01, -9.47282259e-01,  1.73892483e+00,\n",
              "           4.37692367e-01],\n",
              "         [ 5.72836580e-03, -1.33370754e+00, -1.68431474e+00,\n",
              "           1.40176978e+00, -6.61861347e-01, -9.47474136e-01,\n",
              "          -4.76178782e-01,  3.34384051e-01,  4.48444589e-01,\n",
              "          -7.09255300e-01, -1.08186241e+00, -1.21989080e+00,\n",
              "          -7.25651372e-01, -8.07168976e-02, -9.42809092e-01,\n",
              "           6.30981655e-01,  6.84267642e-01, -2.89603652e-01,\n",
              "          -4.87140011e-01, -1.10599503e+00,  3.54697494e-02,\n",
              "          -1.10888019e-02,  2.36174793e-02,  1.52224909e+00,\n",
              "           1.04576745e+00,  2.73407213e+00, -9.44413889e-01,\n",
              "           1.03667019e+00, -5.36750601e-01,  1.28890389e+00,\n",
              "           1.39602286e+00, -7.51315732e-01, -1.04368975e+00,\n",
              "          -4.93087090e-01,  6.50482734e-01,  5.10839619e-02,\n",
              "          -4.64188029e-02, -8.25586220e-02,  7.91322152e-01,\n",
              "          -4.72315099e-01, -2.10992450e+00, -2.73366429e-01,\n",
              "           4.38015120e-01, -1.36173108e+00, -1.50553292e+00,\n",
              "           5.88287558e-01, -1.20822387e+00, -3.35540767e-01,\n",
              "           1.03392762e+00,  1.37373079e+00, -4.33550384e-02,\n",
              "           6.32229056e-01, -4.89790543e-02, -7.79913274e-01,\n",
              "           3.12483751e-03, -1.90781866e+00,  1.87080508e-02,\n",
              "          -8.06640706e-01,  8.94565242e-01, -9.84166499e-01,\n",
              "          -9.46000261e-02,  9.97142188e-01,  1.28641757e+00,\n",
              "           1.68652315e+00,  1.48897882e+00,  6.82600316e-01,\n",
              "          -2.26168769e-01,  5.54876890e-01, -1.24346794e+00,\n",
              "           8.74622332e-01, -5.26932316e-01,  1.49705569e+00,\n",
              "          -1.23316540e+00, -1.41602524e-01, -3.58399530e-01,\n",
              "           3.85309299e-01, -1.44132259e+00, -1.22820038e+00,\n",
              "           5.87280983e-01,  3.25925336e-01, -1.29390911e+00,\n",
              "          -9.90836281e-01,  5.02915726e-01, -5.70537442e-01,\n",
              "          -1.77362146e+00, -2.02395463e+00, -7.82939301e-01,\n",
              "          -2.12572742e-01, -7.79944584e-03,  2.65111433e-01,\n",
              "           7.83193654e-01,  6.38360029e-01, -2.21579258e+00,\n",
              "          -3.53321948e-02,  8.37204631e-02,  6.21962345e-01,\n",
              "           2.19676964e-01, -2.99293112e-01, -5.09476512e-03,\n",
              "          -7.18333243e-01],\n",
              "         [-5.37435466e-01,  4.56354712e-01, -1.22101786e+00,\n",
              "          -1.06501373e+00, -6.59630491e-01,  5.06010104e-01,\n",
              "          -2.00640398e-01,  2.07498673e-01, -3.27447621e-01,\n",
              "           2.38431241e+00,  6.55890840e-02, -1.19881580e+00,\n",
              "          -8.96664509e-01,  9.34107351e-01, -3.82017048e-01,\n",
              "          -4.87057333e-01,  5.28042339e-02, -1.00884544e+00,\n",
              "           9.51273341e-02,  6.95174987e-01,  5.44766831e-02,\n",
              "           3.35483400e-01, -1.05534530e+00,  2.20360883e-02,\n",
              "          -5.40390733e-01, -1.16358603e+00,  5.45301961e-01,\n",
              "          -9.37756711e-01,  2.26176670e-01, -6.60477630e-01,\n",
              "          -2.56575243e-02, -7.35405692e-01,  6.16616274e-02,\n",
              "           1.81212519e+00,  6.03171566e-01,  1.53065217e-02,\n",
              "           3.21310337e-02,  3.20590508e-01,  7.93103913e-01,\n",
              "           1.51161025e+00,  3.07725874e-01,  7.69588569e-01,\n",
              "           9.39385356e-01,  1.96292077e+00, -1.55165024e+00,\n",
              "           1.48571182e+00,  1.72951929e-01,  4.78635505e-01,\n",
              "          -7.99115658e-02, -3.89054959e-01,  1.60849155e+00,\n",
              "          -5.77963179e-01, -1.87511803e-01,  1.95110634e-01,\n",
              "          -5.19218693e-01, -1.48339172e-02,  2.63710438e-01,\n",
              "           1.11336846e+00, -1.08619733e+00, -8.80351564e-01,\n",
              "           4.19729894e-01, -6.82854256e-01, -5.97554433e-01,\n",
              "           1.55450231e+00,  5.91975434e-02,  1.92632306e-01,\n",
              "          -8.06096769e-01,  4.71697303e-01, -9.04999421e-01,\n",
              "          -5.68372068e-01,  4.86944910e-01, -5.74947220e-01,\n",
              "           5.81778490e-01,  9.55093015e-01,  2.34081916e-01,\n",
              "          -4.07730051e-01,  6.29362661e-01,  5.89117617e-01,\n",
              "           3.59804627e-01, -1.70632765e-01,  1.44611324e+00,\n",
              "           9.52888732e-01, -1.19918449e+00,  6.44755343e-01,\n",
              "           1.60377231e+00, -6.30362915e-01, -5.24373336e-01,\n",
              "          -3.80277756e-01,  1.66641160e+00, -1.91730948e+00,\n",
              "           6.63161006e-01, -1.37693422e+00,  3.54418078e-01,\n",
              "           1.10740336e+00, -2.07121393e-01,  5.53103151e-01,\n",
              "          -1.33801088e+00,  2.26826137e+00, -1.89549836e+00,\n",
              "           3.62688165e-01],\n",
              "         [ 2.35760754e-02,  7.99555784e-01, -8.39994036e-01,\n",
              "          -1.25397359e+00, -2.13312231e+00, -1.05989093e-01,\n",
              "          -1.02744579e+00,  8.53344025e-01, -2.92539579e-01,\n",
              "           1.22961827e+00, -9.68321861e-01, -3.15023525e-01,\n",
              "           4.20098930e-01,  6.83701290e-01, -2.27477075e+00,\n",
              "          -1.03257609e-01,  1.02464094e+00,  2.97205794e-01,\n",
              "          -5.84601463e-03,  1.07560779e+00,  2.82596920e-01,\n",
              "          -8.77885855e-01, -1.01781209e+00,  6.01954672e-01,\n",
              "          -2.37799373e-01,  1.18314460e+00, -1.39870629e+00,\n",
              "           1.01281511e+00,  7.22294764e-01, -9.35321948e-01,\n",
              "           7.93894686e-01, -6.65366935e-01, -1.04250159e+00,\n",
              "           8.10424180e-01,  5.01441939e-01, -7.54485704e-01,\n",
              "          -1.08377909e+00,  2.42702692e-01,  5.73774757e-01,\n",
              "          -1.32574435e+00, -8.96542171e-01,  1.79828807e+00,\n",
              "          -3.37906755e-01,  8.15939171e-02,  6.19146429e-01,\n",
              "          -1.36092717e+00, -8.79581148e-01,  1.06810370e+00,\n",
              "          -6.07114549e-01,  1.12031595e-01, -1.20167866e+00,\n",
              "           3.56442605e-01, -1.35151743e+00,  1.89800088e+00,\n",
              "           4.68153026e-01, -1.19371290e+00,  6.21917697e-02,\n",
              "          -6.35281621e-01,  9.67145033e-01,  1.74020365e-01,\n",
              "          -1.01089869e+00,  7.34459268e-01,  6.74669710e-02,\n",
              "          -7.24455183e-01, -2.17824533e+00,  1.16224496e+00,\n",
              "           2.44620474e+00,  9.97066964e-02, -7.46471093e-01,\n",
              "           3.33057268e-01, -1.97036640e-01,  1.26541646e+00,\n",
              "           1.16125446e+00, -6.90463886e-01,  1.03235737e+00,\n",
              "           1.64868847e+00, -1.14015691e+00,  1.53478186e+00,\n",
              "          -1.18529364e+00, -3.66262850e-01,  1.96062618e-01,\n",
              "           9.06306674e-01,  2.10587661e-01, -1.39871944e+00,\n",
              "          -1.15880507e-01, -1.23896438e+00,  2.92696833e-01,\n",
              "          -2.06472009e-01, -1.34952031e+00,  5.33331987e-01,\n",
              "          -1.34506470e+00, -8.41420449e-01, -2.74652382e-01,\n",
              "           1.17148241e+00, -1.08356558e+00, -4.52225450e-01,\n",
              "          -9.40606071e-01,  9.57827766e-01,  6.04098747e-01,\n",
              "          -6.10966490e-01],\n",
              "         [ 1.38856151e-02,  6.03419494e-01,  1.21763768e+00,\n",
              "          -8.45463356e-01, -2.67843545e-01,  7.73456541e-01,\n",
              "           1.22731551e+00, -1.08954473e+00, -4.57404192e-01,\n",
              "          -1.54971666e+00,  8.98546469e-01, -3.80338366e-01,\n",
              "          -7.83126835e-01,  1.44662521e-02, -2.54788335e-01,\n",
              "           1.17846832e+00, -6.33349496e-01, -3.46283288e-01,\n",
              "          -1.38458416e+00,  8.38591351e-02,  8.06968457e-01,\n",
              "           1.28957145e+00,  4.77738237e-01, -3.72561452e-01,\n",
              "          -8.14557035e-01,  3.34525782e-01,  8.92769879e-01,\n",
              "          -1.24634128e+00,  1.17919721e+00,  1.42451395e-01,\n",
              "          -5.31868945e-01,  5.15431176e-01, -4.77976336e-01,\n",
              "          -3.29998990e-01,  8.08689809e-01,  1.08068169e+00,\n",
              "          -2.01932385e-01,  1.13426022e+00, -1.04693343e+00,\n",
              "          -6.45246717e-01, -1.07953795e+00,  8.24057970e-01,\n",
              "          -1.39516690e+00, -7.88832482e-01,  7.17286738e-01,\n",
              "           1.92354477e+00,  1.63608083e-01, -7.19421669e-01,\n",
              "           2.26126839e+00,  4.64922685e-01, -8.69271525e-02,\n",
              "           8.03738364e-01, -6.21639352e-01, -1.16023391e+00,\n",
              "           8.46636367e-01, -1.34798233e+00,  4.35443425e-01,\n",
              "           1.17958037e+00, -2.46591361e-01,  6.07791213e-01,\n",
              "           7.85642735e-01, -2.87091110e-01,  8.87639998e-01,\n",
              "          -4.92764888e-01, -1.18111202e+00, -1.13320237e+00,\n",
              "          -1.65474759e+00, -4.76680344e-01, -1.03908413e+00,\n",
              "           5.32695866e-01, -1.10320245e-02,  9.99225481e-01,\n",
              "           9.26739075e-02,  2.14485193e+00,  6.21865669e-01,\n",
              "           9.38893385e-01, -1.81720665e+00,  8.67950064e-01,\n",
              "          -5.72426717e-01, -1.60876113e-03,  1.08882181e+00,\n",
              "           1.94326636e-01, -1.59534280e+00,  1.16682251e+00,\n",
              "           4.30436834e-01,  3.64528612e-01, -9.31239025e-01,\n",
              "           1.01043421e-01, -1.49146857e+00,  1.04422099e+00,\n",
              "           7.97149745e-01,  5.41716309e-01,  1.71928576e+00,\n",
              "          -2.87411547e-01,  1.60420912e-01,  4.15300545e-01,\n",
              "          -2.57736367e-01,  5.72539672e-01,  1.42740064e+00,\n",
              "          -2.93186145e-01],\n",
              "         [-1.84147784e-01, -5.53370895e-02, -1.31441510e+00,\n",
              "           3.38784271e-01, -2.25359824e+00, -1.57553093e+00,\n",
              "           9.63648309e-02, -1.16600611e+00,  2.40254072e-01,\n",
              "           1.29770471e-01,  5.92458862e-02,  1.07355932e+00,\n",
              "           1.06511447e+00,  1.62551561e+00, -7.61962748e-01,\n",
              "           3.33584924e-01,  1.66867269e-01, -6.14554298e-02,\n",
              "           2.41499286e-01, -6.14785975e-01, -5.68061776e-01,\n",
              "           6.55507199e-01, -1.06323009e+00,  1.97483142e+00,\n",
              "          -6.95411680e-01, -6.69723795e-01,  3.95151204e-01,\n",
              "          -1.73674470e+00, -2.70894595e-01,  1.14813337e+00,\n",
              "          -6.57463572e-02, -2.50783046e-01, -3.74928366e-01,\n",
              "           5.96210349e-01, -1.11044317e+00, -2.52608299e+00,\n",
              "          -6.91408804e-01, -7.28922027e-01, -1.44912881e+00,\n",
              "          -1.62663931e+00,  8.08531486e-01, -6.16361085e-01,\n",
              "           1.82809532e-01,  4.94264336e-03, -2.71646694e+00,\n",
              "          -1.06921036e+00,  6.72898971e-01, -1.72084092e+00,\n",
              "           7.37559663e-01,  3.01715728e-01, -1.69295508e+00,\n",
              "           9.18822964e-04,  5.54924978e-01,  4.85542385e-01,\n",
              "           3.51005605e-01,  1.53289490e+00,  1.24575235e+00,\n",
              "          -3.59545664e-02,  6.04545344e-01, -5.45342334e-01,\n",
              "           1.00287437e-01, -5.66847755e-01,  5.49321716e-01,\n",
              "           5.30234856e-01, -5.91669248e-02,  5.52778766e-01,\n",
              "          -9.72537908e-02, -1.84089757e-01,  6.84994260e-01,\n",
              "          -2.41674846e-01,  9.12270931e-02, -2.06611409e+00,\n",
              "          -5.75797088e-01,  8.61749946e-01, -3.89963074e-01,\n",
              "          -1.14331623e+00, -5.66248353e-01,  4.33673985e-01,\n",
              "           3.16496099e-01,  1.04916074e+00,  2.59455511e-01,\n",
              "           2.31645917e+00, -8.01472734e-01, -1.74473347e+00,\n",
              "          -1.47692969e+00,  1.78699615e+00, -3.77179480e-01,\n",
              "           4.57076715e-01,  4.17665503e-02, -1.69567835e+00,\n",
              "          -4.83395430e-03, -2.68106086e-01,  9.22597216e-01,\n",
              "           1.48406866e-01, -9.25772290e-01,  3.75899591e-01,\n",
              "          -8.83534553e-01, -4.85259282e-01, -1.11029251e+00,\n",
              "          -1.72043612e+00],\n",
              "         [ 3.62103803e-01, -2.09692876e+00, -7.68750591e-01,\n",
              "          -1.90257906e+00,  7.65421006e-01,  1.30633511e+00,\n",
              "          -1.18498720e+00,  7.74561312e-01, -8.50587920e-01,\n",
              "           4.84649031e-01,  3.48067777e-01, -3.12425432e-03,\n",
              "           2.37694821e-01, -1.67555264e-01,  2.29732171e+00,\n",
              "          -4.31797034e-01, -1.01302010e+00, -1.16358823e-01,\n",
              "           1.84464138e-03,  4.61554705e-01, -5.68484350e-01,\n",
              "          -9.34468356e-01, -6.67091867e-01, -1.85744464e-01,\n",
              "          -2.86501455e+00,  6.46737808e-02, -4.85099737e-01,\n",
              "          -6.05419371e-01, -2.03343068e+00, -5.28415062e-01,\n",
              "          -1.96237704e+00,  6.20445626e-02,  7.00458320e-02,\n",
              "          -1.00506731e+00, -9.57764156e-01,  3.77826068e-01,\n",
              "          -1.03296981e+00, -9.64840565e-01,  8.04539120e-01,\n",
              "           9.36118655e-01, -1.08140642e+00,  1.55910641e+00,\n",
              "          -3.75029772e-03, -1.07937636e-01, -1.09084903e+00,\n",
              "           2.29597946e-01,  8.05519670e-01, -3.42376868e-01,\n",
              "           7.53131974e-01, -4.45146635e-01, -3.64819538e-01,\n",
              "           3.88442038e-01, -1.98864524e+00,  5.92639386e-01,\n",
              "          -7.37038009e-03, -1.03844147e+00, -2.68423396e+00,\n",
              "           2.03324525e+00, -1.36699666e-01, -9.42680894e-01,\n",
              "           8.19528694e-01, -8.69000445e-01,  1.54273050e-01,\n",
              "           1.52697254e+00, -6.21670156e-01, -7.33575061e-01,\n",
              "           6.45763932e-01, -7.35031161e-02, -4.68786965e-01,\n",
              "          -9.33656792e-01,  1.56207912e+00,  3.18858272e-01,\n",
              "           5.04921161e-01, -2.17239511e-01,  2.03765152e+00,\n",
              "           2.17992149e-01,  5.39805929e-03, -3.63176954e-01,\n",
              "           8.69725018e-01, -1.83893431e+00,  4.81021510e-01,\n",
              "           1.10102541e-01, -1.44134532e+00, -2.25823641e-01,\n",
              "           1.94402359e+00,  8.01699739e-01, -1.20294861e+00,\n",
              "           7.53189535e-01,  1.25368736e+00, -8.66195927e-01,\n",
              "           4.65659860e-01, -1.42661016e+00,  5.88263570e-02,\n",
              "          -1.44402489e+00,  1.61492663e+00,  3.06727744e-01,\n",
              "          -1.56741603e+00,  2.32832385e-01,  1.42783344e-01,\n",
              "          -3.26372292e-01],\n",
              "         [-1.00764608e+00, -1.02154574e+00,  1.19122071e-01,\n",
              "          -1.84047178e-02, -1.65406587e-01,  1.03672504e+00,\n",
              "           1.50030218e+00,  1.79358503e-01,  1.70361216e-03,\n",
              "           2.41682496e-01,  2.82877901e-02,  1.09157788e+00,\n",
              "          -7.97977706e-01,  2.37428552e-01, -8.81212168e-01,\n",
              "          -6.25878849e-01,  9.62470175e-01, -1.19144793e+00,\n",
              "           1.94329964e+00,  2.18933858e-01,  3.34212513e-02,\n",
              "          -3.13312704e-01, -3.53534832e-01, -1.49399201e+00,\n",
              "          -1.04858246e+00, -2.81571839e+00,  6.16557842e-01,\n",
              "           4.36060685e-01,  6.99235478e-01,  5.64751909e-01,\n",
              "           2.01097607e+00,  1.76613500e-01, -4.57208694e-01,\n",
              "           2.21832885e+00, -9.87271646e-02, -7.15156964e-02,\n",
              "           6.96928566e-01,  1.65954127e+00,  1.45765453e+00,\n",
              "          -6.19279776e-01,  9.65654358e-01,  9.46048634e-02,\n",
              "          -2.49034282e+00, -4.55147331e-01,  1.45473348e+00,\n",
              "           5.77086149e-01,  6.85874802e-01,  3.86316035e-01,\n",
              "          -2.26580493e-01,  6.72157156e-01,  2.18288176e+00,\n",
              "           4.04284750e-01, -1.25029969e+00,  6.74309941e-01,\n",
              "          -2.33850271e-01, -5.49918345e-01,  2.00206850e+00,\n",
              "           5.98065096e-02, -9.62552820e-01,  2.03385531e+00,\n",
              "          -1.11661715e+00,  1.66124165e+00,  2.62376020e-01,\n",
              "           1.91541515e-01,  5.65576745e-02, -6.03386077e-01,\n",
              "          -7.85190562e-01,  6.22891934e-01,  1.87833581e-01,\n",
              "           8.31710029e-01,  1.10195106e+00,  5.87657155e-01,\n",
              "          -7.96715422e-01, -1.27551694e+00, -1.02068513e+00,\n",
              "          -5.55680253e-01,  1.20945836e+00,  2.40596014e-01,\n",
              "           6.26581676e-01,  1.12861343e+00,  3.06967987e-01,\n",
              "           1.00047041e+00,  7.78410127e-01, -6.11595203e-01,\n",
              "           6.04118868e-01,  1.16534517e+00,  1.30608147e-01,\n",
              "          -7.82334715e-01, -8.24023895e-01, -1.28774200e+00,\n",
              "           3.99883736e-01,  1.57470530e+00,  6.41508412e-01,\n",
              "           3.34966302e+00, -1.02467746e+00, -1.12434767e-01,\n",
              "          -1.35724187e+00,  2.85762354e-01, -1.07910566e+00,\n",
              "          -1.23422773e+00],\n",
              "         [-5.98966259e-01, -9.96267875e-01, -8.97340107e-01,\n",
              "          -6.93688523e-01,  2.13316455e+00,  1.81073455e+00,\n",
              "          -5.93220129e-01,  6.49601203e-01, -4.48252703e-01,\n",
              "           9.37261044e-01, -1.02824850e+00, -8.99497617e-01,\n",
              "          -1.37441503e-01, -4.90480204e-01,  1.04703965e+00,\n",
              "           8.26723081e-01,  6.89208287e-01, -1.47511813e-01,\n",
              "          -2.60838325e+00, -3.76601930e-01,  1.92950044e+00,\n",
              "           3.52090519e-01, -1.59583305e+00, -1.30607607e+00,\n",
              "           6.15655021e-01,  1.35546705e-01,  9.00868618e-01,\n",
              "          -6.17666385e-01, -8.31041390e-01, -1.56631964e-01,\n",
              "          -8.36055605e-02, -7.53421890e-01, -1.21461093e+00,\n",
              "          -6.94815789e-01,  8.85826695e-01, -1.61553067e+00,\n",
              "          -2.10450836e+00,  2.99986552e-01, -5.38686902e-01,\n",
              "          -1.42449325e+00, -9.88130523e-01,  5.89182452e-01,\n",
              "           1.41032754e+00, -1.12222748e+00,  2.30979952e-01,\n",
              "           7.03358407e-01,  6.50096821e-01, -1.02484527e+00,\n",
              "          -7.27743967e-01,  4.85820509e-01, -5.40331308e-01,\n",
              "          -2.46939827e+00, -9.19515485e-01, -2.27102706e-01,\n",
              "          -8.30727007e-01,  1.04676881e+00, -4.69621484e-01,\n",
              "          -5.41333299e-01,  2.37181242e+00,  1.60917490e+00,\n",
              "          -3.37663656e-01, -2.59805294e-01,  6.81037281e-01,\n",
              "          -8.82945974e-01, -6.46315172e-01,  1.10136758e+00,\n",
              "          -2.08677975e-01, -5.66203732e-01,  6.22846759e-01,\n",
              "          -7.43333447e-01, -1.08448371e+00,  5.30500971e-01,\n",
              "          -3.14103061e-01, -1.45817375e-01, -2.64887377e-01,\n",
              "           1.55352980e+00, -1.13409549e+00,  5.27633914e-01,\n",
              "          -6.42263517e-01,  6.28858029e-01,  5.82930305e-01,\n",
              "          -4.39033090e-01,  2.86920814e-01,  8.63657341e-01,\n",
              "           3.31213007e-01, -2.66328706e-01,  1.56738477e-02,\n",
              "           2.07533338e-01, -1.49273920e+00,  9.84332731e-01,\n",
              "          -8.37892009e-01,  2.22889882e-01, -8.54903722e-01,\n",
              "          -3.57317979e-01, -3.78710119e-01,  2.14758093e-01,\n",
              "           3.92721719e-02,  1.47018513e+00,  7.68911634e-02,\n",
              "          -5.23735960e-01],\n",
              "         [ 1.52689900e+00,  5.80139388e-01, -1.45250915e+00,\n",
              "           3.04326665e-01, -1.48022921e-01,  5.29201094e-01,\n",
              "          -7.05801673e-02,  1.64077954e+00, -4.62713687e-01,\n",
              "          -1.72598768e+00,  8.51112280e-01,  3.61190811e-01,\n",
              "           6.19965287e-01,  3.72407196e-01,  1.80553859e-01,\n",
              "           3.20682050e-01,  1.07477471e+00,  1.96279730e+00,\n",
              "          -1.46564146e-01,  2.13000509e-01, -2.39787961e-01,\n",
              "          -1.63599541e+00, -5.28327539e-01, -9.53227336e-01,\n",
              "          -2.42357721e+00, -1.54309303e+00, -1.39710457e-01,\n",
              "          -2.43429978e-01, -4.44449529e-01, -3.70690571e-01,\n",
              "          -6.91289250e-01, -1.27013538e+00, -8.39056237e-01,\n",
              "           2.44753407e-01,  1.01081959e+00,  1.19771890e+00,\n",
              "           1.50991252e+00, -1.22528152e+00,  1.28174613e+00,\n",
              "           5.58427209e-01, -2.78876491e-01,  1.09619078e+00,\n",
              "           6.22916720e-01,  1.29296454e+00,  6.43853563e-01,\n",
              "          -5.86299027e-01, -8.21423113e-02, -5.59538395e-01,\n",
              "           1.79292534e-01,  7.19261547e-02,  1.14513886e-01,\n",
              "           8.88374746e-01, -7.72490175e-01,  2.10379733e-02,\n",
              "          -1.04193443e+00, -7.96628267e-01, -2.84186799e+00,\n",
              "          -1.27410526e+00, -7.96590628e-01,  2.67031898e-01,\n",
              "          -1.36664594e+00,  8.66947410e-01,  8.70016264e-01,\n",
              "          -6.77990222e-01,  2.87149682e-01,  6.72594732e-01,\n",
              "           6.35291863e-01,  7.23342394e-01,  8.45169023e-01,\n",
              "           1.92175768e-01,  7.86280503e-01, -1.62018553e-01,\n",
              "           1.10783520e+00,  1.25183180e+00,  1.06303203e+00,\n",
              "          -9.07052418e-01, -2.30370118e-01, -1.74384976e-01,\n",
              "           1.88541769e-01, -6.16209158e-01,  5.30705316e-01,\n",
              "          -2.10598629e+00,  1.49538570e+00, -9.97603867e-01,\n",
              "          -1.09283020e+00, -4.76829014e-01, -1.52566382e+00,\n",
              "          -1.73501642e-01,  4.49028255e-01, -1.18943193e-01,\n",
              "          -1.53077840e+00, -6.84332828e-01,  7.06794323e-01,\n",
              "          -1.68141196e+00, -6.65358464e-01, -4.55862284e-01,\n",
              "           1.11313449e+00,  4.32042016e-01, -9.89901499e-01,\n",
              "          -2.71249769e+00]]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  None]]"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(100, activation='sigmoid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[array([[ 4.50796424e-01, -5.00929339e-01,  2.05825472e+00,\n",
              "          -3.80416321e-01, -1.20361746e+00, -1.04143371e+00,\n",
              "           3.45821278e-01,  7.24775494e-01, -6.39350169e-01,\n",
              "           3.18077223e-01, -1.33124096e+00, -2.88492404e-01,\n",
              "           3.21537676e-01, -2.28877113e-02, -8.39977121e-01,\n",
              "           1.18586716e+00, -8.40727375e-01,  7.86241628e-01,\n",
              "           2.43817777e-01, -9.75119155e-01,  4.27529387e-01,\n",
              "          -5.10860857e-01, -5.82651088e-02,  4.12936912e-01,\n",
              "          -6.05740690e-01, -8.63884275e-01, -9.13760874e-01,\n",
              "           1.29221210e+00,  3.26497394e-01,  1.77356315e+00,\n",
              "          -4.81318687e-01,  1.26198024e-01, -5.01955485e-01,\n",
              "           1.38014738e+00,  1.44837732e+00,  1.08275830e-01,\n",
              "           8.93125771e-01,  1.18508747e+00, -1.13657461e+00,\n",
              "          -8.68016149e-01, -6.19008931e-01, -7.92826412e-01,\n",
              "          -4.99150532e-01,  1.71336134e+00,  3.18261551e-01,\n",
              "          -1.85403023e+00, -9.01099647e-01, -7.88068883e-01,\n",
              "           8.41074354e-01,  2.72980614e-01, -6.65741589e-01,\n",
              "          -2.30075048e+00,  1.04472660e+00,  9.04476057e-01,\n",
              "           4.92809224e-01,  7.68232100e-02,  4.91132593e-01,\n",
              "           1.42418669e+00, -1.70899439e+00, -2.44435102e-01,\n",
              "          -1.30888292e+00, -3.22853663e-01,  4.42702255e-01,\n",
              "          -1.99976829e+00,  9.48789253e-01,  4.52543339e-01,\n",
              "          -1.73096696e+00,  1.67797903e-01,  2.27028205e-01,\n",
              "           2.00604077e+00,  7.39723270e-01,  1.59512080e+00,\n",
              "          -7.84946509e-01, -1.82326759e+00,  9.39864346e-01,\n",
              "          -1.28294237e+00, -8.18123536e-01, -4.88809277e-01,\n",
              "          -2.34981944e-01, -1.50403048e+00,  2.20903582e-01,\n",
              "           2.92921377e-01, -5.90718982e-01,  9.55667022e-02,\n",
              "           3.57904680e-01, -1.80559899e-01, -2.14231840e+00,\n",
              "          -5.09110706e-01, -5.39365112e-01,  4.04602641e-01,\n",
              "          -8.27804480e-01,  4.73763137e-01,  2.12331764e-01,\n",
              "          -1.33853853e+00, -1.53705133e+00,  1.32166334e-01,\n",
              "           5.54221034e-01, -9.47282259e-01,  1.73892483e+00,\n",
              "           4.37692367e-01],\n",
              "         [ 5.72836580e-03, -1.33370754e+00, -1.68431474e+00,\n",
              "           1.40176978e+00, -6.61861347e-01, -9.47474136e-01,\n",
              "          -4.76178782e-01,  3.34384051e-01,  4.48444589e-01,\n",
              "          -7.09255300e-01, -1.08186241e+00, -1.21989080e+00,\n",
              "          -7.25651372e-01, -8.07168976e-02, -9.42809092e-01,\n",
              "           6.30981655e-01,  6.84267642e-01, -2.89603652e-01,\n",
              "          -4.87140011e-01, -1.10599503e+00,  3.54697494e-02,\n",
              "          -1.10888019e-02,  2.36174793e-02,  1.52224909e+00,\n",
              "           1.04576745e+00,  2.73407213e+00, -9.44413889e-01,\n",
              "           1.03667019e+00, -5.36750601e-01,  1.28890389e+00,\n",
              "           1.39602286e+00, -7.51315732e-01, -1.04368975e+00,\n",
              "          -4.93087090e-01,  6.50482734e-01,  5.10839619e-02,\n",
              "          -4.64188029e-02, -8.25586220e-02,  7.91322152e-01,\n",
              "          -4.72315099e-01, -2.10992450e+00, -2.73366429e-01,\n",
              "           4.38015120e-01, -1.36173108e+00, -1.50553292e+00,\n",
              "           5.88287558e-01, -1.20822387e+00, -3.35540767e-01,\n",
              "           1.03392762e+00,  1.37373079e+00, -4.33550384e-02,\n",
              "           6.32229056e-01, -4.89790543e-02, -7.79913274e-01,\n",
              "           3.12483751e-03, -1.90781866e+00,  1.87080508e-02,\n",
              "          -8.06640706e-01,  8.94565242e-01, -9.84166499e-01,\n",
              "          -9.46000261e-02,  9.97142188e-01,  1.28641757e+00,\n",
              "           1.68652315e+00,  1.48897882e+00,  6.82600316e-01,\n",
              "          -2.26168769e-01,  5.54876890e-01, -1.24346794e+00,\n",
              "           8.74622332e-01, -5.26932316e-01,  1.49705569e+00,\n",
              "          -1.23316540e+00, -1.41602524e-01, -3.58399530e-01,\n",
              "           3.85309299e-01, -1.44132259e+00, -1.22820038e+00,\n",
              "           5.87280983e-01,  3.25925336e-01, -1.29390911e+00,\n",
              "          -9.90836281e-01,  5.02915726e-01, -5.70537442e-01,\n",
              "          -1.77362146e+00, -2.02395463e+00, -7.82939301e-01,\n",
              "          -2.12572742e-01, -7.79944584e-03,  2.65111433e-01,\n",
              "           7.83193654e-01,  6.38360029e-01, -2.21579258e+00,\n",
              "          -3.53321948e-02,  8.37204631e-02,  6.21962345e-01,\n",
              "           2.19676964e-01, -2.99293112e-01, -5.09476512e-03,\n",
              "          -7.18333243e-01],\n",
              "         [-5.37435466e-01,  4.56354712e-01, -1.22101786e+00,\n",
              "          -1.06501373e+00, -6.59630491e-01,  5.06010104e-01,\n",
              "          -2.00640398e-01,  2.07498673e-01, -3.27447621e-01,\n",
              "           2.38431241e+00,  6.55890840e-02, -1.19881580e+00,\n",
              "          -8.96664509e-01,  9.34107351e-01, -3.82017048e-01,\n",
              "          -4.87057333e-01,  5.28042339e-02, -1.00884544e+00,\n",
              "           9.51273341e-02,  6.95174987e-01,  5.44766831e-02,\n",
              "           3.35483400e-01, -1.05534530e+00,  2.20360883e-02,\n",
              "          -5.40390733e-01, -1.16358603e+00,  5.45301961e-01,\n",
              "          -9.37756711e-01,  2.26176670e-01, -6.60477630e-01,\n",
              "          -2.56575243e-02, -7.35405692e-01,  6.16616274e-02,\n",
              "           1.81212519e+00,  6.03171566e-01,  1.53065217e-02,\n",
              "           3.21310337e-02,  3.20590508e-01,  7.93103913e-01,\n",
              "           1.51161025e+00,  3.07725874e-01,  7.69588569e-01,\n",
              "           9.39385356e-01,  1.96292077e+00, -1.55165024e+00,\n",
              "           1.48571182e+00,  1.72951929e-01,  4.78635505e-01,\n",
              "          -7.99115658e-02, -3.89054959e-01,  1.60849155e+00,\n",
              "          -5.77963179e-01, -1.87511803e-01,  1.95110634e-01,\n",
              "          -5.19218693e-01, -1.48339172e-02,  2.63710438e-01,\n",
              "           1.11336846e+00, -1.08619733e+00, -8.80351564e-01,\n",
              "           4.19729894e-01, -6.82854256e-01, -5.97554433e-01,\n",
              "           1.55450231e+00,  5.91975434e-02,  1.92632306e-01,\n",
              "          -8.06096769e-01,  4.71697303e-01, -9.04999421e-01,\n",
              "          -5.68372068e-01,  4.86944910e-01, -5.74947220e-01,\n",
              "           5.81778490e-01,  9.55093015e-01,  2.34081916e-01,\n",
              "          -4.07730051e-01,  6.29362661e-01,  5.89117617e-01,\n",
              "           3.59804627e-01, -1.70632765e-01,  1.44611324e+00,\n",
              "           9.52888732e-01, -1.19918449e+00,  6.44755343e-01,\n",
              "           1.60377231e+00, -6.30362915e-01, -5.24373336e-01,\n",
              "          -3.80277756e-01,  1.66641160e+00, -1.91730948e+00,\n",
              "           6.63161006e-01, -1.37693422e+00,  3.54418078e-01,\n",
              "           1.10740336e+00, -2.07121393e-01,  5.53103151e-01,\n",
              "          -1.33801088e+00,  2.26826137e+00, -1.89549836e+00,\n",
              "           3.62688165e-01],\n",
              "         [ 2.35760754e-02,  7.99555784e-01, -8.39994036e-01,\n",
              "          -1.25397359e+00, -2.13312231e+00, -1.05989093e-01,\n",
              "          -1.02744579e+00,  8.53344025e-01, -2.92539579e-01,\n",
              "           1.22961827e+00, -9.68321861e-01, -3.15023525e-01,\n",
              "           4.20098930e-01,  6.83701290e-01, -2.27477075e+00,\n",
              "          -1.03257609e-01,  1.02464094e+00,  2.97205794e-01,\n",
              "          -5.84601463e-03,  1.07560779e+00,  2.82596920e-01,\n",
              "          -8.77885855e-01, -1.01781209e+00,  6.01954672e-01,\n",
              "          -2.37799373e-01,  1.18314460e+00, -1.39870629e+00,\n",
              "           1.01281511e+00,  7.22294764e-01, -9.35321948e-01,\n",
              "           7.93894686e-01, -6.65366935e-01, -1.04250159e+00,\n",
              "           8.10424180e-01,  5.01441939e-01, -7.54485704e-01,\n",
              "          -1.08377909e+00,  2.42702692e-01,  5.73774757e-01,\n",
              "          -1.32574435e+00, -8.96542171e-01,  1.79828807e+00,\n",
              "          -3.37906755e-01,  8.15939171e-02,  6.19146429e-01,\n",
              "          -1.36092717e+00, -8.79581148e-01,  1.06810370e+00,\n",
              "          -6.07114549e-01,  1.12031595e-01, -1.20167866e+00,\n",
              "           3.56442605e-01, -1.35151743e+00,  1.89800088e+00,\n",
              "           4.68153026e-01, -1.19371290e+00,  6.21917697e-02,\n",
              "          -6.35281621e-01,  9.67145033e-01,  1.74020365e-01,\n",
              "          -1.01089869e+00,  7.34459268e-01,  6.74669710e-02,\n",
              "          -7.24455183e-01, -2.17824533e+00,  1.16224496e+00,\n",
              "           2.44620474e+00,  9.97066964e-02, -7.46471093e-01,\n",
              "           3.33057268e-01, -1.97036640e-01,  1.26541646e+00,\n",
              "           1.16125446e+00, -6.90463886e-01,  1.03235737e+00,\n",
              "           1.64868847e+00, -1.14015691e+00,  1.53478186e+00,\n",
              "          -1.18529364e+00, -3.66262850e-01,  1.96062618e-01,\n",
              "           9.06306674e-01,  2.10587661e-01, -1.39871944e+00,\n",
              "          -1.15880507e-01, -1.23896438e+00,  2.92696833e-01,\n",
              "          -2.06472009e-01, -1.34952031e+00,  5.33331987e-01,\n",
              "          -1.34506470e+00, -8.41420449e-01, -2.74652382e-01,\n",
              "           1.17148241e+00, -1.08356558e+00, -4.52225450e-01,\n",
              "          -9.40606071e-01,  9.57827766e-01,  6.04098747e-01,\n",
              "          -6.10966490e-01],\n",
              "         [ 1.38856151e-02,  6.03419494e-01,  1.21763768e+00,\n",
              "          -8.45463356e-01, -2.67843545e-01,  7.73456541e-01,\n",
              "           1.22731551e+00, -1.08954473e+00, -4.57404192e-01,\n",
              "          -1.54971666e+00,  8.98546469e-01, -3.80338366e-01,\n",
              "          -7.83126835e-01,  1.44662521e-02, -2.54788335e-01,\n",
              "           1.17846832e+00, -6.33349496e-01, -3.46283288e-01,\n",
              "          -1.38458416e+00,  8.38591351e-02,  8.06968457e-01,\n",
              "           1.28957145e+00,  4.77738237e-01, -3.72561452e-01,\n",
              "          -8.14557035e-01,  3.34525782e-01,  8.92769879e-01,\n",
              "          -1.24634128e+00,  1.17919721e+00,  1.42451395e-01,\n",
              "          -5.31868945e-01,  5.15431176e-01, -4.77976336e-01,\n",
              "          -3.29998990e-01,  8.08689809e-01,  1.08068169e+00,\n",
              "          -2.01932385e-01,  1.13426022e+00, -1.04693343e+00,\n",
              "          -6.45246717e-01, -1.07953795e+00,  8.24057970e-01,\n",
              "          -1.39516690e+00, -7.88832482e-01,  7.17286738e-01,\n",
              "           1.92354477e+00,  1.63608083e-01, -7.19421669e-01,\n",
              "           2.26126839e+00,  4.64922685e-01, -8.69271525e-02,\n",
              "           8.03738364e-01, -6.21639352e-01, -1.16023391e+00,\n",
              "           8.46636367e-01, -1.34798233e+00,  4.35443425e-01,\n",
              "           1.17958037e+00, -2.46591361e-01,  6.07791213e-01,\n",
              "           7.85642735e-01, -2.87091110e-01,  8.87639998e-01,\n",
              "          -4.92764888e-01, -1.18111202e+00, -1.13320237e+00,\n",
              "          -1.65474759e+00, -4.76680344e-01, -1.03908413e+00,\n",
              "           5.32695866e-01, -1.10320245e-02,  9.99225481e-01,\n",
              "           9.26739075e-02,  2.14485193e+00,  6.21865669e-01,\n",
              "           9.38893385e-01, -1.81720665e+00,  8.67950064e-01,\n",
              "          -5.72426717e-01, -1.60876113e-03,  1.08882181e+00,\n",
              "           1.94326636e-01, -1.59534280e+00,  1.16682251e+00,\n",
              "           4.30436834e-01,  3.64528612e-01, -9.31239025e-01,\n",
              "           1.01043421e-01, -1.49146857e+00,  1.04422099e+00,\n",
              "           7.97149745e-01,  5.41716309e-01,  1.71928576e+00,\n",
              "          -2.87411547e-01,  1.60420912e-01,  4.15300545e-01,\n",
              "          -2.57736367e-01,  5.72539672e-01,  1.42740064e+00,\n",
              "          -2.93186145e-01],\n",
              "         [-1.84147784e-01, -5.53370895e-02, -1.31441510e+00,\n",
              "           3.38784271e-01, -2.25359824e+00, -1.57553093e+00,\n",
              "           9.63648309e-02, -1.16600611e+00,  2.40254072e-01,\n",
              "           1.29770471e-01,  5.92458862e-02,  1.07355932e+00,\n",
              "           1.06511447e+00,  1.62551561e+00, -7.61962748e-01,\n",
              "           3.33584924e-01,  1.66867269e-01, -6.14554298e-02,\n",
              "           2.41499286e-01, -6.14785975e-01, -5.68061776e-01,\n",
              "           6.55507199e-01, -1.06323009e+00,  1.97483142e+00,\n",
              "          -6.95411680e-01, -6.69723795e-01,  3.95151204e-01,\n",
              "          -1.73674470e+00, -2.70894595e-01,  1.14813337e+00,\n",
              "          -6.57463572e-02, -2.50783046e-01, -3.74928366e-01,\n",
              "           5.96210349e-01, -1.11044317e+00, -2.52608299e+00,\n",
              "          -6.91408804e-01, -7.28922027e-01, -1.44912881e+00,\n",
              "          -1.62663931e+00,  8.08531486e-01, -6.16361085e-01,\n",
              "           1.82809532e-01,  4.94264336e-03, -2.71646694e+00,\n",
              "          -1.06921036e+00,  6.72898971e-01, -1.72084092e+00,\n",
              "           7.37559663e-01,  3.01715728e-01, -1.69295508e+00,\n",
              "           9.18822964e-04,  5.54924978e-01,  4.85542385e-01,\n",
              "           3.51005605e-01,  1.53289490e+00,  1.24575235e+00,\n",
              "          -3.59545664e-02,  6.04545344e-01, -5.45342334e-01,\n",
              "           1.00287437e-01, -5.66847755e-01,  5.49321716e-01,\n",
              "           5.30234856e-01, -5.91669248e-02,  5.52778766e-01,\n",
              "          -9.72537908e-02, -1.84089757e-01,  6.84994260e-01,\n",
              "          -2.41674846e-01,  9.12270931e-02, -2.06611409e+00,\n",
              "          -5.75797088e-01,  8.61749946e-01, -3.89963074e-01,\n",
              "          -1.14331623e+00, -5.66248353e-01,  4.33673985e-01,\n",
              "           3.16496099e-01,  1.04916074e+00,  2.59455511e-01,\n",
              "           2.31645917e+00, -8.01472734e-01, -1.74473347e+00,\n",
              "          -1.47692969e+00,  1.78699615e+00, -3.77179480e-01,\n",
              "           4.57076715e-01,  4.17665503e-02, -1.69567835e+00,\n",
              "          -4.83395430e-03, -2.68106086e-01,  9.22597216e-01,\n",
              "           1.48406866e-01, -9.25772290e-01,  3.75899591e-01,\n",
              "          -8.83534553e-01, -4.85259282e-01, -1.11029251e+00,\n",
              "          -1.72043612e+00],\n",
              "         [ 3.62103803e-01, -2.09692876e+00, -7.68750591e-01,\n",
              "          -1.90257906e+00,  7.65421006e-01,  1.30633511e+00,\n",
              "          -1.18498720e+00,  7.74561312e-01, -8.50587920e-01,\n",
              "           4.84649031e-01,  3.48067777e-01, -3.12425432e-03,\n",
              "           2.37694821e-01, -1.67555264e-01,  2.29732171e+00,\n",
              "          -4.31797034e-01, -1.01302010e+00, -1.16358823e-01,\n",
              "           1.84464138e-03,  4.61554705e-01, -5.68484350e-01,\n",
              "          -9.34468356e-01, -6.67091867e-01, -1.85744464e-01,\n",
              "          -2.86501455e+00,  6.46737808e-02, -4.85099737e-01,\n",
              "          -6.05419371e-01, -2.03343068e+00, -5.28415062e-01,\n",
              "          -1.96237704e+00,  6.20445626e-02,  7.00458320e-02,\n",
              "          -1.00506731e+00, -9.57764156e-01,  3.77826068e-01,\n",
              "          -1.03296981e+00, -9.64840565e-01,  8.04539120e-01,\n",
              "           9.36118655e-01, -1.08140642e+00,  1.55910641e+00,\n",
              "          -3.75029772e-03, -1.07937636e-01, -1.09084903e+00,\n",
              "           2.29597946e-01,  8.05519670e-01, -3.42376868e-01,\n",
              "           7.53131974e-01, -4.45146635e-01, -3.64819538e-01,\n",
              "           3.88442038e-01, -1.98864524e+00,  5.92639386e-01,\n",
              "          -7.37038009e-03, -1.03844147e+00, -2.68423396e+00,\n",
              "           2.03324525e+00, -1.36699666e-01, -9.42680894e-01,\n",
              "           8.19528694e-01, -8.69000445e-01,  1.54273050e-01,\n",
              "           1.52697254e+00, -6.21670156e-01, -7.33575061e-01,\n",
              "           6.45763932e-01, -7.35031161e-02, -4.68786965e-01,\n",
              "          -9.33656792e-01,  1.56207912e+00,  3.18858272e-01,\n",
              "           5.04921161e-01, -2.17239511e-01,  2.03765152e+00,\n",
              "           2.17992149e-01,  5.39805929e-03, -3.63176954e-01,\n",
              "           8.69725018e-01, -1.83893431e+00,  4.81021510e-01,\n",
              "           1.10102541e-01, -1.44134532e+00, -2.25823641e-01,\n",
              "           1.94402359e+00,  8.01699739e-01, -1.20294861e+00,\n",
              "           7.53189535e-01,  1.25368736e+00, -8.66195927e-01,\n",
              "           4.65659860e-01, -1.42661016e+00,  5.88263570e-02,\n",
              "          -1.44402489e+00,  1.61492663e+00,  3.06727744e-01,\n",
              "          -1.56741603e+00,  2.32832385e-01,  1.42783344e-01,\n",
              "          -3.26372292e-01],\n",
              "         [-1.00764608e+00, -1.02154574e+00,  1.19122071e-01,\n",
              "          -1.84047178e-02, -1.65406587e-01,  1.03672504e+00,\n",
              "           1.50030218e+00,  1.79358503e-01,  1.70361216e-03,\n",
              "           2.41682496e-01,  2.82877901e-02,  1.09157788e+00,\n",
              "          -7.97977706e-01,  2.37428552e-01, -8.81212168e-01,\n",
              "          -6.25878849e-01,  9.62470175e-01, -1.19144793e+00,\n",
              "           1.94329964e+00,  2.18933858e-01,  3.34212513e-02,\n",
              "          -3.13312704e-01, -3.53534832e-01, -1.49399201e+00,\n",
              "          -1.04858246e+00, -2.81571839e+00,  6.16557842e-01,\n",
              "           4.36060685e-01,  6.99235478e-01,  5.64751909e-01,\n",
              "           2.01097607e+00,  1.76613500e-01, -4.57208694e-01,\n",
              "           2.21832885e+00, -9.87271646e-02, -7.15156964e-02,\n",
              "           6.96928566e-01,  1.65954127e+00,  1.45765453e+00,\n",
              "          -6.19279776e-01,  9.65654358e-01,  9.46048634e-02,\n",
              "          -2.49034282e+00, -4.55147331e-01,  1.45473348e+00,\n",
              "           5.77086149e-01,  6.85874802e-01,  3.86316035e-01,\n",
              "          -2.26580493e-01,  6.72157156e-01,  2.18288176e+00,\n",
              "           4.04284750e-01, -1.25029969e+00,  6.74309941e-01,\n",
              "          -2.33850271e-01, -5.49918345e-01,  2.00206850e+00,\n",
              "           5.98065096e-02, -9.62552820e-01,  2.03385531e+00,\n",
              "          -1.11661715e+00,  1.66124165e+00,  2.62376020e-01,\n",
              "           1.91541515e-01,  5.65576745e-02, -6.03386077e-01,\n",
              "          -7.85190562e-01,  6.22891934e-01,  1.87833581e-01,\n",
              "           8.31710029e-01,  1.10195106e+00,  5.87657155e-01,\n",
              "          -7.96715422e-01, -1.27551694e+00, -1.02068513e+00,\n",
              "          -5.55680253e-01,  1.20945836e+00,  2.40596014e-01,\n",
              "           6.26581676e-01,  1.12861343e+00,  3.06967987e-01,\n",
              "           1.00047041e+00,  7.78410127e-01, -6.11595203e-01,\n",
              "           6.04118868e-01,  1.16534517e+00,  1.30608147e-01,\n",
              "          -7.82334715e-01, -8.24023895e-01, -1.28774200e+00,\n",
              "           3.99883736e-01,  1.57470530e+00,  6.41508412e-01,\n",
              "           3.34966302e+00, -1.02467746e+00, -1.12434767e-01,\n",
              "          -1.35724187e+00,  2.85762354e-01, -1.07910566e+00,\n",
              "          -1.23422773e+00],\n",
              "         [-5.98966259e-01, -9.96267875e-01, -8.97340107e-01,\n",
              "          -6.93688523e-01,  2.13316455e+00,  1.81073455e+00,\n",
              "          -5.93220129e-01,  6.49601203e-01, -4.48252703e-01,\n",
              "           9.37261044e-01, -1.02824850e+00, -8.99497617e-01,\n",
              "          -1.37441503e-01, -4.90480204e-01,  1.04703965e+00,\n",
              "           8.26723081e-01,  6.89208287e-01, -1.47511813e-01,\n",
              "          -2.60838325e+00, -3.76601930e-01,  1.92950044e+00,\n",
              "           3.52090519e-01, -1.59583305e+00, -1.30607607e+00,\n",
              "           6.15655021e-01,  1.35546705e-01,  9.00868618e-01,\n",
              "          -6.17666385e-01, -8.31041390e-01, -1.56631964e-01,\n",
              "          -8.36055605e-02, -7.53421890e-01, -1.21461093e+00,\n",
              "          -6.94815789e-01,  8.85826695e-01, -1.61553067e+00,\n",
              "          -2.10450836e+00,  2.99986552e-01, -5.38686902e-01,\n",
              "          -1.42449325e+00, -9.88130523e-01,  5.89182452e-01,\n",
              "           1.41032754e+00, -1.12222748e+00,  2.30979952e-01,\n",
              "           7.03358407e-01,  6.50096821e-01, -1.02484527e+00,\n",
              "          -7.27743967e-01,  4.85820509e-01, -5.40331308e-01,\n",
              "          -2.46939827e+00, -9.19515485e-01, -2.27102706e-01,\n",
              "          -8.30727007e-01,  1.04676881e+00, -4.69621484e-01,\n",
              "          -5.41333299e-01,  2.37181242e+00,  1.60917490e+00,\n",
              "          -3.37663656e-01, -2.59805294e-01,  6.81037281e-01,\n",
              "          -8.82945974e-01, -6.46315172e-01,  1.10136758e+00,\n",
              "          -2.08677975e-01, -5.66203732e-01,  6.22846759e-01,\n",
              "          -7.43333447e-01, -1.08448371e+00,  5.30500971e-01,\n",
              "          -3.14103061e-01, -1.45817375e-01, -2.64887377e-01,\n",
              "           1.55352980e+00, -1.13409549e+00,  5.27633914e-01,\n",
              "          -6.42263517e-01,  6.28858029e-01,  5.82930305e-01,\n",
              "          -4.39033090e-01,  2.86920814e-01,  8.63657341e-01,\n",
              "           3.31213007e-01, -2.66328706e-01,  1.56738477e-02,\n",
              "           2.07533338e-01, -1.49273920e+00,  9.84332731e-01,\n",
              "          -8.37892009e-01,  2.22889882e-01, -8.54903722e-01,\n",
              "          -3.57317979e-01, -3.78710119e-01,  2.14758093e-01,\n",
              "           3.92721719e-02,  1.47018513e+00,  7.68911634e-02,\n",
              "          -5.23735960e-01],\n",
              "         [ 1.52689900e+00,  5.80139388e-01, -1.45250915e+00,\n",
              "           3.04326665e-01, -1.48022921e-01,  5.29201094e-01,\n",
              "          -7.05801673e-02,  1.64077954e+00, -4.62713687e-01,\n",
              "          -1.72598768e+00,  8.51112280e-01,  3.61190811e-01,\n",
              "           6.19965287e-01,  3.72407196e-01,  1.80553859e-01,\n",
              "           3.20682050e-01,  1.07477471e+00,  1.96279730e+00,\n",
              "          -1.46564146e-01,  2.13000509e-01, -2.39787961e-01,\n",
              "          -1.63599541e+00, -5.28327539e-01, -9.53227336e-01,\n",
              "          -2.42357721e+00, -1.54309303e+00, -1.39710457e-01,\n",
              "          -2.43429978e-01, -4.44449529e-01, -3.70690571e-01,\n",
              "          -6.91289250e-01, -1.27013538e+00, -8.39056237e-01,\n",
              "           2.44753407e-01,  1.01081959e+00,  1.19771890e+00,\n",
              "           1.50991252e+00, -1.22528152e+00,  1.28174613e+00,\n",
              "           5.58427209e-01, -2.78876491e-01,  1.09619078e+00,\n",
              "           6.22916720e-01,  1.29296454e+00,  6.43853563e-01,\n",
              "          -5.86299027e-01, -8.21423113e-02, -5.59538395e-01,\n",
              "           1.79292534e-01,  7.19261547e-02,  1.14513886e-01,\n",
              "           8.88374746e-01, -7.72490175e-01,  2.10379733e-02,\n",
              "          -1.04193443e+00, -7.96628267e-01, -2.84186799e+00,\n",
              "          -1.27410526e+00, -7.96590628e-01,  2.67031898e-01,\n",
              "          -1.36664594e+00,  8.66947410e-01,  8.70016264e-01,\n",
              "          -6.77990222e-01,  2.87149682e-01,  6.72594732e-01,\n",
              "           6.35291863e-01,  7.23342394e-01,  8.45169023e-01,\n",
              "           1.92175768e-01,  7.86280503e-01, -1.62018553e-01,\n",
              "           1.10783520e+00,  1.25183180e+00,  1.06303203e+00,\n",
              "          -9.07052418e-01, -2.30370118e-01, -1.74384976e-01,\n",
              "           1.88541769e-01, -6.16209158e-01,  5.30705316e-01,\n",
              "          -2.10598629e+00,  1.49538570e+00, -9.97603867e-01,\n",
              "          -1.09283020e+00, -4.76829014e-01, -1.52566382e+00,\n",
              "          -1.73501642e-01,  4.49028255e-01, -1.18943193e-01,\n",
              "          -1.53077840e+00, -6.84332828e-01,  7.06794323e-01,\n",
              "          -1.68141196e+00, -6.65358464e-01, -4.55862284e-01,\n",
              "           1.11313449e+00,  4.32042016e-01, -9.89901499e-01,\n",
              "          -2.71249769e+00]]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  None],\n",
              " [array([[-2.00986028,  2.78455856,  1.16559505, ..., -0.85196899,\n",
              "          -0.48698736, -0.62807644],\n",
              "         [ 0.83203444,  0.09197177, -0.38530041, ..., -1.0939487 ,\n",
              "           0.01400316, -0.69017815],\n",
              "         [-0.02466401,  0.20964176,  0.0403148 , ..., -1.48206729,\n",
              "           0.25277543, -1.27583832],\n",
              "         ...,\n",
              "         [-0.07546266,  0.62713589,  1.06048574, ..., -0.39446862,\n",
              "          -0.82352951,  0.36766055],\n",
              "         [ 0.39986403, -0.14704049, -0.55863978, ..., -0.43743968,\n",
              "          -0.74232015,  0.05096646],\n",
              "         [ 0.21644985,  1.58667368,  1.61529624, ..., -0.46247025,\n",
              "          -1.22859855,  1.24347186]]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  __main__.Sigmoid]]"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================================\n",
            "-------------Output Shape---------param #------\n",
            "--------------(None, 100),-------1000----\n",
            "--------------(None, 10),-------1000----\n",
            "--------------(None, 10),-------100----\n",
            "==============================================\n",
            "Total Parmerter # ---- 2220\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Net(10)\n",
        "model.add(100, activation='relu')\n",
        "model.add(10, activation='relu')\n",
        "model.add(10, activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = model.predict(np.random.randn(7,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.random.randint(0, 10, 50)\n",
        "x = to_categorical(x)[:7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from time import time, sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|         | 1/20 [00:01<00:19,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|         | 2/20 [00:02<00:18,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|        | 3/20 [00:03<00:17,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|        | 4/20 [00:04<00:16,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|       | 5/20 [00:05<00:15,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|       | 6/20 [00:06<00:14,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|      | 7/20 [00:07<00:13,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|      | 8/20 [00:08<00:12,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|     | 9/20 [00:09<00:11,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|     | 10/20 [00:10<00:10,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|    | 11/20 [00:11<00:09,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|    | 12/20 [00:12<00:08,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|   | 13/20 [00:13<00:07,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|   | 14/20 [00:14<00:06,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|  | 15/20 [00:15<00:05,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|  | 16/20 [00:16<00:04,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%| | 17/20 [00:17<00:03,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%| | 18/20 [00:18<00:02,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|| 19/20 [00:19<00:01,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 20/20 [00:20<00:00,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(20)):\n",
        "    sleep(1)\n",
        "    \n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Net(10)\n",
        "model.add(256, activation='relu')\n",
        "model.add(128, activation='relu')\n",
        "model.add(10, activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics='accuracy', lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:00<00:00, 58.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 ====================> accuracy : 0.107 loss : 1.4277339134672187\n",
            "2 ====================> accuracy : 0.109 loss : 1.42518643814196\n",
            "3 ====================> accuracy : 0.115 loss : 1.420464669312911\n",
            "4 ====================> accuracy : 0.112 loss : 1.423689697057316\n",
            "5 ====================> accuracy : 0.111 loss : 1.424632739945217\n",
            "6 ====================> accuracy : 0.113 loss : 1.422521383205124\n",
            "7 ====================> accuracy : 0.113 loss : 1.4198110893464135\n",
            "8 ====================> accuracy : 0.113 loss : 1.4204242253450308\n",
            "9 ====================> accuracy : 0.11 loss : 1.4224579240919752\n",
            "10 ====================> accuracy : 0.111 loss : 1.4219838250428494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.fit(np.random.randn(1000, 10), to_categorical(np.random.randint(0, 10, 1000)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(-1, 784)/255\n",
        "X_test = X_test.reshape(-1, 784)/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Net(784)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model.add(256, activation='relu')\n",
        "model.add(128, activation='relu')\n",
        "model.add(10, activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics='accuracy', lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 1/100 [00:02<03:47,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 ====================> accuracy : 0.08671666666666666 loss : 1.4706707630250557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|         | 2/100 [00:04<03:49,  2.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 ====================> accuracy : 0.0837 loss : 1.4744993009829142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|         | 3/100 [00:07<03:46,  2.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 ====================> accuracy : 0.08295 loss : 1.4751797779569473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|         | 4/100 [00:09<03:46,  2.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 ====================> accuracy : 0.08245 loss : 1.4759832093035914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|         | 5/100 [00:11<03:41,  2.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 ====================> accuracy : 0.08251666666666667 loss : 1.475137859570594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|         | 6/100 [00:14<03:40,  2.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 ====================> accuracy : 0.0818 loss : 1.4766901572055082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|         | 7/100 [00:16<03:36,  2.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7 ====================> accuracy : 0.08255 loss : 1.4748278155775445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|         | 8/100 [00:18<03:32,  2.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8 ====================> accuracy : 0.08356666666666666 loss : 1.4735743253531652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|         | 9/100 [00:20<03:28,  2.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9 ====================> accuracy : 0.08388333333333334 loss : 1.4718916741957793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|         | 10/100 [00:23<03:24,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 ====================> accuracy : 0.0854 loss : 1.469923007808285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|         | 11/100 [00:25<03:22,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11 ====================> accuracy : 0.08615 loss : 1.4681383408633373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|        | 12/100 [00:27<03:18,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12 ====================> accuracy : 0.08723333333333333 loss : 1.4662301231051043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|        | 13/100 [00:29<03:17,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13 ====================> accuracy : 0.08833333333333333 loss : 1.4647611425511313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|        | 14/100 [00:32<03:13,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14 ====================> accuracy : 0.0889 loss : 1.4635911668396169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|        | 15/100 [00:34<03:10,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15 ====================> accuracy : 0.08901666666666666 loss : 1.4629187801138512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|        | 16/100 [00:36<03:07,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16 ====================> accuracy : 0.08958333333333333 loss : 1.4624675166346262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|        | 17/100 [00:38<03:06,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17 ====================> accuracy : 0.09003333333333334 loss : 1.4618750203773518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|        | 18/100 [00:41<03:04,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18 ====================> accuracy : 0.09045 loss : 1.4613730988837046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|        | 19/100 [00:43<03:02,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19 ====================> accuracy : 0.09061666666666666 loss : 1.4613221000025653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|        | 20/100 [00:45<03:00,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20 ====================> accuracy : 0.09046666666666667 loss : 1.4614857731662723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|        | 21/100 [00:47<02:58,  2.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21 ====================> accuracy : 0.0904 loss : 1.4613446983493694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|       | 22/100 [00:50<02:55,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22 ====================> accuracy : 0.0903 loss : 1.461150585662726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|       | 23/100 [00:52<02:53,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23 ====================> accuracy : 0.09015 loss : 1.4611359190368307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|       | 24/100 [00:54<02:50,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24 ====================> accuracy : 0.09031666666666667 loss : 1.461064135294143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|       | 25/100 [00:56<02:48,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25 ====================> accuracy : 0.09056666666666667 loss : 1.4608096699526674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|       | 26/100 [00:59<02:46,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26 ====================> accuracy : 0.09015 loss : 1.4611326347712876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|       | 27/100 [01:01<02:42,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27 ====================> accuracy : 0.0901 loss : 1.4615529636454119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|       | 28/100 [01:03<02:41,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28 ====================> accuracy : 0.09028333333333333 loss : 1.461575504415286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|       | 29/100 [01:05<02:39,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29 ====================> accuracy : 0.09021666666666667 loss : 1.4615908293243376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|       | 30/100 [01:07<02:36,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30 ====================> accuracy : 0.09013333333333333 loss : 1.4613766078976544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|       | 31/100 [01:10<02:33,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31 ====================> accuracy : 0.08995 loss : 1.4617674635337496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|      | 32/100 [01:12<02:31,  2.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32 ====================> accuracy : 0.08973333333333333 loss : 1.46211995350894\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|      | 33/100 [01:14<02:29,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33 ====================> accuracy : 0.08986666666666666 loss : 1.4617620053706852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|      | 34/100 [01:16<02:27,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34 ====================> accuracy : 0.08966666666666667 loss : 1.4617855750903392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|      | 35/100 [01:19<02:24,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35 ====================> accuracy : 0.08961666666666666 loss : 1.4624470686826425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|      | 36/100 [01:21<02:22,  2.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36 ====================> accuracy : 0.0894 loss : 1.46250451475832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|      | 37/100 [01:23<02:20,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37 ====================> accuracy : 0.0897 loss : 1.4619906118452106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|      | 38/100 [01:25<02:18,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38 ====================> accuracy : 0.09006666666666667 loss : 1.4614499007559487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|      | 39/100 [01:28<02:16,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39 ====================> accuracy : 0.08998333333333333 loss : 1.461460352931774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|      | 40/100 [01:30<02:14,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40 ====================> accuracy : 0.09006666666666667 loss : 1.4615266986964652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|      | 41/100 [01:32<02:12,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41 ====================> accuracy : 0.08991666666666667 loss : 1.4618186863297222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|     | 42/100 [01:34<02:10,  2.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42 ====================> accuracy : 0.09 loss : 1.4613488285985208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|     | 43/100 [01:37<02:07,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43 ====================> accuracy : 0.08933333333333333 loss : 1.46262156757904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|     | 44/100 [01:39<02:06,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44 ====================> accuracy : 0.09018333333333334 loss : 1.4608597726516028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|     | 45/100 [01:41<02:04,  2.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45 ====================> accuracy : 0.0871 loss : 1.466370985858553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|     | 46/100 [01:43<02:02,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46 ====================> accuracy : 0.097 loss : 1.4506551348568517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|     | 47/100 [01:46<02:00,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47 ====================> accuracy : 0.0833 loss : 1.4731107077024213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|     | 48/100 [01:48<01:57,  2.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48 ====================> accuracy : 0.08986666666666666 loss : 1.4633750235098586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|     | 49/100 [01:50<01:55,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49 ====================> accuracy : 0.08546666666666666 loss : 1.4709164156728176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|     | 50/100 [01:52<01:53,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50 ====================> accuracy : 0.10751666666666666 loss : 1.4367484548382543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|     | 51/100 [01:55<01:51,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51 ====================> accuracy : 0.07306666666666667 loss : 1.4916929333254854\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|    | 52/100 [01:57<01:48,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52 ====================> accuracy : 0.05993333333333333 loss : 1.5132009730196139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|    | 53/100 [01:59<01:47,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53 ====================> accuracy : 0.10066666666666667 loss : 1.4493980087807836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|    | 54/100 [02:02<01:44,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "54 ====================> accuracy : 0.1093 loss : 1.4347812709010233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|    | 55/100 [02:04<01:42,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55 ====================> accuracy : 0.06368333333333333 loss : 1.507846976058269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|    | 56/100 [02:06<01:40,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "56 ====================> accuracy : 0.08711666666666666 loss : 1.469610411704718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|    | 57/100 [02:08<01:37,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57 ====================> accuracy : 0.09915 loss : 1.4519986457250806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|    | 58/100 [02:11<01:35,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "58 ====================> accuracy : 0.09035 loss : 1.4661825699859241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|    | 59/100 [02:13<01:33,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "59 ====================> accuracy : 0.07828333333333333 loss : 1.4842865044503815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|    | 60/100 [02:15<01:31,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60 ====================> accuracy : 0.11236666666666667 loss : 1.4306958958408968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|    | 61/100 [02:18<01:29,  2.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "61 ====================> accuracy : 0.10621666666666667 loss : 1.4403407730845694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|   | 62/100 [02:20<01:27,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62 ====================> accuracy : 0.09863333333333334 loss : 1.452831414005547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|   | 63/100 [02:22<01:24,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63 ====================> accuracy : 0.08336666666666667 loss : 1.4762515181037976\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|   | 64/100 [02:24<01:21,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64 ====================> accuracy : 0.09751666666666667 loss : 1.4546312680310702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|   | 65/100 [02:27<01:19,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 ====================> accuracy : 0.0993 loss : 1.4517568742888163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|   | 66/100 [02:29<01:21,  2.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66 ====================> accuracy : 0.09915 loss : 1.4519986457250806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|   | 67/100 [02:32<01:18,  2.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67 ====================> accuracy : 0.09736666666666667 loss : 1.4548730394673353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|   | 68/100 [02:34<01:16,  2.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "68 ====================> accuracy : 0.06765 loss : 1.5019007108615137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|   | 68/100 [02:36<01:13,  2.30s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[245], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[225], line 102\u001b[0m, in \u001b[0;36mNet.fit\u001b[1;34m(self, x, y, epochs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient(x,y)\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====================> accuracy : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x,y)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers,\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAffine_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(idx))\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(idx)]\n",
            "Cell \u001b[1;32mIn[225], line 82\u001b[0m, in \u001b[0;36mNet.loss\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,y):\n\u001b[1;32m---> 82\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     loss_val \u001b[38;5;241m=\u001b[39m categorical_crossentropy(y,y_hat)\n\u001b[0;32m     84\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39margmax(y_hat,\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y,\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(y)\n",
            "Cell \u001b[1;32mIn[225], line 60\u001b[0m, in \u001b[0;36mNet.predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat \u001b[38;5;241m=\u001b[39m \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat\n",
            "Cell \u001b[1;32mIn[112], line 9\u001b[0m, in \u001b[0;36mAffine.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout\n",
            "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
