{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Giv45HDjRw3j"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjtMVPuWUICf"
      },
      "outputs": [],
      "source": [
        "x = np.array([1, 2, 3, 4, 5, 6])\n",
        "x = x.reshape(2, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8fjk9I8UT-Z",
        "outputId": "2ef677e0-4e68-410b-fb45-34d2453c6667"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te0-fhsBUUR3"
      },
      "outputs": [],
      "source": [
        "y1 = x.reshape(3, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f893m_OkUZwI",
        "outputId": "aaa121b9-33fc-44e0-c3e8-9f7b44b5fea5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4],\n",
              "       [5, 6]])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92_X9qOOUaKg"
      },
      "outputs": [],
      "source": [
        "data = np.array([[0,0],[1,0],[0, 1],[1, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0qLMbnufN9J"
      },
      "outputs": [],
      "source": [
        "And = np.array([[0],[0],[0],[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jj6UEMcfxkT"
      },
      "outputs": [],
      "source": [
        "W = np.array([0.5, 0.5]).reshape(2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiEtMaTko0x6",
        "outputId": "264b6d87-4ea8-4f67-8edf-d22e02286b98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5],\n",
              "       [0.5]])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DXCo1yLf7j1",
        "outputId": "73a4fa4f-1db6-45d1-ac89-700e3a62cf00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(np.dot(data, W) < 0.6, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJn6SCZQAYMQ",
        "outputId": "bfd20585-237c-49e1-b04f-e76158535b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.10526315789473684\n",
            "0.05263157894736842 0.05263157894736842 0.15789473684210525\n",
            "0.05263157894736842 0.05263157894736842 0.21052631578947367\n",
            "0.05263157894736842 0.05263157894736842 0.2631578947368421\n",
            "0.05263157894736842 0.05263157894736842 0.3157894736842105\n",
            "0.05263157894736842 0.05263157894736842 0.3684210526315789\n",
            "0.05263157894736842 0.05263157894736842 0.42105263157894735\n",
            "0.05263157894736842 0.05263157894736842 0.47368421052631576\n",
            "0.05263157894736842 0.05263157894736842 0.5263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.5789473684210527\n",
            "0.05263157894736842 0.05263157894736842 0.631578947368421\n",
            "0.05263157894736842 0.05263157894736842 0.6842105263157894\n",
            "0.05263157894736842 0.05263157894736842 0.7894736842105263\n",
            "0.05263157894736842 0.05263157894736842 0.8421052631578947\n",
            "0.05263157894736842 0.05263157894736842 0.894736842105263\n",
            "0.05263157894736842 0.05263157894736842 1.0\n",
            "0.10526315789473684 0.10526315789473684 0.15789473684210525\n",
            "0.10526315789473684 0.10526315789473684 0.15789473684210525\n",
            "0.10526315789473684 0.10526315789473684 0.21052631578947367\n",
            "0.10526315789473684 0.10526315789473684 0.2631578947368421\n",
            "0.10526315789473684 0.10526315789473684 0.3157894736842105\n",
            "0.10526315789473684 0.10526315789473684 0.3684210526315789\n",
            "0.10526315789473684 0.10526315789473684 0.42105263157894735\n",
            "0.10526315789473684 0.10526315789473684 0.47368421052631576\n",
            "0.10526315789473684 0.10526315789473684 0.5263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.5789473684210527\n",
            "0.10526315789473684 0.10526315789473684 0.631578947368421\n",
            "0.10526315789473684 0.10526315789473684 0.6842105263157894\n",
            "0.10526315789473684 0.10526315789473684 0.7368421052631579\n",
            "0.10526315789473684 0.10526315789473684 0.7894736842105263\n",
            "0.10526315789473684 0.10526315789473684 0.8421052631578947\n",
            "0.10526315789473684 0.10526315789473684 0.894736842105263\n",
            "0.10526315789473684 0.10526315789473684 0.9473684210526315\n",
            "0.10526315789473684 0.10526315789473684 1.0\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.2631578947368421\n",
            "0.15789473684210525 0.15789473684210525 0.3157894736842105\n",
            "0.15789473684210525 0.15789473684210525 0.3684210526315789\n",
            "0.15789473684210525 0.15789473684210525 0.42105263157894735\n",
            "0.15789473684210525 0.15789473684210525 0.47368421052631576\n",
            "0.15789473684210525 0.15789473684210525 0.5263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.5789473684210527\n",
            "0.15789473684210525 0.15789473684210525 0.631578947368421\n",
            "0.15789473684210525 0.15789473684210525 0.6842105263157894\n",
            "0.15789473684210525 0.15789473684210525 0.7368421052631579\n",
            "0.15789473684210525 0.15789473684210525 0.7894736842105263\n",
            "0.15789473684210525 0.15789473684210525 0.8421052631578947\n",
            "0.15789473684210525 0.15789473684210525 0.894736842105263\n",
            "0.15789473684210525 0.15789473684210525 0.9473684210526315\n",
            "0.15789473684210525 0.15789473684210525 1.0\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.3157894736842105\n",
            "0.21052631578947367 0.21052631578947367 0.3684210526315789\n",
            "0.21052631578947367 0.21052631578947367 0.42105263157894735\n",
            "0.21052631578947367 0.21052631578947367 0.47368421052631576\n",
            "0.21052631578947367 0.21052631578947367 0.5263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.5789473684210527\n",
            "0.21052631578947367 0.21052631578947367 0.631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.6842105263157894\n",
            "0.21052631578947367 0.21052631578947367 0.7368421052631579\n",
            "0.21052631578947367 0.21052631578947367 0.7894736842105263\n",
            "0.21052631578947367 0.21052631578947367 0.8421052631578947\n",
            "0.21052631578947367 0.21052631578947367 0.894736842105263\n",
            "0.21052631578947367 0.21052631578947367 0.9473684210526315\n",
            "0.21052631578947367 0.21052631578947367 1.0\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3684210526315789\n",
            "0.2631578947368421 0.2631578947368421 0.42105263157894735\n",
            "0.2631578947368421 0.2631578947368421 0.47368421052631576\n",
            "0.2631578947368421 0.2631578947368421 0.5263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.5789473684210527\n",
            "0.2631578947368421 0.2631578947368421 0.631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.6842105263157894\n",
            "0.2631578947368421 0.2631578947368421 0.7368421052631579\n",
            "0.2631578947368421 0.2631578947368421 0.7894736842105263\n",
            "0.2631578947368421 0.2631578947368421 0.8421052631578947\n",
            "0.2631578947368421 0.2631578947368421 0.894736842105263\n",
            "0.2631578947368421 0.2631578947368421 0.9473684210526315\n",
            "0.2631578947368421 0.2631578947368421 1.0\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.42105263157894735\n",
            "0.3157894736842105 0.3157894736842105 0.47368421052631576\n",
            "0.3157894736842105 0.3157894736842105 0.5263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.5789473684210527\n",
            "0.3157894736842105 0.3157894736842105 0.631578947368421\n",
            "0.3157894736842105 0.3157894736842105 0.6842105263157894\n",
            "0.3157894736842105 0.3157894736842105 0.7368421052631579\n",
            "0.3157894736842105 0.3157894736842105 0.7894736842105263\n",
            "0.3157894736842105 0.3157894736842105 0.8421052631578947\n",
            "0.3157894736842105 0.3157894736842105 0.894736842105263\n",
            "0.3157894736842105 0.3157894736842105 0.9473684210526315\n",
            "0.3157894736842105 0.3157894736842105 1.0\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.47368421052631576\n",
            "0.3684210526315789 0.3684210526315789 0.5263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.5789473684210527\n",
            "0.3684210526315789 0.3684210526315789 0.631578947368421\n",
            "0.3684210526315789 0.3684210526315789 0.6842105263157894\n",
            "0.3684210526315789 0.3684210526315789 0.7368421052631579\n",
            "0.3684210526315789 0.3684210526315789 0.7894736842105263\n",
            "0.3684210526315789 0.3684210526315789 0.8421052631578947\n",
            "0.3684210526315789 0.3684210526315789 0.894736842105263\n",
            "0.3684210526315789 0.3684210526315789 0.9473684210526315\n",
            "0.3684210526315789 0.3684210526315789 1.0\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.5263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.5789473684210527\n",
            "0.42105263157894735 0.42105263157894735 0.631578947368421\n",
            "0.42105263157894735 0.42105263157894735 0.6842105263157894\n",
            "0.42105263157894735 0.42105263157894735 0.7368421052631579\n",
            "0.42105263157894735 0.42105263157894735 0.7894736842105263\n",
            "0.42105263157894735 0.42105263157894735 0.8421052631578947\n",
            "0.42105263157894735 0.42105263157894735 0.894736842105263\n",
            "0.42105263157894735 0.42105263157894735 0.9473684210526315\n",
            "0.42105263157894735 0.42105263157894735 1.0\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5789473684210527\n",
            "0.47368421052631576 0.47368421052631576 0.631578947368421\n",
            "0.47368421052631576 0.47368421052631576 0.6842105263157894\n",
            "0.47368421052631576 0.47368421052631576 0.7368421052631579\n",
            "0.47368421052631576 0.47368421052631576 0.7894736842105263\n",
            "0.47368421052631576 0.47368421052631576 0.8421052631578947\n",
            "0.47368421052631576 0.47368421052631576 0.894736842105263\n",
            "0.47368421052631576 0.47368421052631576 0.9473684210526315\n",
            "0.47368421052631576 0.47368421052631576 1.0\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.631578947368421\n",
            "0.5263157894736842 0.5263157894736842 0.6842105263157894\n",
            "0.5263157894736842 0.5263157894736842 0.7368421052631579\n",
            "0.5263157894736842 0.5263157894736842 0.7894736842105263\n",
            "0.5263157894736842 0.5263157894736842 0.8421052631578947\n",
            "0.5263157894736842 0.5263157894736842 0.894736842105263\n",
            "0.5263157894736842 0.5263157894736842 0.9473684210526315\n",
            "0.5263157894736842 0.5263157894736842 1.0\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.6842105263157894\n",
            "0.5789473684210527 0.5789473684210527 0.7368421052631579\n",
            "0.5789473684210527 0.5789473684210527 0.7894736842105263\n",
            "0.5789473684210527 0.5789473684210527 0.8421052631578947\n",
            "0.5789473684210527 0.5789473684210527 0.894736842105263\n",
            "0.5789473684210527 0.5789473684210527 0.9473684210526315\n",
            "0.5789473684210527 0.5789473684210527 1.0\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.7368421052631579\n",
            "0.631578947368421 0.631578947368421 0.7894736842105263\n",
            "0.631578947368421 0.631578947368421 0.8421052631578947\n",
            "0.631578947368421 0.631578947368421 0.894736842105263\n",
            "0.631578947368421 0.631578947368421 0.9473684210526315\n",
            "0.631578947368421 0.631578947368421 1.0\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7894736842105263\n",
            "0.6842105263157894 0.6842105263157894 0.8421052631578947\n",
            "0.6842105263157894 0.6842105263157894 0.894736842105263\n",
            "0.6842105263157894 0.6842105263157894 0.9473684210526315\n",
            "0.6842105263157894 0.6842105263157894 1.0\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.8421052631578947\n",
            "0.7368421052631579 0.7368421052631579 0.894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.9473684210526315\n",
            "0.7368421052631579 0.7368421052631579 1.0\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.9473684210526315\n",
            "0.7894736842105263 0.7894736842105263 1.0\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.9473684210526315\n",
            "0.8421052631578947 0.8421052631578947 1.0\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n"
          ]
        }
      ],
      "source": [
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 < theta,0,1) == And.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WptuRnw6gBNN"
      },
      "outputs": [],
      "source": [
        "Or = np.array([[0],[1],[1],[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuMcHh8agcAY",
        "outputId": "a3649238-25be-471e-a600-d4ad075afa30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "W_or = np.array([0.5, 0.5])\n",
        "np.where(np.dot(data, W_or) < 0.4, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dt4OIuJtefI",
        "outputId": "b30aadad-f480-44f1-8ca4-4703d97dee9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n"
          ]
        }
      ],
      "source": [
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 < theta,0,1) == Or.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7-i5IdRim7n"
      },
      "outputs": [],
      "source": [
        "Nand = np.array([[1],[1],[1],[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7GA7keXg15J",
        "outputId": "1d9666ca-5269-4d35-8e7c-cf9f388dde4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.10526315789473684\n",
            "0.05263157894736842 0.05263157894736842 0.15789473684210525\n",
            "0.05263157894736842 0.05263157894736842 0.21052631578947367\n",
            "0.05263157894736842 0.05263157894736842 0.2631578947368421\n",
            "0.05263157894736842 0.05263157894736842 0.3157894736842105\n",
            "0.05263157894736842 0.05263157894736842 0.3684210526315789\n",
            "0.05263157894736842 0.05263157894736842 0.42105263157894735\n",
            "0.05263157894736842 0.05263157894736842 0.47368421052631576\n",
            "0.05263157894736842 0.05263157894736842 0.5263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.5789473684210527\n",
            "0.05263157894736842 0.05263157894736842 0.631578947368421\n",
            "0.05263157894736842 0.05263157894736842 0.6842105263157894\n",
            "0.05263157894736842 0.05263157894736842 0.7368421052631579\n",
            "0.05263157894736842 0.05263157894736842 0.7894736842105263\n",
            "0.05263157894736842 0.05263157894736842 0.8421052631578947\n",
            "0.05263157894736842 0.05263157894736842 0.894736842105263\n",
            "0.05263157894736842 0.05263157894736842 0.9473684210526315\n",
            "0.05263157894736842 0.05263157894736842 1.0\n",
            "0.10526315789473684 0.10526315789473684 0.10526315789473684\n",
            "0.10526315789473684 0.10526315789473684 0.10526315789473684\n",
            "0.10526315789473684 0.10526315789473684 0.15789473684210525\n",
            "0.10526315789473684 0.10526315789473684 0.21052631578947367\n",
            "0.10526315789473684 0.10526315789473684 0.2631578947368421\n",
            "0.10526315789473684 0.10526315789473684 0.3157894736842105\n",
            "0.10526315789473684 0.10526315789473684 0.3684210526315789\n",
            "0.10526315789473684 0.10526315789473684 0.42105263157894735\n",
            "0.10526315789473684 0.10526315789473684 0.47368421052631576\n",
            "0.10526315789473684 0.10526315789473684 0.5263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.5789473684210527\n",
            "0.10526315789473684 0.10526315789473684 0.631578947368421\n",
            "0.10526315789473684 0.10526315789473684 0.6842105263157894\n",
            "0.10526315789473684 0.10526315789473684 0.7368421052631579\n",
            "0.10526315789473684 0.10526315789473684 0.7894736842105263\n",
            "0.10526315789473684 0.10526315789473684 0.8421052631578947\n",
            "0.10526315789473684 0.10526315789473684 0.894736842105263\n",
            "0.10526315789473684 0.10526315789473684 0.9473684210526315\n",
            "0.10526315789473684 0.10526315789473684 1.0\n",
            "0.15789473684210525 0.15789473684210525 0.15789473684210525\n",
            "0.15789473684210525 0.15789473684210525 0.15789473684210525\n",
            "0.15789473684210525 0.15789473684210525 0.15789473684210525\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.2631578947368421\n",
            "0.15789473684210525 0.15789473684210525 0.3157894736842105\n",
            "0.15789473684210525 0.15789473684210525 0.3684210526315789\n",
            "0.15789473684210525 0.15789473684210525 0.42105263157894735\n",
            "0.15789473684210525 0.15789473684210525 0.47368421052631576\n",
            "0.15789473684210525 0.15789473684210525 0.5263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.5789473684210527\n",
            "0.15789473684210525 0.15789473684210525 0.631578947368421\n",
            "0.15789473684210525 0.15789473684210525 0.6842105263157894\n",
            "0.15789473684210525 0.15789473684210525 0.7368421052631579\n",
            "0.15789473684210525 0.15789473684210525 0.7894736842105263\n",
            "0.15789473684210525 0.15789473684210525 0.8421052631578947\n",
            "0.15789473684210525 0.15789473684210525 0.894736842105263\n",
            "0.15789473684210525 0.15789473684210525 0.9473684210526315\n",
            "0.15789473684210525 0.15789473684210525 1.0\n",
            "0.21052631578947367 0.21052631578947367 0.21052631578947367\n",
            "0.21052631578947367 0.21052631578947367 0.21052631578947367\n",
            "0.21052631578947367 0.21052631578947367 0.21052631578947367\n",
            "0.21052631578947367 0.21052631578947367 0.21052631578947367\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.3157894736842105\n",
            "0.21052631578947367 0.21052631578947367 0.3684210526315789\n",
            "0.21052631578947367 0.21052631578947367 0.42105263157894735\n",
            "0.21052631578947367 0.21052631578947367 0.47368421052631576\n",
            "0.21052631578947367 0.21052631578947367 0.5263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.5789473684210527\n",
            "0.21052631578947367 0.21052631578947367 0.631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.6842105263157894\n",
            "0.21052631578947367 0.21052631578947367 0.7368421052631579\n",
            "0.21052631578947367 0.21052631578947367 0.7894736842105263\n",
            "0.21052631578947367 0.21052631578947367 0.8421052631578947\n",
            "0.21052631578947367 0.21052631578947367 0.894736842105263\n",
            "0.21052631578947367 0.21052631578947367 0.9473684210526315\n",
            "0.21052631578947367 0.21052631578947367 1.0\n",
            "0.2631578947368421 0.2631578947368421 0.2631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.2631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.2631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.2631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.2631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3684210526315789\n",
            "0.2631578947368421 0.2631578947368421 0.42105263157894735\n",
            "0.2631578947368421 0.2631578947368421 0.47368421052631576\n",
            "0.2631578947368421 0.2631578947368421 0.5263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.5789473684210527\n",
            "0.2631578947368421 0.2631578947368421 0.631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.6842105263157894\n",
            "0.2631578947368421 0.2631578947368421 0.7368421052631579\n",
            "0.2631578947368421 0.2631578947368421 0.7894736842105263\n",
            "0.2631578947368421 0.2631578947368421 0.8421052631578947\n",
            "0.2631578947368421 0.2631578947368421 0.894736842105263\n",
            "0.2631578947368421 0.2631578947368421 0.9473684210526315\n",
            "0.2631578947368421 0.2631578947368421 1.0\n",
            "0.3157894736842105 0.3157894736842105 0.3157894736842105\n",
            "0.3157894736842105 0.3157894736842105 0.3157894736842105\n",
            "0.3157894736842105 0.3157894736842105 0.3157894736842105\n",
            "0.3157894736842105 0.3157894736842105 0.3157894736842105\n",
            "0.3157894736842105 0.3157894736842105 0.3157894736842105\n",
            "0.3157894736842105 0.3157894736842105 0.3157894736842105\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.42105263157894735\n",
            "0.3157894736842105 0.3157894736842105 0.47368421052631576\n",
            "0.3157894736842105 0.3157894736842105 0.5263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.5789473684210527\n",
            "0.3157894736842105 0.3157894736842105 0.631578947368421\n",
            "0.3157894736842105 0.3157894736842105 0.6842105263157894\n",
            "0.3157894736842105 0.3157894736842105 0.7368421052631579\n",
            "0.3157894736842105 0.3157894736842105 0.7894736842105263\n",
            "0.3157894736842105 0.3157894736842105 0.8421052631578947\n",
            "0.3157894736842105 0.3157894736842105 0.894736842105263\n",
            "0.3157894736842105 0.3157894736842105 0.9473684210526315\n",
            "0.3157894736842105 0.3157894736842105 1.0\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.3684210526315789\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.47368421052631576\n",
            "0.3684210526315789 0.3684210526315789 0.5263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.5789473684210527\n",
            "0.3684210526315789 0.3684210526315789 0.631578947368421\n",
            "0.3684210526315789 0.3684210526315789 0.6842105263157894\n",
            "0.3684210526315789 0.3684210526315789 0.7368421052631579\n",
            "0.3684210526315789 0.3684210526315789 0.7894736842105263\n",
            "0.3684210526315789 0.3684210526315789 0.8421052631578947\n",
            "0.3684210526315789 0.3684210526315789 0.894736842105263\n",
            "0.3684210526315789 0.3684210526315789 0.9473684210526315\n",
            "0.3684210526315789 0.3684210526315789 1.0\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.42105263157894735\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.5263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.5789473684210527\n",
            "0.42105263157894735 0.42105263157894735 0.631578947368421\n",
            "0.42105263157894735 0.42105263157894735 0.6842105263157894\n",
            "0.42105263157894735 0.42105263157894735 0.7368421052631579\n",
            "0.42105263157894735 0.42105263157894735 0.7894736842105263\n",
            "0.42105263157894735 0.42105263157894735 0.8421052631578947\n",
            "0.42105263157894735 0.42105263157894735 0.894736842105263\n",
            "0.42105263157894735 0.42105263157894735 0.9473684210526315\n",
            "0.42105263157894735 0.42105263157894735 1.0\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.47368421052631576\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5789473684210527\n",
            "0.47368421052631576 0.47368421052631576 0.631578947368421\n",
            "0.47368421052631576 0.47368421052631576 0.6842105263157894\n",
            "0.47368421052631576 0.47368421052631576 0.7368421052631579\n",
            "0.47368421052631576 0.47368421052631576 0.7894736842105263\n",
            "0.47368421052631576 0.47368421052631576 0.8421052631578947\n",
            "0.47368421052631576 0.47368421052631576 0.894736842105263\n",
            "0.47368421052631576 0.47368421052631576 0.9473684210526315\n",
            "0.47368421052631576 0.47368421052631576 1.0\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.631578947368421\n",
            "0.5263157894736842 0.5263157894736842 0.6842105263157894\n",
            "0.5263157894736842 0.5263157894736842 0.7368421052631579\n",
            "0.5263157894736842 0.5263157894736842 0.7894736842105263\n",
            "0.5263157894736842 0.5263157894736842 0.8421052631578947\n",
            "0.5263157894736842 0.5263157894736842 0.894736842105263\n",
            "0.5263157894736842 0.5263157894736842 0.9473684210526315\n",
            "0.5263157894736842 0.5263157894736842 1.0\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.5789473684210527\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.6842105263157894\n",
            "0.5789473684210527 0.5789473684210527 0.7368421052631579\n",
            "0.5789473684210527 0.5789473684210527 0.7894736842105263\n",
            "0.5789473684210527 0.5789473684210527 0.8421052631578947\n",
            "0.5789473684210527 0.5789473684210527 0.894736842105263\n",
            "0.5789473684210527 0.5789473684210527 0.9473684210526315\n",
            "0.5789473684210527 0.5789473684210527 1.0\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.631578947368421\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.7368421052631579\n",
            "0.631578947368421 0.631578947368421 0.7894736842105263\n",
            "0.631578947368421 0.631578947368421 0.8421052631578947\n",
            "0.631578947368421 0.631578947368421 0.894736842105263\n",
            "0.631578947368421 0.631578947368421 0.9473684210526315\n",
            "0.631578947368421 0.631578947368421 1.0\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.6842105263157894\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7894736842105263\n",
            "0.6842105263157894 0.6842105263157894 0.8421052631578947\n",
            "0.6842105263157894 0.6842105263157894 0.894736842105263\n",
            "0.6842105263157894 0.6842105263157894 0.9473684210526315\n",
            "0.6842105263157894 0.6842105263157894 1.0\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7368421052631579\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.8421052631578947\n",
            "0.7368421052631579 0.7368421052631579 0.894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.9473684210526315\n",
            "0.7368421052631579 0.7368421052631579 1.0\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.7894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.9473684210526315\n",
            "0.7894736842105263 0.7894736842105263 1.0\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.8421052631578947\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.9473684210526315\n",
            "0.8421052631578947 0.8421052631578947 1.0\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.894736842105263\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 1.0\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 0.9473684210526315\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n",
            "1.0 1.0 1.0\n"
          ]
        }
      ],
      "source": [
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 > theta,0,1) == Nand.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAUtytFyjMIS"
      },
      "outputs": [],
      "source": [
        "w1, w2, theta = 0.05263157894736836, 1.0, 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCpp9PSXp13A",
        "outputId": "fe169560-f691-4b70-e349-6e93bfc38e67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(np.dot(data, np.array([w1,w2]).reshape(2,1)) > theta, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVqMeVdCn8_j"
      },
      "outputs": [],
      "source": [
        "Nor = np.array([[1],[0],[0],[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3BqpveqpCsB",
        "outputId": "e0a740c8-65f7-4f45-dacb-a8b242444a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n"
          ]
        }
      ],
      "source": [
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 > theta,0,1) == Nor.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwtiMLoTpHYz"
      },
      "outputs": [],
      "source": [
        "w1, w2, theta = 0.5263157894736842, 0.5263157894736842, 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfAFGyetpNea",
        "outputId": "06c85462-9d36-4c13-d4b5-6df0897600ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(np.dot(data, np.array([w1,w2]).reshape(2,1)) > theta, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMnKAq0VpbsV"
      },
      "outputs": [],
      "source": [
        "XNor = np.array([[1],[0],[0],[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wesU7Lnorww7"
      },
      "outputs": [],
      "source": [
        "w11, w21, theta1 = -0.15789473684210525, -0.15789473684210525, -0.15789473684210525 # Nand\n",
        "w12, w22, theta2 = 0.9473684210526315, 0.9473684210526315, 0.05263157894736842 #Or"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP-mrPhwtq1o"
      },
      "outputs": [],
      "source": [
        "W1 = np.array([[w11, w12],[w21, w22]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_3e2UJnuG-l",
        "outputId": "def49923-fae0-4391-891a-8aacee2dbb2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.15789474,  0.94736842],\n",
              "       [-0.15789474,  0.94736842]])"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQLZjvXHuJjs"
      },
      "outputs": [],
      "source": [
        "b1 = np.array([theta1, theta2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwYJIPu_udZ1",
        "outputId": "7ada0ca1-3e60-4947-9d2e-25a4a48b8037"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.15789474,  0.05263158])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7-ei_vWueFN",
        "outputId": "7b9d9336-fb61-46b7-8bf5-9ecffe4a77b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 1]])"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l1 = np.where(np.dot(data, W1) < b1, 0, 1)\n",
        "l1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oxRUHkTu5Jp"
      },
      "outputs": [],
      "source": [
        "w1, w2, b2 = 0.15789473684210525, 0.15789473684210525, 0.21052631578947367 #And"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTtGvVYFAui2"
      },
      "outputs": [],
      "source": [
        "W2 = np.array([w1, w2]).reshape(2,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFZ1YcCnBVUD",
        "outputId": "d24b5e6f-060a-4474-c5a0-d4369f8e5241"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(np.dot(l1, W2) < b2, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WBK44SjBk6e"
      },
      "outputs": [],
      "source": [
        "Nor = np.array([[1],[0],[0],[0]])\n",
        "And = np.array([[0],[0],[0],[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6xLMozzDIDM",
        "outputId": "40816cd5-7aa8-419e-8bc1-9679cf58d0ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.10526315789473684\n",
            "0.05263157894736842 0.05263157894736842 0.15789473684210525\n",
            "0.05263157894736842 0.05263157894736842 0.21052631578947367\n",
            "0.05263157894736842 0.05263157894736842 0.2631578947368421\n",
            "0.05263157894736842 0.05263157894736842 0.3157894736842105\n",
            "0.05263157894736842 0.05263157894736842 0.3684210526315789\n",
            "0.05263157894736842 0.05263157894736842 0.42105263157894735\n",
            "0.05263157894736842 0.05263157894736842 0.47368421052631576\n",
            "0.05263157894736842 0.05263157894736842 0.5263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.5789473684210527\n",
            "0.05263157894736842 0.05263157894736842 0.631578947368421\n",
            "0.05263157894736842 0.05263157894736842 0.6842105263157894\n",
            "0.05263157894736842 0.05263157894736842 0.7894736842105263\n",
            "0.05263157894736842 0.05263157894736842 0.8421052631578947\n",
            "0.05263157894736842 0.05263157894736842 0.894736842105263\n",
            "0.05263157894736842 0.05263157894736842 1.0\n",
            "0.10526315789473684 0.10526315789473684 0.15789473684210525\n",
            "0.10526315789473684 0.10526315789473684 0.15789473684210525\n",
            "0.10526315789473684 0.10526315789473684 0.21052631578947367\n",
            "0.10526315789473684 0.10526315789473684 0.2631578947368421\n",
            "0.10526315789473684 0.10526315789473684 0.3157894736842105\n",
            "0.10526315789473684 0.10526315789473684 0.3684210526315789\n",
            "0.10526315789473684 0.10526315789473684 0.42105263157894735\n",
            "0.10526315789473684 0.10526315789473684 0.47368421052631576\n",
            "0.10526315789473684 0.10526315789473684 0.5263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.5789473684210527\n",
            "0.10526315789473684 0.10526315789473684 0.631578947368421\n",
            "0.10526315789473684 0.10526315789473684 0.6842105263157894\n",
            "0.10526315789473684 0.10526315789473684 0.7368421052631579\n",
            "0.10526315789473684 0.10526315789473684 0.7894736842105263\n",
            "0.10526315789473684 0.10526315789473684 0.8421052631578947\n",
            "0.10526315789473684 0.10526315789473684 0.894736842105263\n",
            "0.10526315789473684 0.10526315789473684 0.9473684210526315\n",
            "0.10526315789473684 0.10526315789473684 1.0\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.21052631578947367\n",
            "0.15789473684210525 0.15789473684210525 0.2631578947368421\n",
            "0.15789473684210525 0.15789473684210525 0.3157894736842105\n",
            "0.15789473684210525 0.15789473684210525 0.3684210526315789\n",
            "0.15789473684210525 0.15789473684210525 0.42105263157894735\n",
            "0.15789473684210525 0.15789473684210525 0.47368421052631576\n",
            "0.15789473684210525 0.15789473684210525 0.5263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.5789473684210527\n",
            "0.15789473684210525 0.15789473684210525 0.631578947368421\n",
            "0.15789473684210525 0.15789473684210525 0.6842105263157894\n",
            "0.15789473684210525 0.15789473684210525 0.7368421052631579\n",
            "0.15789473684210525 0.15789473684210525 0.7894736842105263\n",
            "0.15789473684210525 0.15789473684210525 0.8421052631578947\n",
            "0.15789473684210525 0.15789473684210525 0.894736842105263\n",
            "0.15789473684210525 0.15789473684210525 0.9473684210526315\n",
            "0.15789473684210525 0.15789473684210525 1.0\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.2631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.3157894736842105\n",
            "0.21052631578947367 0.21052631578947367 0.3684210526315789\n",
            "0.21052631578947367 0.21052631578947367 0.42105263157894735\n",
            "0.21052631578947367 0.21052631578947367 0.47368421052631576\n",
            "0.21052631578947367 0.21052631578947367 0.5263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.5789473684210527\n",
            "0.21052631578947367 0.21052631578947367 0.631578947368421\n",
            "0.21052631578947367 0.21052631578947367 0.6842105263157894\n",
            "0.21052631578947367 0.21052631578947367 0.7368421052631579\n",
            "0.21052631578947367 0.21052631578947367 0.7894736842105263\n",
            "0.21052631578947367 0.21052631578947367 0.8421052631578947\n",
            "0.21052631578947367 0.21052631578947367 0.894736842105263\n",
            "0.21052631578947367 0.21052631578947367 0.9473684210526315\n",
            "0.21052631578947367 0.21052631578947367 1.0\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3157894736842105\n",
            "0.2631578947368421 0.2631578947368421 0.3684210526315789\n",
            "0.2631578947368421 0.2631578947368421 0.42105263157894735\n",
            "0.2631578947368421 0.2631578947368421 0.47368421052631576\n",
            "0.2631578947368421 0.2631578947368421 0.5263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.5789473684210527\n",
            "0.2631578947368421 0.2631578947368421 0.631578947368421\n",
            "0.2631578947368421 0.2631578947368421 0.6842105263157894\n",
            "0.2631578947368421 0.2631578947368421 0.7368421052631579\n",
            "0.2631578947368421 0.2631578947368421 0.7894736842105263\n",
            "0.2631578947368421 0.2631578947368421 0.8421052631578947\n",
            "0.2631578947368421 0.2631578947368421 0.894736842105263\n",
            "0.2631578947368421 0.2631578947368421 0.9473684210526315\n",
            "0.2631578947368421 0.2631578947368421 1.0\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.3684210526315789\n",
            "0.3157894736842105 0.3157894736842105 0.42105263157894735\n",
            "0.3157894736842105 0.3157894736842105 0.47368421052631576\n",
            "0.3157894736842105 0.3157894736842105 0.5263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.5789473684210527\n",
            "0.3157894736842105 0.3157894736842105 0.631578947368421\n",
            "0.3157894736842105 0.3157894736842105 0.6842105263157894\n",
            "0.3157894736842105 0.3157894736842105 0.7368421052631579\n",
            "0.3157894736842105 0.3157894736842105 0.7894736842105263\n",
            "0.3157894736842105 0.3157894736842105 0.8421052631578947\n",
            "0.3157894736842105 0.3157894736842105 0.894736842105263\n",
            "0.3157894736842105 0.3157894736842105 0.9473684210526315\n",
            "0.3157894736842105 0.3157894736842105 1.0\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.42105263157894735\n",
            "0.3684210526315789 0.3684210526315789 0.47368421052631576\n",
            "0.3684210526315789 0.3684210526315789 0.5263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.5789473684210527\n",
            "0.3684210526315789 0.3684210526315789 0.631578947368421\n",
            "0.3684210526315789 0.3684210526315789 0.6842105263157894\n",
            "0.3684210526315789 0.3684210526315789 0.7368421052631579\n",
            "0.3684210526315789 0.3684210526315789 0.7894736842105263\n",
            "0.3684210526315789 0.3684210526315789 0.8421052631578947\n",
            "0.3684210526315789 0.3684210526315789 0.894736842105263\n",
            "0.3684210526315789 0.3684210526315789 0.9473684210526315\n",
            "0.3684210526315789 0.3684210526315789 1.0\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.47368421052631576\n",
            "0.42105263157894735 0.42105263157894735 0.5263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.5789473684210527\n",
            "0.42105263157894735 0.42105263157894735 0.631578947368421\n",
            "0.42105263157894735 0.42105263157894735 0.6842105263157894\n",
            "0.42105263157894735 0.42105263157894735 0.7368421052631579\n",
            "0.42105263157894735 0.42105263157894735 0.7894736842105263\n",
            "0.42105263157894735 0.42105263157894735 0.8421052631578947\n",
            "0.42105263157894735 0.42105263157894735 0.894736842105263\n",
            "0.42105263157894735 0.42105263157894735 0.9473684210526315\n",
            "0.42105263157894735 0.42105263157894735 1.0\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.5789473684210527\n",
            "0.47368421052631576 0.47368421052631576 0.631578947368421\n",
            "0.47368421052631576 0.47368421052631576 0.6842105263157894\n",
            "0.47368421052631576 0.47368421052631576 0.7368421052631579\n",
            "0.47368421052631576 0.47368421052631576 0.7894736842105263\n",
            "0.47368421052631576 0.47368421052631576 0.8421052631578947\n",
            "0.47368421052631576 0.47368421052631576 0.894736842105263\n",
            "0.47368421052631576 0.47368421052631576 0.9473684210526315\n",
            "0.47368421052631576 0.47368421052631576 1.0\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.5789473684210527\n",
            "0.5263157894736842 0.5263157894736842 0.631578947368421\n",
            "0.5263157894736842 0.5263157894736842 0.6842105263157894\n",
            "0.5263157894736842 0.5263157894736842 0.7368421052631579\n",
            "0.5263157894736842 0.5263157894736842 0.7894736842105263\n",
            "0.5263157894736842 0.5263157894736842 0.8421052631578947\n",
            "0.5263157894736842 0.5263157894736842 0.894736842105263\n",
            "0.5263157894736842 0.5263157894736842 0.9473684210526315\n",
            "0.5263157894736842 0.5263157894736842 1.0\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.631578947368421\n",
            "0.5789473684210527 0.5789473684210527 0.6842105263157894\n",
            "0.5789473684210527 0.5789473684210527 0.7368421052631579\n",
            "0.5789473684210527 0.5789473684210527 0.7894736842105263\n",
            "0.5789473684210527 0.5789473684210527 0.8421052631578947\n",
            "0.5789473684210527 0.5789473684210527 0.894736842105263\n",
            "0.5789473684210527 0.5789473684210527 0.9473684210526315\n",
            "0.5789473684210527 0.5789473684210527 1.0\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.6842105263157894\n",
            "0.631578947368421 0.631578947368421 0.7368421052631579\n",
            "0.631578947368421 0.631578947368421 0.7894736842105263\n",
            "0.631578947368421 0.631578947368421 0.8421052631578947\n",
            "0.631578947368421 0.631578947368421 0.894736842105263\n",
            "0.631578947368421 0.631578947368421 0.9473684210526315\n",
            "0.631578947368421 0.631578947368421 1.0\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7368421052631579\n",
            "0.6842105263157894 0.6842105263157894 0.7894736842105263\n",
            "0.6842105263157894 0.6842105263157894 0.8421052631578947\n",
            "0.6842105263157894 0.6842105263157894 0.894736842105263\n",
            "0.6842105263157894 0.6842105263157894 0.9473684210526315\n",
            "0.6842105263157894 0.6842105263157894 1.0\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.7894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.8421052631578947\n",
            "0.7368421052631579 0.7368421052631579 0.894736842105263\n",
            "0.7368421052631579 0.7368421052631579 0.9473684210526315\n",
            "0.7368421052631579 0.7368421052631579 1.0\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.8421052631578947\n",
            "0.7894736842105263 0.7894736842105263 0.894736842105263\n",
            "0.7894736842105263 0.7894736842105263 0.9473684210526315\n",
            "0.7894736842105263 0.7894736842105263 1.0\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.894736842105263\n",
            "0.8421052631578947 0.8421052631578947 0.9473684210526315\n",
            "0.8421052631578947 0.8421052631578947 1.0\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 0.9473684210526315\n",
            "0.894736842105263 0.894736842105263 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n",
            "0.9473684210526315 0.9473684210526315 1.0\n"
          ]
        }
      ],
      "source": [
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 < theta,0,1) == And.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNVpkpnMDOLW",
        "outputId": "358ba6a4-4ebe-488c-96ad-f68e038ee2ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.05263157894736842 0.05263157894736842 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.10526315789473684 0.10526315789473684 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.15789473684210525 0.15789473684210525 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.21052631578947367 0.21052631578947367 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.2631578947368421 0.2631578947368421 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3157894736842105 0.3157894736842105 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.3684210526315789 0.3684210526315789 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.42105263157894735 0.42105263157894735 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.47368421052631576 0.47368421052631576 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5263157894736842 0.5263157894736842 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.5789473684210527 0.5789473684210527 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.631578947368421 0.631578947368421 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.6842105263157894 0.6842105263157894 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7368421052631579 0.7368421052631579 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.7894736842105263 0.7894736842105263 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.8421052631578947 0.8421052631578947 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.894736842105263 0.894736842105263 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "0.9473684210526315 0.9473684210526315 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n",
            "1.0 1.0 0.0\n"
          ]
        }
      ],
      "source": [
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 > theta,0,1) == Nor.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCHqp3uHDQ7k"
      },
      "outputs": [],
      "source": [
        "w11, w12, theta1 = -0.15789473684210525, -0.15789473684210525, -0.21052631578947367\n",
        "w21, w22, theta2 = 0.21052631578947367, 0.21052631578947367, 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8GPO8EHDg6K"
      },
      "outputs": [],
      "source": [
        "W1 = np.array([[w11, w12],[w21, w22]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyi6M2-YDow7",
        "outputId": "19a6e787-aaf7-4244-db24-349574c1f184"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.15789474, -0.15789474],\n",
              "       [ 0.21052632,  0.21052632]])"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91XJLvWODpRb",
        "outputId": "e3387314-fbb4-4d14-d0fa-e2e08b111dc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.21052632,  0.        ])"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "theta = np.array([theta1, theta2])\n",
        "theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoHxi9_RDvfc",
        "outputId": "9515e83d-ed6b-4e5c-cae7-f988e340ce1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [1, 1]])"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l1 = np.where(np.dot(data, W1) < theta, 0, 1)\n",
        "l1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbfQJ789D8eb",
        "outputId": "9203ec6d-be13-4efe-e20f-1c663fa0ce7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.05263157894736842 0.05263157894736842 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.10526315789473684 0.10526315789473684 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.15789473684210525 0.15789473684210525 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.21052631578947367 0.21052631578947367 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.2631578947368421 0.2631578947368421 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3157894736842105 0.3157894736842105 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.3684210526315789 0.3684210526315789 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.42105263157894735 0.42105263157894735 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.47368421052631576 0.47368421052631576 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5263157894736842 0.5263157894736842 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.5789473684210527 0.5789473684210527 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.631578947368421 0.631578947368421 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.6842105263157894 0.6842105263157894 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7368421052631579 0.7368421052631579 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.7894736842105263 0.7894736842105263 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.8421052631578947 0.8421052631578947 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.894736842105263 0.894736842105263 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "0.9473684210526315 0.9473684210526315 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n",
            "1.0 1.0 0.05263157894736842\n"
          ]
        }
      ],
      "source": [
        "Or = np.array([[0],[1],[1],[1]])\n",
        "for w1 in np.linspace(0, 1, 20):\n",
        "  for w2 in np.linspace(0, 1, 20):\n",
        "    for theta in np.linspace(0, 1, 20):\n",
        "      if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 < theta,0,1) == Or.reshape(-1,)) == 4:\n",
        "        print(w1, w1, theta)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ_m4HyhEJN-"
      },
      "outputs": [],
      "source": [
        "w31, w32, theta3 = 0.21052631578947367, 0.21052631578947367, 0.05263157894736842"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aR0otoNEVLO"
      },
      "outputs": [],
      "source": [
        "W3 = np.array([w31, w32]).reshape(2,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztzZC82hEXSW",
        "outputId": "31615c18-5c88-4718-be1d-a7fe3671247b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.21052632],\n",
              "       [0.21052632]])"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPeYt6e_EYwA",
        "outputId": "81a32db0-e1e1-498a-c7e0-eb61a0fd4b2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(np.dot(l1, W3) < theta, 0, 1) # ????? 한참 잘못된건디?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhi9hw4IEe4I"
      },
      "outputs": [],
      "source": [
        "def make_w(method):\n",
        "  method_dict ={\n",
        "      'And': [0, 0, 0, 1],\n",
        "      'Nor' : [1, 0, 0, 0],\n",
        "      'Or' : [0, 1, 1, 1],\n",
        "      'Nand' : [1, 1, 1, 0]\n",
        "  }\n",
        "  data = np.array([[0,0],[1,0],[0, 1],[1, 1]])\n",
        "  for w1 in np.linspace(0, 1, 20):\n",
        "    for w2 in np.linspace(0, 1, 20):\n",
        "      for theta in np.linspace(-1, 1, 20):\n",
        "        if method in ['Nor', 'Nand']:\n",
        "           if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 > theta,0,1) == method_dict.get(method)) == 4:\n",
        "            return -w1, -w2, -theta\n",
        "        else:\n",
        "          if np.sum(np.where(data[:,0]*w1 + data[:,1]*w2 < theta,0,1) == method_dict.get(method)) == 4:\n",
        "            return w1, w2, theta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDrvPhbbHJyK"
      },
      "outputs": [],
      "source": [
        "w11, w21, b11 = make_w('Nor')\n",
        "w12, w22, b21 = make_w('And')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdZr9MpaHL1y"
      },
      "outputs": [],
      "source": [
        "X = np.array([[0,0],[1,0],[0, 1],[1, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERFfsyjpISz4"
      },
      "outputs": [],
      "source": [
        "W1 = np.array([[w11, w12], [w21, w22]])\n",
        "b1 = np.array([b11, b21])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMi18MnSIhHM"
      },
      "outputs": [],
      "source": [
        "l1 = np.where(np.dot(X, W1) < b1, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgL6NgCxI06V"
      },
      "outputs": [],
      "source": [
        "w1, w2, b2 = make_w('Or')\n",
        "W2 = np.array([w1, w2]).reshape(2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHtpUEovI92e",
        "outputId": "04cc6ab0-8dbe-41b0-f8a2-685323a55be9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = np.where(np.dot(l1, W2) < b2, 0, 1)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItCzsPqNJFgA"
      },
      "outputs": [],
      "source": [
        "W1 = np.random.randn(2, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4-JnaeaSqUH"
      },
      "outputs": [],
      "source": [
        "b1 = np.zeros(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3l6a88GISvoQ"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "oyRAlhRbS8XZ",
        "outputId": "ec413dde-a27f-4eb5-a88a-4e85fd3118ad"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = np.linspace(-5, 5)\n",
        "y = sigmoid(x)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLORlFZsTPK5",
        "outputId": "b5f02620-46d4-4932-9b0d-4750104d74a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5       , 0.5       ],\n",
              "       [0.43595063, 0.36512572],\n",
              "       [0.25382917, 0.31556397],\n",
              "       [0.20818414, 0.20958661]])"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sigmoid(np.dot(X, W1) + b1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxR7UWMNT57-"
      },
      "outputs": [],
      "source": [
        "W2 = np.random.randn(2, 1)\n",
        "b2 = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzWpEq4vTgkN",
        "outputId": "3f4e6ee3-8b03-454f-8ebb-d0aed533dcf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.62512794],\n",
              "       [0.60001201],\n",
              "       [0.57316437],\n",
              "       [0.55322703]])"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = sigmoid(np.dot(sigmoid(np.dot(X, W1) + b1), W2) + b2)\n",
        "y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKqGBr_6UApH",
        "outputId": "d8db34d6-f1a8-41f3-8029-ec73d6ca1ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 1)"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tiQ2NmZUONY"
      },
      "outputs": [],
      "source": [
        "y = np.array([0, 0, 0, 1]).reshape(4, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zykjbLqWL8H",
        "outputId": "43e20299-4738-4cd9-b64e-71824d495d85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHyIw22YUt4W"
      },
      "outputs": [],
      "source": [
        "W1 = np.random.randn(2, 1)\n",
        "b1 = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L_OTx1nUWGq"
      },
      "outputs": [],
      "source": [
        "y_hat = sigmoid(np.dot(X, W1) + b1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiWc1rsqUr7U",
        "outputId": "3d829949-bc3a-4754-ec04-076c6f0c916d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5       ],\n",
              "       [0.24235118],\n",
              "       [0.61990956],\n",
              "       [0.34283907]])"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfysDwE2U3Im"
      },
      "outputs": [],
      "source": [
        "def loss(y_hat):\n",
        "  loss_val = np.sum(-((1-y)*np.log(1-y_hat) + y*np.log(y_hat)))\n",
        "  return loss_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZDRQkj8VhHS"
      },
      "outputs": [],
      "source": [
        "fx = loss(y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5wHAo6aYvN5",
        "outputId": "95b7b38e-391b-4bc3-8660-8aa4e1db66fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1.13983214])"
            ]
          },
          "execution_count": 244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzIMGCK4cUsw"
      },
      "outputs": [],
      "source": [
        "tmp = W1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMFDiANEWFKF",
        "outputId": "7d592ae1-3c80-4f35-ba7a-cdd52cf244fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1.13982214])"
            ]
          },
          "execution_count": 246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " h = 1e-5\n",
        " W1[0] += h\n",
        " W1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZgSKsffYrYf",
        "outputId": "1dc00aa5-08be-4129-e620-be7aa071a22d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3.0085226548584343, 3.008518506781375)"
            ]
          },
          "execution_count": 247,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = sigmoid(np.dot(X, W1) + b1)\n",
        "fxh  = loss(y_hat)\n",
        "fx, fxh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1CUTFwBck8y"
      },
      "outputs": [],
      "source": [
        "dW1 = (fxh - fx)/h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVDBer3Wctzi",
        "outputId": "70949785-6042-4fb0-b8a5-f318d663f034"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-0.4148077059173971"
            ]
          },
          "execution_count": 249,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dW1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq2w5x97curB"
      },
      "outputs": [],
      "source": [
        "W1[0] = tmp\n",
        "tmp = W1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpIHpcpvdFw8"
      },
      "outputs": [],
      "source": [
        "W1[1] += h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPTg8E6VdI9_",
        "outputId": "98c6f60b-7784-4568-be5c-2104e189c77d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3.0085226548584343, 3.0085181343131993)"
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = sigmoid(np.dot(X, W1) + b1)\n",
        "fxh  = loss(y_hat)\n",
        "fx, fxh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fEsrqHYdhY5"
      },
      "outputs": [],
      "source": [
        "dW2 = (fxh - fx)/h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAAB_ZbGdkao"
      },
      "outputs": [],
      "source": [
        "W1[1] = tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWjW3ZVRdmrW"
      },
      "outputs": [],
      "source": [
        "tmp = b1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4SNcw9jdqk3"
      },
      "outputs": [],
      "source": [
        "b1 += h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1nPsNlrdxEo",
        "outputId": "7c862a37-0254-4635-8db4-e8ae115d0ad2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3.0085226548584343, 3.0085251854429673)"
            ]
          },
          "execution_count": 257,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = sigmoid(np.dot(X, W1) + b1)\n",
        "fxh  = loss(y_hat)\n",
        "fx, fxh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg6ktX4NdyxK"
      },
      "outputs": [],
      "source": [
        "db = (fxh - fx)/h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toUdliJsd2UB"
      },
      "outputs": [],
      "source": [
        "b1 = tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC02LBY2eGIK",
        "outputId": "33b19d28-0353-49ad-c62d-17fc3b2ca13c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.0085181343131993"
            ]
          },
          "execution_count": 262,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = sigmoid(np.dot(X, W1) + b1)\n",
        "loss(y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcNAJPDteTjj"
      },
      "outputs": [],
      "source": [
        "dW = np.array([dW1, dW2]).reshape(2,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMvbqv47eaUN"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "W1 -= dW*lr\n",
        "b1 -= db*lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOcTU33wetV3",
        "outputId": "890f7323-3448-44a1-f104-c9b7bb5b1176"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.0081508579615344"
            ]
          },
          "execution_count": 266,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = sigmoid(np.dot(X, W1) + b1)\n",
        "loss(y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLFQkJo_eujX",
        "outputId": "3777036c-3f1b-42c8-9617-6b91bb34d325"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.00036727635166489137"
            ]
          },
          "execution_count": 267,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "3.0085181343131993 - 3.0081508579615344"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lat5k573j_c7"
      },
      "outputs": [],
      "source": [
        "W = np.random.randn(2, 1)\n",
        "b = np.zeros(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "1dndYBYgez5_"
      },
      "outputs": [],
      "source": [
        "def gradient(W, b):\n",
        "  cols = W.shape[1]\n",
        "  rows = W.shape[0]\n",
        "  dW = np.zeros_like(W)\n",
        "  #dW = np.zeros((W.shape[0], W.shape[1]))\n",
        "  db = np.zeros_like(b)\n",
        "  h = 1e-5\n",
        "  for col in range(cols):\n",
        "    for row in range(rows):\n",
        "      y_hat = sigmoid(np.dot(X, W) + b)\n",
        "      fx = loss(y_hat)\n",
        "      tmp = W[row, col]\n",
        "      W[row, col] += h\n",
        "      y_hat = sigmoid(np.dot(X, W) + b)\n",
        "      fxh = loss(y_hat)\n",
        "      dv = (fxh - fx)/h\n",
        "      dW[row, col] = dv\n",
        "      W[row, col] = tmp\n",
        "  for idx in range(len(b)):\n",
        "    y_hat = sigmoid(np.dot(X, W) + b)\n",
        "    fx = loss(y_hat)\n",
        "    tmp = b[idx]\n",
        "    b[idx] += h\n",
        "    y_hat = sigmoid(np.dot(X, W) + b)\n",
        "    fxh = loss(y_hat)\n",
        "    db[idx] = (fxh-fx)/h\n",
        "    b[idx] = tmp\n",
        "  return dW, db\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlkT1NhlfgVc",
        "outputId": "3bf57a7e-5645-4a80-c380-f30b95e5d52f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[1.91427868],\n",
              "        [2.10145994]]),\n",
              " array([-3.28211037]))"
            ]
          },
          "execution_count": 306,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W = np.random.randn(2, 1)\n",
        "b = np.zeros(1)\n",
        "lr = 1e-4\n",
        "for _ in range(1000):\n",
        "  W -=  gradient(W, b)[0]*lr\n",
        "  b -= gradient(W, b)[1]*lr\n",
        "W, b\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjXIt03kniKU",
        "outputId": "beb5b86b-2587-439e-fc74-ce63d00181c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.03619003],\n",
              "       [0.2029704 ],\n",
              "       [0.23493527],\n",
              "       [0.67560096]])"
            ]
          },
          "execution_count": 307,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sigmoid(np.dot(X, W) + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoUYY4oCl3CH",
        "outputId": "1e7e189d-e3d9-4480-e150-f4e65d2926de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 311,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(sigmoid(np.dot(X, W) + b) > 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OYe0Umi6nF3f"
      },
      "outputs": [],
      "source": [
        "  y = np.array([[0],[1],[1],[1]]).reshape(4,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LCG78py0oA1m"
      },
      "outputs": [],
      "source": [
        "X = np.array([[0,0],[1,0],[0, 1],[1, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "y2lsecQYhI1u"
      },
      "outputs": [],
      "source": [
        "y1 = np.array([0, 0, 0, 1]).reshape(4, 1)\n",
        "y2 = np.array([1, 1, 1, 0]).reshape(4, 1)\n",
        "y3 = np.array([0, 1, 1, 1]).reshape(4, 1)\n",
        "y4 = np.array([1, 0, 0, 0]).reshape(4, 1)\n",
        "y5 = np.array([0, 1, 1, 0]).reshape(4, 1)\n",
        "y6 = np.array([1, 0, 0, 1]).reshape(4, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oZGqZlnVh430"
      },
      "outputs": [],
      "source": [
        "\n",
        "W = np.random.randn(X.shape[1], y1.shape[1])\n",
        "b = np.zeros(y1.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IUGKO1y4ielB"
      },
      "outputs": [],
      "source": [
        "y_hat = np.dot(X, W) + b\n",
        "y_hat = sigmoid(y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hZSMMw4jh8CF"
      },
      "outputs": [],
      "source": [
        "def loss(y_hat, y):\n",
        "  return -np.sum((1-y)*np.log(1-y_hat) + y*np.log(y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4iYnekQjGPU",
        "outputId": "4effa706-1cf1-4ff2-93a3-5b4d1dc6560e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.563921468779761"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss(y_hat, y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siqwxFG6jmdG",
        "outputId": "d1446dcd-c720-416c-d40f-7562ace8dde5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.5609579 ]\n",
            " [1.95802586]]\n",
            "[[0.79771473]\n",
            " [0.84754294]]\n"
          ]
        }
      ],
      "source": [
        "# (fxh - fx)/h ---> gradient\n",
        "print(W)\n",
        "y_hat = np.dot(X, W) + b\n",
        "y_hat = sigmoid(y_hat)\n",
        "fx = loss(y_hat, y1)\n",
        "h = 1e-5\n",
        "tmp = W[0, 0]\n",
        "W[0, 0] += h\n",
        "y_hat = np.dot(X, W) + b\n",
        "y_hat = sigmoid(y_hat)\n",
        "fxh = loss(y_hat, y1)\n",
        "dW1 = (fxh-fx)/h\n",
        "\n",
        "W[0, 0] = tmp\n",
        "tmp = W[1, 0]\n",
        "W[1,0] += h\n",
        "y_hat = np.dot(X, W) + b\n",
        "y_hat = sigmoid(y_hat)\n",
        "fxh = loss(y_hat, y1)\n",
        "dW2 = (fxh-fx)/h\n",
        "dW = np.array([dW1, dW2]).reshape(2,1)\n",
        "print(dW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIoF3TviqCRs",
        "outputId": "41286c7c-2af6-4345-8c59-d0e4e7f1885a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.563929944209187"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss(y_hat, y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mStvCy4zq_tw",
        "outputId": "c045c3d3-2d77-485c-8cff-2eda0322a3b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.562575388671844"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat = np.dot(X, W-(1e-3)*dW) + b\n",
        "y_hat = sigmoid(y_hat)\n",
        "loss(y_hat, y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lo3ipUQzrVPM"
      },
      "outputs": [],
      "source": [
        "def predict(x, W, b):\n",
        "  return sigmoid(np.dot(X, W) + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrHE0quBr34l",
        "outputId": "5b42f81d-ee82-4060-df90-d5c0b4e36120"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5       ],\n",
              "       [0.82649076],\n",
              "       [0.87632023],\n",
              "       [0.97122339]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(X, W, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "R_Cn3wXAr44l"
      },
      "outputs": [],
      "source": [
        "def loss(y_hat, y):\n",
        "  return -np.sum((1-y)*np.log(1-y_hat) + y*np.log(y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1UJk0cXXslL8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def gradient(x, y, W, b):\n",
        "  h = 1e-5\n",
        "  dW = np.zeros_like(W)\n",
        "  db = np.zeros_like(b)\n",
        "  cols = range(W.shape[1])\n",
        "  rows = range(W.shape[0])\n",
        "  for col in cols:\n",
        "    for row in rows:\n",
        "      y_hat = predict(x, W, b)\n",
        "      fx = loss(y_hat, y)\n",
        "      tmp = W[row, col]\n",
        "      W[row, col] += h\n",
        "      y_hat = predict(x, W, b)\n",
        "      fxh = loss(y_hat, y)\n",
        "      dW[row,col] = (fxh - fx)/h\n",
        "      W[row, col] = tmp\n",
        "  for i in range(db.size):\n",
        "    y_hat = predict(x, W, b)\n",
        "    fx = loss(y_hat, y)\n",
        "    tmp = b[i]\n",
        "    b[i] += h\n",
        "    y_hat = predict(x, W, b)\n",
        "    fxh = loss(y_hat, y)\n",
        "    db[i] = (fxh-fx)/h\n",
        "    b[i] = tmp\n",
        "    y_hat = predict(x, W, b)\n",
        "    fx = loss(y_hat, y)\n",
        "\n",
        "  return dW, db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJyO9pFW185x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i3sbGSR15gw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "btu7xEtz2EdR"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "W = np.random.randn(X.shape[1], y2.shape[1])\n",
        "b = np.zeros(y2.shape[1])\n",
        "for i in range(10000):\n",
        "    W = W - gradient(X, y2, W, b)[0]*lr\n",
        "    b = b - gradient(X ,y2, W, b)[1]*lr\n",
        "    y_hat = predict(X, W, b)\n",
        "    # if i % 100 == 0:\n",
        "    #   print(f'loss =====> {loss(y_hat, y1)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHegvgSW6faX",
        "outputId": "e0c09224-342b-4563-8112-0233480f5e74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH_Atwq36fuH",
        "outputId": "be3b1df5-9291-421d-85b9-9a0af8acf434"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "np.where(predict(X, W, b)>0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "q5gZYprJwMx6"
      },
      "outputs": [],
      "source": [
        "def descent_gradient(x, y, lr = 1e-3, epochs=10000):\n",
        "  W = np.random.randn(x.shape[1], y.shape[1])\n",
        "  b = np.zeros(y.shape[1])\n",
        "  for i in range(epochs):\n",
        "    W -= gradient(x, y, W, b)[0]*lr\n",
        "    b -= gradient(x ,y, W, b)[1]*lr\n",
        "    y_hat = predict(x, W, b)\n",
        "    if i % 100 == 0:\n",
        "      print(f'loss =====> {loss(y_hat, y)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScAAEhoWyYbS",
        "outputId": "ee279980-c7cb-4eb2-a720-0f443c0ca82b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss =====> 3.3904775195402994\n",
            "loss =====> 3.320029612937298\n",
            "loss =====> 3.252277681247807\n",
            "loss =====> 3.1870272901174985\n",
            "loss =====> 3.124110184678475\n",
            "loss =====> 3.0633803714208665\n",
            "loss =====> 3.004710667358\n",
            "loss =====> 2.9479896893615085\n",
            "loss =====> 2.8931192525833245\n",
            "loss =====> 2.84001214379008\n",
            "loss =====> 2.7885902336187076\n",
            "loss =====> 2.7387828911949557\n",
            "loss =====> 2.6905256651255973\n",
            "loss =====> 2.6437591963474665\n",
            "loss =====> 2.598428330456219\n",
            "loss =====> 2.5544813997281377\n",
            "loss =====> 2.5118696479032447\n",
            "loss =====> 2.4705467737572544\n",
            "loss =====> 2.4304685724198194\n",
            "loss =====> 2.3915926562266305\n",
            "loss =====> 2.3538782395242857\n",
            "loss =====> 2.317285974292945\n",
            "loss =====> 2.281777825604206\n",
            "loss =====> 2.2473169778833997\n",
            "loss =====> 2.213867764605316\n",
            "loss =====> 2.18139561549975\n",
            "loss =====> 2.14986701656565\n",
            "loss =====> 2.1192494791966916\n",
            "loss =====> 2.0895115155819948\n",
            "loss =====> 2.060622618207851\n",
            "loss =====> 2.032553241857708\n",
            "loss =====> 2.0052747869338456\n",
            "loss =====> 1.9787595832698694\n",
            "loss =====> 1.952980873874763\n",
            "loss =====> 1.9279127982416577\n",
            "loss =====> 1.903530375018644\n",
            "loss =====> 1.8798094839403903\n",
            "loss =====> 1.8567268470020153\n",
            "loss =====> 1.8342600089157504\n",
            "loss =====> 1.812387316919542\n",
            "loss =====> 1.7910879000360453\n",
            "loss =====> 1.7703416478881677\n",
            "loss =====> 1.7501291891836908\n",
            "loss =====> 1.73043186997866\n",
            "loss =====> 1.7112317318252044\n",
            "loss =====> 1.6925114899041118\n",
            "loss =====> 1.674254511231501\n",
            "loss =====> 1.656444793021427\n",
            "loss =====> 1.6390669412753127\n",
            "loss =====> 1.6221061496635378\n",
            "loss =====> 1.6055481787516324\n",
            "loss =====> 1.589379335617429\n",
            "loss =====> 1.5735864538980628\n",
            "loss =====> 1.5581568742975342\n",
            "loss =====> 1.5430784255815406\n",
            "loss =====> 1.5283394060772388\n",
            "loss =====> 1.5139285656922592\n",
            "loss =====> 1.4998350884666767\n",
            "loss =====> 1.4860485756600696\n",
            "loss =====> 1.4725590293771413\n",
            "loss =====> 1.4593568367328698\n",
            "loss =====> 1.4464327545552456\n",
            "loss =====> 1.4337778946182929\n",
            "loss =====> 1.4213837093991297\n",
            "loss =====> 1.409241978352131\n",
            "loss =====> 1.397344794689971\n",
            "loss =====> 1.3856845526594197\n",
            "loss =====> 1.3742539353026764\n",
            "loss =====> 1.3630459026904946\n",
            "loss =====> 1.3520536806139671\n",
            "loss =====> 1.3412707497227643\n",
            "loss =====> 1.3306908350979114\n",
            "loss =====> 1.3203078962406791\n",
            "loss =====> 1.3101161174694473\n",
            "loss =====> 1.3001098987076602\n",
            "loss =====> 1.290283846650452\n",
            "loss =====> 1.2806327662953887\n",
            "loss =====> 1.2711516528266968\n",
            "loss =====> 1.261835683835984\n",
            "loss =====> 1.25268021187063\n",
            "loss =====> 1.2436807572945312\n",
            "loss =====> 1.2348330014505582\n",
            "loss =====> 1.2261327801124784\n",
            "loss =====> 1.2175760772133915\n",
            "loss =====> 1.2091590188425239\n",
            "loss =====> 1.2008778674959384\n",
            "loss =====> 1.1927290165737072\n",
            "loss =====> 1.1847089851110757\n",
            "loss =====> 1.1768144127349045\n",
            "loss =====> 1.169042054836321\n",
            "loss =====> 1.1613887779489265\n",
            "loss =====> 1.1538515553254036\n",
            "loss =====> 1.1464274627030193\n",
            "loss =====> 1.139113674249889\n",
            "loss =====> 1.131907458684967\n",
            "loss =====> 1.1248061755636216\n",
            "loss =====> 1.1178072717213206\n",
            "loss =====> 1.1109082778695427\n",
            "loss =====> 1.1041068053358978\n",
            "loss =====> 1.0974005429435212\n"
          ]
        }
      ],
      "source": [
        "descent_gradient(X, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUZhXqfTxpPt",
        "outputId": "0907afe9-b0ad-44b2-d80b-160d3ad6daf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "np.where(predict(X, W, b)>0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "na7oxvG1ytpK"
      },
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "  def __init__(self, x, y):\n",
        "    self.x = x\n",
        "    if y.ndim == 1:\n",
        "      y = y.reshape(-1, 1)\n",
        "    self.y = y\n",
        "    self.W = np.random.randn(x.shape[1], y.shape[1])\n",
        "    self.b = np.zeros(y.shape[1])\n",
        "\n",
        "  def predict_proba(self):\n",
        "\n",
        "    self.y_hat = np.dot(self.x, self.W) + self.b\n",
        "    self.y_hat = sigmoid(self.y_hat)\n",
        "    return self.y_hat\n",
        "\n",
        "\n",
        "  def loss(self):\n",
        "    result = self.predict_proba()\n",
        "    return -np.sum((1-self.y)*np.log(1-result)+self.y*np.log(result))\n",
        "\n",
        "  def gradient(self):\n",
        "    h = 1e-5\n",
        "    self.dW = np.zeros_like(self.W)\n",
        "    self.db = np.zeros_like(self.b)\n",
        "    cols = range(self.W.shape[1])\n",
        "    rows = range(self.W.shape[0])\n",
        "    for col in cols:\n",
        "      for row in rows:\n",
        "        fx = self.loss()\n",
        "        tmp = self.W[row, col]\n",
        "        self.W[row, col] += h\n",
        "        fxh = self.loss()\n",
        "        self.dW[row, col] = (fxh-fx)/h\n",
        "        self.W[row, col] = tmp\n",
        "    for i in range(self.b.size):\n",
        "      fx = self.loss()\n",
        "      tmp = self.b[i]\n",
        "      self.b[i] += h\n",
        "      fxh = self.loss()\n",
        "      self.db[i] = (fxh-fx)/h\n",
        "      self.b[i] = tmp\n",
        "    return self.dW, self.db\n",
        "\n",
        "\n",
        "\n",
        "  def descent_gradient(self):\n",
        "    lr = 1e-3\n",
        "    dW, db = self.gradient()\n",
        "    self.W -= dW*lr\n",
        "    self.b -= db*lr\n",
        "\n",
        "  def fit(self, epoches=10000, lr=1e-3):\n",
        "    for epoche in range(epoches):\n",
        "      self.descent_gradient()\n",
        "      if epoche % 100 == 0:\n",
        "        print(self.loss())\n",
        "\n",
        "  def predict(self, x):\n",
        "    return np.where(sigmoid(np.dot(x, self.W)+self.b) > 0.5, 1, 0)\n",
        "\n",
        "  def score(self, x ,y):\n",
        "    if y.ndim == 1:\n",
        "      y = y.reshape(-1, 1)\n",
        "    return np.sum(self.predict(x) == y)/x.shape[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6tJO-CHbHcgp"
      },
      "outputs": [],
      "source": [
        "and_ = Perceptron(X, y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTdnI455M6Ea",
        "outputId": "b4c8c972-071a-4ed4-c879-5135be2a2cac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-0.0804938 ],\n",
              "        [ 0.17480522]]),\n",
              " array([1.06218765]))"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "and_.gradient()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYlL-y9lHlie",
        "outputId": "d5eb4c3d-9cac-4acd-a116-3bc5a629e354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8419929822030636\n",
            "2.736523030108265\n",
            "2.6491217789506787\n",
            "2.5753136828997\n",
            "2.5117719041660527\n",
            "2.4560377716503234\n",
            "2.4062978586595416\n",
            "2.3612138824093796\n",
            "2.319795875593391\n",
            "2.2813088344497094\n",
            "2.245204463191538\n",
            "2.2110714065781867\n",
            "2.1785989767371055\n",
            "2.147550687326747\n",
            "2.1177449071342425\n",
            "2.089040685602767\n",
            "2.061327342407885\n",
            "2.034516803082148\n",
            "2.008537943346431\n",
            "1.983332406716669\n",
            "1.9588515054163218\n",
            "1.9350539196809584\n",
            "1.911903986667809\n",
            "1.8893704255306798\n",
            "1.8674253856160619\n",
            "1.8460437343093155\n",
            "1.8252025227814275\n",
            "1.8048805838944104\n",
            "1.7850582283357657\n",
            "1.7657170137964613\n",
            "1.7468395684906985\n",
            "1.7284094551218794\n",
            "1.7104110649760174\n",
            "1.6928295344748832\n",
            "1.6756506785018395\n",
            "1.6588609362772562\n",
            "1.6424473266533406\n",
            "1.626397410510109\n",
            "1.6106992585349205\n",
            "1.5953414231162892\n",
            "1.5803129134111087\n",
            "1.5656031728945592\n",
            "1.551202058874749\n",
            "1.5370998235968925\n",
            "1.5232870966529133\n",
            "1.509754868487695\n",
            "1.4964944748469757\n",
            "1.483497582047529\n",
            "1.4707561729824894\n",
            "1.4582625337909623\n",
            "1.4460092411392502\n",
            "1.4339891500709694\n",
            "1.422195382390644\n",
            "1.410621315550827\n",
            "1.3992605720176927\n",
            "1.3881070090933187\n",
            "1.3771547091733325\n",
            "1.366397970422014\n",
            "1.3558312978474767\n",
            "1.3454493947602753\n",
            "1.3352471546000024\n",
            "1.3252196531147042\n",
            "1.3153621408787353\n",
            "1.3056700361351523\n",
            "1.2961389179491587\n",
            "1.2867645196594029\n",
            "1.2775427226150593\n",
            "1.268469550185774\n",
            "1.2595411620332428\n",
            "1.250753848633349\n",
            "1.2421040260368577\n",
            "1.233588230859712\n",
            "1.2252031154911078\n",
            "1.2169454435113\n",
            "1.2088120853084523\n",
            "1.200800013886641\n",
            "1.192906300855328\n",
            "1.185128112593406\n",
            "1.1774627065783982\n",
            "1.1699074278749968\n",
            "1.162459705774492\n",
            "1.1551170505782384\n",
            "1.1478770505194738\n",
            "1.140737368816558\n",
            "1.1336957408514847\n",
            "1.1267499714685516\n",
            "1.119897932387261\n",
            "1.1131375597243651\n",
            "1.1064668516200744\n",
            "1.0998838659639962\n",
            "1.0933867182157149\n",
            "1.086973579316184\n",
            "1.0806426736856365\n",
            "1.0743922773042622\n",
            "1.0682207158716506\n",
            "1.062126363041727\n",
            "1.0561076387296948\n",
            "1.0501630074875659\n",
            "1.0442909769457964\n",
            "1.0384900963173744\n"
          ]
        }
      ],
      "source": [
        "and_.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxr4V4TSHn-F",
        "outputId": "5c461d4e-37d7-4df5-b562-66f9a1e34130"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "and_.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7QeczI5dCt_",
        "outputId": "d24f0ccb-0c29-443d-c6b6-6e971e784c67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "and_.score(X, y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "xQxcu94-Lhry"
      },
      "outputs": [],
      "source": [
        "nand_ = Perceptron(X, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI2wcSVnLncx",
        "outputId": "92832cb4-88ef-4c3e-e424-d28c38101e98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.0692602747513043\n",
            "2.810635498753689\n",
            "2.609400047557525\n",
            "2.453318384203718\n",
            "2.33182432935389\n",
            "2.2363525530126336\n",
            "2.160250388709887\n",
            "2.0984940407393795\n",
            "2.047356395142244\n",
            "2.0041010099746193\n",
            "1.9667295760757049\n",
            "1.9337856275871594\n",
            "1.904207171021988\n",
            "1.8772182550618162\n",
            "1.852250096084088\n",
            "1.828884039104162\n",
            "1.8068104066488835\n",
            "1.7857988145397896\n",
            "1.765676733294363\n",
            "1.7463139734429132\n",
            "1.7276114303293755\n",
            "1.7094928973683494\n",
            "1.6918990952109438\n",
            "1.6747833055293921\n",
            "1.6581081700349962\n",
            "1.6418433379928188\n",
            "1.625963733216846\n",
            "1.6104482744453357\n",
            "1.59527892828355\n",
            "1.580440006591507\n",
            "1.5659176438830522\n",
            "1.5516994075135422\n",
            "1.5377740059742746\n",
            "1.5241310697792203\n",
            "1.5107609861421025\n",
            "1.4976547735682115\n",
            "1.4848039861099245\n",
            "1.4722006397022234\n",
            "1.4598371549651616\n",
            "1.4477063123128666\n",
            "1.4358012162845886\n",
            "1.4241152668064965\n",
            "1.4126421356860006\n",
            "1.4013757470724437\n",
            "1.3903102609452982\n",
            "1.379440058928028\n",
            "1.3687597319057834\n",
            "1.358264069056764\n",
            "1.347948048004671\n",
            "1.3378068258727418\n",
            "1.3278357310748845\n",
            "1.318030255718051\n",
            "1.3083860485206542\n",
            "1.298898908174436\n",
            "1.2895647770932817\n",
            "1.2803797355042286\n",
            "1.2713399958467775\n",
            "1.262441897450854\n",
            "1.2536819014725056\n",
            "1.2450565860661975\n",
            "1.2365626417794804\n",
            "1.2281968671551633\n",
            "1.219956164528471\n",
            "1.2118375360101026\n",
            "1.2038380796434303\n",
            "1.1959549857285805\n",
            "1.188185533304695\n",
            "1.1805270867823139\n",
            "1.172977092719885\n",
            "1.1655330767366436\n",
            "1.1581926405563536\n",
            "1.1509534591752564\n",
            "1.1438132781496901\n",
            "1.1367699109966811\n",
            "1.129821236703166\n",
            "1.1229651973390589\n",
            "1.1161997957691165\n",
            "1.109523093459327\n",
            "1.1029332083738923\n",
            "1.0964283129579662\n",
            "1.0900066322033144\n",
            "1.0836664417926776\n",
            "1.0774060663194795\n",
            "1.071223877578969\n",
            "1.065118292928854\n",
            "1.0590877737152304\n",
            "1.0531308237614057\n",
            "1.0472459879168108\n",
            "1.0414318506633249\n",
            "1.0356870347766742\n",
            "1.0300102000400329\n",
            "1.0244000420082062\n",
            "1.0188552908195194\n",
            "1.0133747100539283\n",
            "1.0079570956351795\n",
            "1.002601274774831\n",
            "0.9973061049566778\n",
            "0.99207047295986\n",
            "0.98689329391858\n",
            "0.9817735104177456\n"
          ]
        }
      ],
      "source": [
        "nand_.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzhoaYPdLo_N",
        "outputId": "1a4e9d58-7d34-44d3-d237-ad4d72b4e387"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nand_.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "0X_jFsD_LqM-"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "SQqBmvpNdlz6"
      },
      "outputs": [],
      "source": [
        "X = load_breast_cancer()['data']\n",
        "y = load_breast_cancer()['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1NqmvONd0wb",
        "outputId": "de8b9aaf-832f-446c-faac-bdc37d17f123"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8531468531468531"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tree_model = DecisionTreeClassifier()\n",
        "tree_model.fit(X_train, y_train)\n",
        "tree_model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "xJ8_3l1wzILa"
      },
      "outputs": [],
      "source": [
        "X = np.array([[0,0],[1,0],[0, 1],[1, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "zxivgFNUeMEc"
      },
      "outputs": [],
      "source": [
        "class MultiLayer:\n",
        "  def __init__(self, x, y):\n",
        "    self.Activation = {\n",
        "        'sigmoid':sigmoid,\n",
        "    }\n",
        "    self.x = x\n",
        "    if y.ndim == 1:\n",
        "      y = y.reshape(-1, 1)\n",
        "    self.y = y\n",
        "    self.W1 = np.random.randn(2,2)\n",
        "    self.b1 = np.zeros(2)\n",
        "    self.W2 = np.random.randn(2,1)\n",
        "    self.b2 = np.zeros(1)\n",
        "\n",
        "  def predict_proba(self):\n",
        "\n",
        "    x = (self.x-self.x.min(0))/self.x.max(0)\n",
        "    self.y_hat = np.dot(x, self.W1) + self.b1\n",
        "    self.y_hat = self.Activation['sigmoid'](self.y_hat)\n",
        "    self.y_hat = np.dot(self.y_hat, self.W2) + self.b2\n",
        "    self.y_hat = self.Activation['sigmoid'](self.y_hat)\n",
        "    return self.y_hat\n",
        "\n",
        "\n",
        "  def loss(self):\n",
        "    result = self.predict_proba()\n",
        "    return -np.sum((1-self.y)*np.log(1-result)+self.y*np.log(result))\n",
        "\n",
        "  def gradient(self):\n",
        "    h = 1e-5\n",
        "    self.dW1 = np.zeros_like(self.W1)\n",
        "    self.dW2 = np.zeros_like(self.W2)\n",
        "    self.db1 = np.zeros_like(self.b1)\n",
        "    self.db2 = np.zeros_like(self.b2)\n",
        "    for row in range(self.W1.shape[0]):\n",
        "      for col in range(self.W1.shape[1]):\n",
        "        fx = self.loss()\n",
        "        tmp = self.W1[row,col]\n",
        "        self.W1[row,col] += h\n",
        "        fxh = self.loss()\n",
        "        self.dW1[row,col] = (fxh-fx)/h\n",
        "        self.W1[row,col] = tmp\n",
        "\n",
        "    for row in range(self.W2.shape[0]):\n",
        "      for col in range(self.W2.shape[1]):\n",
        "        fx = self.loss()\n",
        "        tmp = self.W2[row,col]\n",
        "        self.W2[row,col] += h\n",
        "        fxh = self.loss()\n",
        "        self.dW2[row,col] = (fxh-fx)/h\n",
        "        self.W2[row,col] = tmp\n",
        "\n",
        "    for i in range(self.b1.size):\n",
        "      fx = self.loss()\n",
        "      tmp = self.b1[i]\n",
        "      self.b1[i] += h\n",
        "      fxh = self.loss()\n",
        "      self.db1[i] = (fxh-fx)/h\n",
        "      self.b1[i] = tmp\n",
        "\n",
        "    for i in range(self.b2.size):\n",
        "      fx = self.loss()\n",
        "      tmp = self.b2[i]\n",
        "      self.b2[i] += h\n",
        "      fxh = self.loss()\n",
        "      self.db2[i] = (fxh-fx)/h\n",
        "      self.b2[i] = tmp\n",
        "\n",
        "    return self.dW1, self.dW2, self.db1, self.db2\n",
        "\n",
        "\n",
        "  def descent_gradient(self):\n",
        "    dW1, dW2, db1, db2 = self.gradient()\n",
        "    self.W1 -= dW1*1e-3\n",
        "    self.W2 -= dW2*1e-3\n",
        "    self.b1 -= db1*1e-3\n",
        "    self.b2 -= db2*1e-3\n",
        "\n",
        "\n",
        "  def fit(self, epochs=1000):\n",
        "    self.history = []\n",
        "    for _ in range(epochs):\n",
        "      self.descent_gradient()\n",
        "      self.history.append(self.descent_gradient())\n",
        "\n",
        "  def predict(self, x):\n",
        "    x = (x-x.min(0))/x.max(0)\n",
        "    result = np.dot(x, self.W1) + self.b1\n",
        "    result = self.Activation['sigmoid'](result)\n",
        "    result = np.dot(result, self.W2) + self.b2\n",
        "    result = self.Activation['sigmoid'](result)\n",
        "    return np.where(result > 0.5, 1, 0)\n",
        "\n",
        "  def score(self, x, y):\n",
        "    return np.sum(self.predict(x) == y)/x.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QvPN5NqvfCt7"
      },
      "outputs": [],
      "source": [
        "model = MultiLayer(X, y5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "y7j91LjtxuKQ"
      },
      "outputs": [],
      "source": [
        "model.fit(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MBamtu_4u-2",
        "outputId": "ea7d8577-4b83-4b8d-f995-1b7cc9d66036"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(X, y5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0oSFpz11W-p",
        "outputId": "bdf5eb16-3774-43f5-aa7f-52a008ff7b2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt_2b1g41e3b",
        "outputId": "b00feb57-942e-4512-f379-a38a867a6cc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-0.03424537,  0.00397677],\n",
              "        [-0.0559335 ,  0.00291456]]),\n",
              " array([[-0.0410735 ],\n",
              "        [ 0.01374139]]),\n",
              " array([0.00055935, 0.00247074]),\n",
              " array([0.03096127]))"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.gradient()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDhRiiIe5Rqw",
        "outputId": "de8ea50b-f050-4dd9-f7d3-a04959ac21a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.6885624976398272"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h8YKlIvX5U6-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(Dense(10, activation='sigmoid', input_shape=(100,)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1010 (3.95 KB)\n",
            "Trainable params: 1010 (3.95 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(Dense(250, activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                1010      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 250)               2750      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3760 (14.69 KB)\n",
            "Trainable params: 3760 (14.69 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<keras.src.layers.core.dense.Dense at 0x20ce60c9d10>,\n",
              " <keras.src.layers.core.dense.Dense at 0x20ce79621d0>]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense/kernel:0' shape=(100, 10) dtype=float32, numpy=\n",
              " array([[ 3.37091684e-02,  2.19384879e-01,  8.87590945e-02,\n",
              "         -2.68568844e-02, -4.82946783e-02, -2.04167962e-02,\n",
              "          1.45337999e-01, -1.68928146e-01,  2.02397555e-01,\n",
              "         -7.30796009e-02],\n",
              "        [ 1.38451010e-01,  1.33597940e-01, -2.09814757e-01,\n",
              "         -4.88116890e-02,  5.18701077e-02, -1.48471773e-01,\n",
              "          2.16540337e-01, -1.78644150e-01,  6.27817214e-02,\n",
              "          4.74732518e-02],\n",
              "        [ 2.10342079e-01, -5.50450236e-02, -5.03012538e-02,\n",
              "         -7.45198876e-02,  2.24905133e-01,  2.01874971e-02,\n",
              "          1.18953079e-01,  6.95732236e-03,  7.07140565e-03,\n",
              "          1.42148286e-01],\n",
              "        [-1.66094184e-01, -2.16126665e-01, -1.94315791e-01,\n",
              "          1.09314948e-01, -2.26435959e-01, -4.32715416e-02,\n",
              "         -1.25482261e-01,  2.06176281e-01,  7.07326531e-02,\n",
              "          9.72098708e-02],\n",
              "        [-7.16869235e-02,  1.60155863e-01, -1.31971061e-01,\n",
              "         -1.59498304e-01, -8.79688561e-02,  1.00891113e-01,\n",
              "          1.03126198e-01, -1.84610039e-02,  7.54588544e-02,\n",
              "         -5.31985909e-02],\n",
              "        [ 3.92016470e-02, -1.67502612e-02,  1.34267986e-01,\n",
              "          9.73861217e-02,  1.60358042e-01,  8.21006298e-03,\n",
              "          1.98199660e-01, -9.37580615e-02,  1.78804964e-01,\n",
              "         -1.09226011e-01],\n",
              "        [ 1.55877769e-01,  1.12000436e-01, -9.78230536e-02,\n",
              "         -1.07682824e-01, -2.23847941e-01, -3.09310108e-02,\n",
              "         -7.28570968e-02, -1.36027321e-01, -1.25775546e-01,\n",
              "          3.23348641e-02],\n",
              "        [-1.40995204e-01, -2.89642364e-02, -1.75397843e-02,\n",
              "         -1.71326458e-01, -5.23821712e-02,  1.37184858e-01,\n",
              "          8.28786790e-02,  5.39154410e-02, -1.59195393e-01,\n",
              "         -8.26452672e-02],\n",
              "        [ 2.02407628e-01,  1.67214960e-01,  8.00541341e-02,\n",
              "          2.32750416e-01, -1.03445157e-01, -2.20441669e-01,\n",
              "          7.56848752e-02, -1.08299851e-02,  2.32119560e-02,\n",
              "          1.10886455e-01],\n",
              "        [ 2.10641623e-02,  3.00187171e-02,  9.89879370e-02,\n",
              "          2.03370452e-01, -2.14312524e-01, -2.10983038e-01,\n",
              "          5.07133007e-02,  5.51347733e-02,  1.10610723e-02,\n",
              "         -6.99858814e-02],\n",
              "        [ 5.24847209e-03,  1.42475814e-01, -3.20886523e-02,\n",
              "         -1.69173390e-01, -1.74913198e-01,  1.85811847e-01,\n",
              "         -8.51659477e-03, -1.15456946e-01, -4.97679263e-02,\n",
              "         -4.18127775e-02],\n",
              "        [ 1.82398766e-01,  2.28096813e-01,  2.24409699e-02,\n",
              "         -9.08897966e-02,  7.30333924e-02,  2.18849182e-02,\n",
              "          1.31070614e-04,  2.80494988e-02, -1.63132876e-01,\n",
              "         -3.16905677e-02],\n",
              "        [ 5.79194129e-02, -4.33217734e-02, -2.32147768e-01,\n",
              "         -1.25835121e-01, -1.54717237e-01, -2.06573084e-01,\n",
              "         -4.76938039e-02, -1.76112354e-03,  1.94885820e-01,\n",
              "         -1.92306429e-01],\n",
              "        [ 1.69291466e-01,  6.31593764e-02, -1.69709548e-01,\n",
              "         -4.23775017e-02,  1.78504288e-01,  6.81096613e-02,\n",
              "         -5.18499017e-02, -2.32102439e-01,  5.05588353e-02,\n",
              "          1.15970075e-01],\n",
              "        [-1.08868249e-01, -2.21798718e-01, -2.32573301e-02,\n",
              "          9.00633037e-02,  1.15499824e-01,  1.22174710e-01,\n",
              "         -3.72583270e-02, -2.10500598e-01, -1.85539097e-01,\n",
              "         -4.19061631e-02],\n",
              "        [ 1.74041986e-01, -3.40590328e-02, -1.16396867e-01,\n",
              "         -9.30525064e-02, -1.24260753e-01, -1.14923172e-01,\n",
              "         -9.29739922e-02,  9.49257612e-02, -2.30251998e-02,\n",
              "         -7.90826827e-02],\n",
              "        [ 1.21378124e-01, -1.94009840e-02,  2.06564456e-01,\n",
              "          2.24053025e-01,  1.27840072e-01,  8.36855769e-02,\n",
              "          6.12973869e-02,  8.56043994e-02,  8.00922811e-02,\n",
              "          1.04779035e-01],\n",
              "        [-1.46627888e-01, -1.08685888e-01,  8.43009353e-02,\n",
              "         -1.74417838e-01, -1.36242151e-01,  9.23936069e-03,\n",
              "         -1.35884210e-01,  2.00887054e-01, -2.82606930e-02,\n",
              "         -7.46691823e-02],\n",
              "        [ 5.58480620e-02, -1.68347552e-01,  9.47303176e-02,\n",
              "         -5.82383573e-03,  1.28590137e-01,  7.43984878e-02,\n",
              "         -4.27705795e-02, -1.21030770e-01, -2.12219134e-01,\n",
              "          3.17923725e-02],\n",
              "        [-2.00024143e-01,  2.30065286e-02,  1.63698733e-01,\n",
              "         -1.72558382e-01,  5.92868030e-02, -6.72224164e-02,\n",
              "         -1.92068607e-01, -1.42693460e-01,  2.79825032e-02,\n",
              "         -1.83876693e-01],\n",
              "        [ 1.19843006e-01, -1.43689245e-01,  1.50474846e-01,\n",
              "         -1.19418152e-01,  2.14376658e-01, -1.98735267e-01,\n",
              "         -8.11100006e-03,  2.13242352e-01,  8.91014338e-02,\n",
              "         -2.24552214e-01],\n",
              "        [ 1.41158760e-01, -1.45032644e-01, -7.33854175e-02,\n",
              "          1.44375354e-01, -1.78062320e-01,  1.60307586e-01,\n",
              "         -1.26194447e-01,  6.80473447e-02, -1.88969150e-01,\n",
              "          1.82361305e-01],\n",
              "        [ 2.02541500e-01, -1.42955571e-01, -2.24722162e-01,\n",
              "         -1.91952229e-01, -1.89426422e-01,  1.13638699e-01,\n",
              "         -2.22331822e-01,  1.52932167e-01, -1.33061320e-01,\n",
              "          2.30006754e-01],\n",
              "        [ 1.96418822e-01, -1.72491223e-01, -1.42316103e-01,\n",
              "         -1.56508878e-01,  1.85354352e-01, -2.03486383e-01,\n",
              "         -1.08122945e-01, -2.04849273e-01,  6.95159733e-02,\n",
              "         -1.76076621e-01],\n",
              "        [ 1.89272285e-01, -6.76882565e-02, -1.84375063e-01,\n",
              "          1.02068931e-02,  8.06289315e-02, -1.63265571e-01,\n",
              "         -1.02837548e-01,  1.89733326e-01,  6.97812438e-02,\n",
              "         -2.17901707e-01],\n",
              "        [ 1.33972466e-01,  7.32391477e-02,  6.18638098e-02,\n",
              "          4.49425280e-02, -2.04265654e-01,  4.21516597e-02,\n",
              "         -6.98457211e-02,  2.09311545e-01,  1.29964918e-01,\n",
              "         -1.15168244e-02],\n",
              "        [ 8.25180113e-02,  3.41110826e-02,  1.56737894e-01,\n",
              "          3.33668888e-02, -8.37317407e-02, -8.87244940e-04,\n",
              "         -2.03449294e-01, -4.13978100e-03,  1.43432260e-01,\n",
              "          7.07291067e-03],\n",
              "        [-1.48853183e-01,  5.83216548e-02,  1.17797911e-01,\n",
              "          9.84514952e-02,  2.07414329e-01, -8.73728245e-02,\n",
              "         -2.19032615e-01, -1.93658903e-01,  1.28601611e-01,\n",
              "         -1.35781378e-01],\n",
              "        [ 1.21283561e-01,  6.87948763e-02, -7.60853440e-02,\n",
              "          1.57276511e-01,  1.56877041e-01, -8.26183110e-02,\n",
              "          1.93502605e-01,  6.20118082e-02, -1.58435762e-01,\n",
              "          4.54030335e-02],\n",
              "        [ 1.71253502e-01,  1.39616996e-01, -1.29393786e-01,\n",
              "         -2.28264123e-01, -6.53634965e-02, -2.19703928e-01,\n",
              "          1.35276884e-01,  1.91918761e-01, -1.19379893e-01,\n",
              "         -1.73916638e-01],\n",
              "        [-2.04943374e-01, -4.83564287e-02,  2.00338811e-01,\n",
              "         -3.58650386e-02,  6.39405251e-02, -2.16249719e-01,\n",
              "         -1.29678115e-01, -1.82538703e-01, -1.67275608e-01,\n",
              "          1.37169361e-01],\n",
              "        [ 1.30814701e-01, -1.33349434e-01,  2.31526613e-01,\n",
              "         -1.02771670e-02, -1.62704855e-01, -4.57770973e-02,\n",
              "         -7.14366287e-02,  1.41482890e-01,  1.67886883e-01,\n",
              "         -2.32751757e-01],\n",
              "        [-1.60696372e-01,  1.82060987e-01, -2.16339082e-02,\n",
              "         -1.34849906e-01, -1.75001949e-01, -2.41923034e-02,\n",
              "          2.02430427e-01, -7.84399509e-02,  7.57321715e-03,\n",
              "         -2.03962862e-01],\n",
              "        [-2.20704108e-01, -2.10485622e-01, -5.07795066e-02,\n",
              "         -9.11455452e-02, -2.17992812e-01,  3.92812490e-03,\n",
              "         -6.49383068e-02, -1.81681022e-01, -1.69578969e-01,\n",
              "         -1.06776640e-01],\n",
              "        [-5.46095818e-02, -1.62861198e-01,  1.42385602e-01,\n",
              "         -8.57602507e-02,  2.19909132e-01,  1.28270000e-01,\n",
              "         -1.33461863e-01, -2.13205993e-01,  2.03339726e-01,\n",
              "         -1.25276804e-01],\n",
              "        [-6.51300848e-02, -9.72548127e-02,  1.99265242e-01,\n",
              "         -2.12333009e-01,  1.23701245e-01, -2.86039710e-02,\n",
              "          6.20804131e-02, -7.84590989e-02, -1.80848405e-01,\n",
              "         -2.67869383e-02],\n",
              "        [-8.19144249e-02,  1.82780713e-01, -7.67048150e-02,\n",
              "         -8.95058066e-02, -2.01547295e-01,  3.87637019e-02,\n",
              "          2.79295444e-02, -1.99160904e-01,  1.20140612e-03,\n",
              "         -1.69260636e-01],\n",
              "        [-1.80252984e-01, -8.62007588e-02,  1.85866952e-01,\n",
              "          1.81565583e-01, -1.58118099e-01,  1.60304993e-01,\n",
              "          9.17284191e-02, -2.22173393e-01,  1.00083947e-02,\n",
              "          1.40961230e-01],\n",
              "        [ 1.65198147e-01,  2.37696171e-02, -8.03579837e-02,\n",
              "         -4.67985421e-02,  1.05001271e-01,  1.50088519e-02,\n",
              "          2.57914960e-02, -7.90998340e-02,  1.71601146e-01,\n",
              "         -2.19940752e-01],\n",
              "        [ 2.95800865e-02, -2.23618135e-01, -1.38864294e-01,\n",
              "         -9.99459475e-02, -1.50844842e-01, -5.59954643e-02,\n",
              "         -1.47439122e-01, -9.34326649e-03,  1.92376077e-02,\n",
              "          1.59672379e-01],\n",
              "        [-7.88820684e-02,  2.30380386e-01, -4.95306104e-02,\n",
              "          2.54949331e-02,  1.83717489e-01,  2.21698314e-01,\n",
              "          1.71978503e-01,  1.94694221e-01, -1.32442534e-01,\n",
              "         -1.85725421e-01],\n",
              "        [ 1.77034438e-01, -2.43326724e-02, -5.98385632e-02,\n",
              "         -9.89488363e-02,  2.58423984e-02,  1.42943710e-01,\n",
              "         -5.26748896e-02,  1.01684123e-01,  6.37871921e-02,\n",
              "          5.93822598e-02],\n",
              "        [ 1.36934876e-01, -1.31455958e-02, -1.46676615e-01,\n",
              "          1.04248106e-01, -9.26880538e-03,  2.33161747e-01,\n",
              "         -1.49804860e-01,  1.32133871e-01,  6.22448325e-03,\n",
              "          1.40647918e-01],\n",
              "        [ 1.94327205e-01, -1.07650027e-01, -7.70406425e-02,\n",
              "         -6.95339590e-02, -1.54427856e-01,  2.18853652e-01,\n",
              "          8.00592601e-02, -1.95729688e-01,  9.29921865e-02,\n",
              "         -1.23272441e-01],\n",
              "        [ 3.79033685e-02, -1.05663657e-01,  2.04443961e-01,\n",
              "         -1.48980647e-01, -2.54741758e-02, -1.12096891e-01,\n",
              "          1.66614324e-01, -6.83095604e-02,  2.02994764e-01,\n",
              "          1.53256446e-01],\n",
              "        [-1.03429571e-01,  2.77127326e-03,  5.26850224e-02,\n",
              "         -1.37333691e-01, -2.27349311e-01,  1.82104886e-01,\n",
              "          1.44743711e-01, -2.04685509e-01, -8.09425414e-02,\n",
              "          1.06949538e-01],\n",
              "        [ 7.60752261e-02,  2.06565857e-03,  3.88605893e-02,\n",
              "         -3.45581770e-02,  2.18883395e-01,  2.13191241e-01,\n",
              "          1.02037549e-01, -1.32635802e-01,  1.32227719e-01,\n",
              "         -1.41796872e-01],\n",
              "        [ 1.41877264e-01,  1.65720433e-01,  4.34579253e-02,\n",
              "          7.79764950e-02,  2.11195916e-01,  4.14673984e-03,\n",
              "         -2.59949714e-02,  1.92484260e-03, -1.47052109e-03,\n",
              "         -6.13772422e-02],\n",
              "        [ 9.47352350e-02,  1.19527340e-01,  2.01567888e-01,\n",
              "         -1.01946741e-01, -1.91308096e-01,  1.57825947e-01,\n",
              "         -1.20496780e-01, -1.80439353e-02,  8.51111114e-02,\n",
              "         -1.64465308e-01],\n",
              "        [-8.12240243e-02, -8.45963806e-02,  6.28108382e-02,\n",
              "         -1.73187539e-01, -4.73189503e-02, -1.22411199e-01,\n",
              "          8.95975232e-02,  6.29538894e-02,  1.40685946e-01,\n",
              "          1.74168169e-01],\n",
              "        [ 1.37804270e-01, -1.28051072e-01, -1.20533414e-01,\n",
              "          1.84613466e-02, -2.20684946e-01,  3.93311083e-02,\n",
              "          1.08094603e-01, -2.29881763e-01, -2.98351049e-04,\n",
              "         -1.28413439e-02],\n",
              "        [-2.01129109e-01, -1.09225065e-01,  1.97492480e-01,\n",
              "         -1.35327220e-01, -8.96275789e-02,  5.33965826e-02,\n",
              "          2.13120908e-01,  1.47630513e-01, -1.27205461e-01,\n",
              "         -1.01176366e-01],\n",
              "        [ 2.81991661e-02,  4.26920056e-02,  4.39094901e-02,\n",
              "         -2.08515242e-01, -2.33036339e-01,  7.47244060e-03,\n",
              "          3.44773233e-02, -1.46190897e-01, -2.37115920e-02,\n",
              "          2.35099196e-02],\n",
              "        [ 1.28790081e-01, -1.72056347e-01,  1.39355302e-01,\n",
              "          1.14646941e-01,  1.83530033e-01, -5.19057512e-02,\n",
              "          9.37972963e-03, -1.40271217e-01, -5.01978546e-02,\n",
              "          6.09164238e-02],\n",
              "        [ 1.19226784e-01, -1.88009515e-01,  1.38548791e-01,\n",
              "         -8.82629156e-02, -1.10957846e-01, -1.54878944e-02,\n",
              "         -8.90206397e-02, -1.87358752e-01, -1.37636542e-01,\n",
              "          2.13050932e-01],\n",
              "        [-1.70070812e-01,  2.12898403e-01, -1.17692493e-01,\n",
              "          1.78838044e-01,  2.16409206e-01,  1.54199451e-01,\n",
              "          1.95047349e-01, -3.79192829e-02, -2.28345394e-02,\n",
              "          9.56956446e-02],\n",
              "        [-1.32383227e-01,  1.31766200e-01, -1.67970136e-01,\n",
              "          1.30955577e-01,  5.36893010e-02,  2.04975843e-01,\n",
              "          2.13515699e-01, -2.11067557e-01,  2.20974505e-01,\n",
              "          2.12881595e-01],\n",
              "        [ 2.41161883e-03, -1.79222524e-01,  1.63496554e-01,\n",
              "          2.04229683e-01,  1.45847052e-01,  4.30395603e-02,\n",
              "         -1.55078381e-01,  8.22609961e-02, -1.06243268e-01,\n",
              "         -2.33440161e-01],\n",
              "        [ 1.36552602e-02, -9.42730606e-02, -2.96966881e-02,\n",
              "          1.13027900e-01, -9.31639820e-02,  3.64387929e-02,\n",
              "         -3.70449573e-02, -1.86017245e-01, -3.59012932e-02,\n",
              "          2.32289076e-01],\n",
              "        [-1.80246681e-02,  4.01932597e-02,  8.76449943e-02,\n",
              "         -1.28659278e-01, -1.75766468e-01, -3.98289710e-02,\n",
              "          1.29765540e-01,  3.14644575e-02, -1.72863752e-02,\n",
              "         -1.01362467e-01],\n",
              "        [ 2.59327590e-02,  1.61740035e-02, -1.35093018e-01,\n",
              "         -2.14246705e-01, -1.49161056e-01,  1.40988857e-01,\n",
              "          1.45934135e-01,  3.19218934e-02,  2.11673498e-01,\n",
              "          1.76331699e-02],\n",
              "        [-2.30270326e-02, -2.06654161e-01, -1.77529946e-01,\n",
              "          1.35604739e-01, -6.20756745e-02, -1.57471687e-01,\n",
              "         -1.49014771e-01,  1.19056612e-01, -1.48729414e-01,\n",
              "         -1.92002013e-01],\n",
              "        [-1.37356743e-01,  1.07418269e-01, -1.05673850e-01,\n",
              "          4.71078455e-02, -1.48790091e-01, -7.29764849e-02,\n",
              "          2.32824415e-01,  1.30835980e-01, -3.84739339e-02,\n",
              "          1.60805136e-02],\n",
              "        [-1.03911713e-01,  7.24009573e-02,  3.30180526e-02,\n",
              "          7.61771202e-02, -2.90288925e-02,  8.47887695e-02,\n",
              "         -2.19081238e-01,  7.25922287e-02, -9.81911123e-02,\n",
              "         -1.79943442e-03],\n",
              "        [-6.90909475e-02,  1.21896476e-01,  1.17395431e-01,\n",
              "          2.00885326e-01,  7.03629553e-02, -1.25821978e-02,\n",
              "         -1.75965279e-02,  8.68362188e-02, -8.21938366e-02,\n",
              "          3.52822542e-02],\n",
              "        [ 1.91967994e-01, -5.63948154e-02, -1.25053674e-01,\n",
              "          2.62203813e-02,  4.48251367e-02,  1.07296556e-01,\n",
              "          8.15111697e-02, -5.96109927e-02, -6.22313023e-02,\n",
              "         -1.86440498e-01],\n",
              "        [ 1.17017835e-01, -6.65117353e-02, -3.01301479e-04,\n",
              "         -5.70268780e-02,  1.01706982e-01,  9.30141509e-02,\n",
              "         -7.82664418e-02,  4.06340957e-02, -1.28620982e-01,\n",
              "         -2.01171651e-01],\n",
              "        [-1.85212523e-01,  9.55647230e-02,  1.47141844e-01,\n",
              "          1.57276362e-01, -1.92791983e-01, -2.05975175e-01,\n",
              "          5.70634007e-02, -1.94616139e-01,  7.30499625e-03,\n",
              "         -7.59576112e-02],\n",
              "        [-2.20698535e-01,  5.27590215e-02, -2.98118442e-02,\n",
              "          2.24468201e-01,  2.26535469e-01, -3.13542783e-03,\n",
              "         -1.84255838e-01,  1.88065410e-01,  1.21947199e-01,\n",
              "          3.15098166e-02],\n",
              "        [ 8.36029947e-02,  1.38679475e-01,  1.56668305e-01,\n",
              "          4.56622839e-02, -1.91670984e-01,  8.50725770e-02,\n",
              "          3.68673205e-02, -9.58113372e-03, -1.92085594e-01,\n",
              "          1.00792110e-01],\n",
              "        [-1.55305624e-01,  2.04655945e-01, -8.37942660e-02,\n",
              "         -1.68234795e-01,  2.08778501e-01,  1.99439824e-01,\n",
              "         -5.83780706e-02, -1.63234830e-01,  1.82966024e-01,\n",
              "         -1.09912798e-01],\n",
              "        [ 2.10855305e-01, -2.29284674e-01,  3.43628824e-02,\n",
              "         -1.77512348e-01,  1.48581415e-01,  6.90334439e-02,\n",
              "         -2.21184641e-02,  2.14150429e-01, -8.84892046e-02,\n",
              "          2.09030479e-01],\n",
              "        [ 1.85687929e-01, -1.01160169e-01, -1.28458500e-01,\n",
              "         -1.15869664e-01, -6.86089545e-02,  2.00989008e-01,\n",
              "          1.78341687e-01,  1.61975682e-01,  1.62968546e-01,\n",
              "         -1.82134166e-01],\n",
              "        [ 3.27938795e-02,  2.31903553e-01,  1.88939273e-02,\n",
              "         -1.31162554e-01,  1.46637350e-01,  1.86297446e-01,\n",
              "          4.99573350e-03, -5.48813045e-02, -1.49337903e-01,\n",
              "          2.46309638e-02],\n",
              "        [-2.62140781e-02, -1.94008917e-01,  1.77668989e-01,\n",
              "         -3.87426019e-02, -2.21088976e-01,  1.08100057e-01,\n",
              "         -1.17981538e-01,  7.25644827e-03,  8.05998147e-02,\n",
              "         -1.29811302e-01],\n",
              "        [ 4.46678996e-02,  1.73638225e-01,  1.97731465e-01,\n",
              "         -8.85307938e-02,  7.71848559e-02, -1.45599097e-01,\n",
              "          9.03399885e-02,  1.12747252e-01, -1.44649655e-01,\n",
              "          9.54319239e-02],\n",
              "        [ 2.01428801e-01,  1.96202040e-01,  1.92994207e-01,\n",
              "          8.24865103e-02, -1.98520333e-01, -9.20803398e-02,\n",
              "         -1.30090714e-02, -3.49816978e-02, -1.68242976e-01,\n",
              "         -1.14429824e-01],\n",
              "        [-9.62935388e-03, -1.77833691e-01,  1.12238646e-01,\n",
              "         -6.24167174e-02, -4.28239107e-02,  5.73123097e-02,\n",
              "         -3.97267342e-02,  1.52494341e-01, -8.96592587e-02,\n",
              "          1.41767025e-01],\n",
              "        [-1.95988998e-01, -8.18234980e-02, -2.09376648e-01,\n",
              "         -3.09041739e-02,  1.11931860e-01,  2.24305481e-01,\n",
              "         -2.11891890e-01,  2.04532534e-01, -1.29587561e-01,\n",
              "          9.83348191e-02],\n",
              "        [ 4.76978123e-02, -4.94515300e-02,  5.15591204e-02,\n",
              "         -2.06984416e-01, -1.79444581e-01,  1.24339610e-01,\n",
              "         -2.25240499e-01,  8.90366733e-02, -2.15671673e-01,\n",
              "         -1.44579858e-02],\n",
              "        [ 1.41838968e-01,  4.13466692e-02, -1.60215676e-01,\n",
              "         -1.86856240e-02,  5.17886877e-02, -1.42400742e-01,\n",
              "         -1.30431265e-01, -1.22227781e-01,  6.28347397e-02,\n",
              "         -1.27208710e-01],\n",
              "        [-5.36786765e-02,  1.32415414e-01, -4.22222167e-02,\n",
              "         -1.98327109e-01, -2.22375020e-01,  6.47093356e-02,\n",
              "          1.66661382e-01,  3.01316381e-02,  2.80178189e-02,\n",
              "         -4.88572866e-02],\n",
              "        [-1.44474864e-01,  2.08779573e-01,  1.37632132e-01,\n",
              "         -2.15024084e-01,  2.11797118e-01,  9.03264582e-02,\n",
              "          2.74270773e-02,  9.30139124e-02, -7.10915178e-02,\n",
              "         -1.56313822e-01],\n",
              "        [-2.12956965e-02,  1.44971877e-01,  1.45193517e-01,\n",
              "         -2.22045779e-01, -2.22939193e-01,  2.80246437e-02,\n",
              "         -5.74077964e-02, -6.15837127e-02,  1.79299325e-01,\n",
              "          2.15528697e-01],\n",
              "        [ 1.90861017e-01,  1.21159285e-01, -1.91308379e-01,\n",
              "          1.99037939e-01, -6.52679503e-02, -1.21245541e-01,\n",
              "          1.67658985e-01, -9.05006230e-02, -1.77602112e-01,\n",
              "         -2.32128382e-01],\n",
              "        [-1.02622613e-01,  1.01765215e-01, -2.20791578e-01,\n",
              "         -1.72136247e-01, -8.29156041e-02, -6.47224784e-02,\n",
              "          7.59713650e-02,  2.21532166e-01,  1.05863631e-01,\n",
              "         -1.86341256e-02],\n",
              "        [-2.29222149e-01,  1.22946501e-03, -2.30081379e-01,\n",
              "         -3.40151489e-02,  1.02817774e-01, -1.58929944e-01,\n",
              "          1.09057397e-01, -1.87185362e-01,  1.83486521e-01,\n",
              "          1.80641204e-01],\n",
              "        [-6.79951906e-03, -2.10030302e-01,  1.07621908e-01,\n",
              "          2.13573277e-01,  6.50964379e-02, -8.96080881e-02,\n",
              "         -1.66834146e-01, -1.52194366e-01,  2.24559724e-01,\n",
              "         -3.91066074e-02],\n",
              "        [-1.07952550e-01, -3.42195630e-02,  3.01857591e-02,\n",
              "         -4.97189164e-03, -1.96355611e-01, -1.14640191e-01,\n",
              "         -1.63768560e-01,  1.95028633e-01,  1.47906989e-01,\n",
              "         -1.39038518e-01],\n",
              "        [-1.14724331e-01, -2.14705646e-01, -7.27747977e-02,\n",
              "         -3.66583467e-02, -5.80713153e-03, -6.92076087e-02,\n",
              "         -1.09506041e-01, -4.46863472e-03,  2.21180409e-01,\n",
              "          2.07228750e-01],\n",
              "        [ 2.19167203e-01,  4.34500575e-02,  2.32902050e-01,\n",
              "         -1.63501158e-01, -1.82829350e-02, -9.55441892e-02,\n",
              "         -1.61206156e-01, -3.01271230e-02, -1.35559291e-02,\n",
              "         -2.01713771e-01],\n",
              "        [ 4.28215265e-02, -1.56210810e-01, -2.06893817e-01,\n",
              "          2.02419221e-01,  1.40582651e-01,  1.79784685e-01,\n",
              "         -3.73304933e-02, -1.49897844e-01,  9.94609594e-02,\n",
              "          1.85573280e-01],\n",
              "        [ 2.30357021e-01,  2.01888353e-01, -8.65926594e-02,\n",
              "         -2.09022343e-01, -1.06660321e-01,  9.67729390e-02,\n",
              "         -1.77271634e-01, -1.57101169e-01,  1.07297659e-01,\n",
              "          1.79670483e-01],\n",
              "        [-2.84596980e-02, -1.38343766e-01,  8.62970948e-02,\n",
              "         -2.94475704e-02,  1.27551317e-01, -1.25440121e-01,\n",
              "         -1.41352415e-01, -1.20744064e-01, -3.19005549e-02,\n",
              "          9.65204239e-02],\n",
              "        [ 9.26904976e-02,  1.14845932e-02,  7.39483535e-02,\n",
              "         -1.35698065e-01, -3.37997675e-02,  1.23974204e-01,\n",
              "         -1.44935519e-01,  1.19601011e-01, -1.00240961e-01,\n",
              "          1.02021635e-01],\n",
              "        [ 1.28218442e-01,  1.07464045e-01, -7.87660778e-02,\n",
              "          4.53737378e-02, -3.70585918e-02, -6.42331392e-02,\n",
              "          1.78715885e-01, -1.15848005e-01,  5.72059453e-02,\n",
              "         -6.56432509e-02],\n",
              "        [ 1.96988612e-01,  2.02825934e-01,  1.03608876e-01,\n",
              "         -7.98638612e-02,  1.59670711e-01,  3.83320153e-02,\n",
              "         -2.31198549e-01,  2.01672405e-01, -4.39842790e-02,\n",
              "          1.26999676e-01],\n",
              "        [-6.74193650e-02, -1.12542294e-01,  8.68990719e-02,\n",
              "          1.91311449e-01,  1.68859661e-02, -1.65712327e-01,\n",
              "         -9.52147692e-02,  7.35645592e-02,  1.60058856e-01,\n",
              "         -9.75640714e-02],\n",
              "        [-1.35393083e-01, -1.65024072e-01, -2.59223580e-02,\n",
              "          1.75464690e-01,  1.69522732e-01,  5.85085452e-02,\n",
              "         -2.30260402e-01,  3.10553610e-02,  1.46951288e-01,\n",
              "         -1.61080629e-01],\n",
              "        [ 1.43017769e-01,  8.87628198e-02, -1.19645558e-01,\n",
              "          9.05621052e-02,  8.73140693e-02,  1.00668609e-01,\n",
              "         -6.04141057e-02, -2.33133793e-01, -2.06073388e-01,\n",
              "         -2.27938220e-01]], dtype=float32)>,\n",
              " <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[0].weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x20cecf5ffd0>"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_categorical(y_train).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(-1, 28*28)\n",
        "y_train = to_categorical(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(Dense(100, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4783 - accuracy: 0.8718\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3086 - accuracy: 0.9071\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2745 - accuracy: 0.9153\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2449 - accuracy: 0.9243\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2362 - accuracy: 0.9273\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2300 - accuracy: 0.9272\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2107 - accuracy: 0.9342\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2044 - accuracy: 0.9361\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1926 - accuracy: 0.9399\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1817 - accuracy: 0.9438\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1741 - accuracy: 0.9458\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1696 - accuracy: 0.9465\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1669 - accuracy: 0.9469\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1607 - accuracy: 0.9491\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1536 - accuracy: 0.9519\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1470 - accuracy: 0.9539\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1392 - accuracy: 0.9567\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1382 - accuracy: 0.9567\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1334 - accuracy: 0.9580\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1313 - accuracy: 0.9588\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1308 - accuracy: 0.9591\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1283 - accuracy: 0.9598\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1304 - accuracy: 0.9589\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1252 - accuracy: 0.9604\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1168 - accuracy: 0.9625\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1190 - accuracy: 0.9625\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1231 - accuracy: 0.9604\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1187 - accuracy: 0.9624\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1119 - accuracy: 0.9649\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1109 - accuracy: 0.9650\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1120 - accuracy: 0.9645\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1167 - accuracy: 0.9627\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1158 - accuracy: 0.9631\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1082 - accuracy: 0.9658\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1029 - accuracy: 0.9667\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1073 - accuracy: 0.9663\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1086 - accuracy: 0.9659\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1071 - accuracy: 0.9658\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1035 - accuracy: 0.9669\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1019 - accuracy: 0.9676\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1001 - accuracy: 0.9678\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0996 - accuracy: 0.9679\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0955 - accuracy: 0.9694\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0938 - accuracy: 0.9698\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0944 - accuracy: 0.9699\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0950 - accuracy: 0.9701\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0905 - accuracy: 0.9712\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0918 - accuracy: 0.9698\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0953 - accuracy: 0.9698\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0927 - accuracy: 0.9707\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0901 - accuracy: 0.9709\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0880 - accuracy: 0.9714\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0889 - accuracy: 0.9715\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0878 - accuracy: 0.9713\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0874 - accuracy: 0.9716\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0877 - accuracy: 0.9716\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0871 - accuracy: 0.9716\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0871 - accuracy: 0.9719\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9736\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0806 - accuracy: 0.9739\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0813 - accuracy: 0.9735\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0814 - accuracy: 0.9741\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0821 - accuracy: 0.9730\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0848 - accuracy: 0.9719\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0847 - accuracy: 0.9726\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0864 - accuracy: 0.9719\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0870 - accuracy: 0.9710\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0843 - accuracy: 0.9721\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0848 - accuracy: 0.9726\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0792 - accuracy: 0.9746\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0763 - accuracy: 0.9750\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9762\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0750 - accuracy: 0.9755\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0757 - accuracy: 0.9750\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0759 - accuracy: 0.9747\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0750 - accuracy: 0.9754\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0742 - accuracy: 0.9761\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0742 - accuracy: 0.9762\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0732 - accuracy: 0.9761\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0679 - accuracy: 0.9777\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0707 - accuracy: 0.9768\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0737 - accuracy: 0.9754\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0757 - accuracy: 0.9759\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0685 - accuracy: 0.9776\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0682 - accuracy: 0.9768\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0695 - accuracy: 0.9775\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0714 - accuracy: 0.9767\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0719 - accuracy: 0.9760\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0731 - accuracy: 0.9759\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0741 - accuracy: 0.9754\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0715 - accuracy: 0.9766\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0691 - accuracy: 0.9776\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0673 - accuracy: 0.9773\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0687 - accuracy: 0.9772\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0669 - accuracy: 0.9778\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0651 - accuracy: 0.9793\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0699 - accuracy: 0.9768\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0726 - accuracy: 0.9759\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0710 - accuracy: 0.9765\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0709 - accuracy: 0.9767\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x20cffa83550>"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1 = Sequential(\n",
        "    [\n",
        "        Dense(256, activation='sigmoid', input_shape=(784,)),\n",
        "        Dense(100, activation='sigmoid'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def linear(x):\n",
        "    return x\n",
        "\n",
        "def relu(x):\n",
        "    return np.where(x > 0, x, 0)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return (1-np.exp(x))/(1+np.exp(x))\n",
        "\n",
        "def softmax(x):\n",
        "    x -= np.max(x,1).reshape(x.shape[0], -1)\n",
        "    return np.exp(x)/np.sum(np.exp(x),1).reshape(x.shape[0], -1)\n",
        "# def softmax(x):\n",
        "#     exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "#     softmax_values = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "    \n",
        "#     return softmax_values\n",
        "\n",
        "def rmse(y_hat, y):\n",
        "    return np.mean(np.square(y_hat - y))\n",
        "\n",
        "def binary_crossentropy(y_hat, y):\n",
        "    epsilon = 1e-7\n",
        "    return -np.mean((1-y)*np.log(1-y_hat+epsilon) + y*np.log(y_hat+epsilon))\n",
        "\n",
        "def categorical_crossentropy(y_hat, y):\n",
        "    epsilon = 1e-7\n",
        "    return -np.mean(y*np.log(y_hat+epsilon))\n",
        "\n",
        "def make_onehot(x):\n",
        "    result = np.zeros((x.size, np.max(x)+1))\n",
        "    for idx, val in enumerate(x):\n",
        "        result[idx, val] = 1\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.09003057, 0.24472847, 0.66524096],\n",
              "       [1.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([[1,2,3],[1000,5,6]])\n",
        "softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 's' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[191], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# s = time()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m e \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m----> 4\u001b[0m (e \u001b[38;5;241m-\u001b[39m \u001b[43ms\u001b[49m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m\n",
            "\u001b[1;31mNameError\u001b[0m: name 's' is not defined"
          ]
        }
      ],
      "source": [
        "from time import time\n",
        "# s = time()\n",
        "e = time()\n",
        "(e - s)/1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SequentialModel:\n",
        "    def __init__(self,x,y,output_shape,activation='linear'):\n",
        "        self.activation_dic = {\n",
        "            'linear':linear,\n",
        "            'sigmoid':sigmoid,\n",
        "            'relu':relu,\n",
        "            'softmax':softmax\n",
        "        }\n",
        "        self.loss_func_dic = {\n",
        "            'rmse':rmse,\n",
        "            'binary_crossentropy':binary_crossentropy,\n",
        "            'categorical_crossentropy':categorical_crossentropy\n",
        "        }\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.activation = [activation]\n",
        "        self.W = [[np.random.randn(self.x.shape[1],output_shape),\n",
        "                  np.zeros(output_shape)]]\n",
        "        self.dW = [[np.zeros((self.x.shape[1],output_shape)),\n",
        "                  np.zeros(output_shape)]]\n",
        "    def add(self,output,activation='linear'):\n",
        "        self.input = self.W[-1][0].shape[1]\n",
        "        self.W.append([np.random.randn(self.input,output),np.zeros(output)])\n",
        "        self.dW.append([np.zeros((self.input,output)),np.zeros(output)])\n",
        "        self.activation.append(activation)\n",
        "    \n",
        "    def predict(self):\n",
        "        self.y_hat = self.x.copy()\n",
        "        for i in range(len(self.W)):\n",
        "            self.y_hat = np.dot(self.y_hat,self.W[i][0]) + self.W[i][1]\n",
        "            self.y_hat = self.activation_dic[self.activation[i]](self.y_hat)\n",
        "        return self.y_hat\n",
        "    \n",
        "    def compile(self,loss):\n",
        "        self.loss_func = self.loss_func_dic[loss]\n",
        "    \n",
        "    def summary(self):\n",
        "        print(\"-------------------------\")\n",
        "        print(\" Output Shape     Param #\")\n",
        "        print(\"=========================\")\n",
        "        self.total_params = 0\n",
        "        for W in self.W:\n",
        "            print(f'(None, {W[0].shape[1]})   {W[0].shape[0]*W[0].shape[1] + W[0].shape[1]:^}\\n')\n",
        "            self.total_params += (W[0].shape[0]*W[0].shape[1] + W[0].shape[1])\n",
        "        print(\"=========================\")\n",
        "        print(f\"total parameters = {self.total_params}\")\n",
        "        \n",
        "    def loss(self):\n",
        "        s = time()\n",
        "        y_hat = self.predict()\n",
        "        y = self.y\n",
        "        self.loss_val = self.loss_func(y_hat, y)\n",
        "        e = time()\n",
        "        self.predict_elapse = (e-s)\n",
        "        self.forword_elapse = self.predict_elapse*self.total_params*2\n",
        "        return self.loss_val\n",
        "    \n",
        "    def gradient(self):\n",
        "        h = 1e-5\n",
        "        weight = 0\n",
        "        bias = 1\n",
        "        \n",
        "        for layer in range(len(self.W)):\n",
        "            rows = self.W[layer][weight].shape[0]\n",
        "            cols = self.W[layer][weight].shape[1]\n",
        "            for row in range(rows):\n",
        "                for col in range(cols):\n",
        "                    fx = self.loss()\n",
        "                    self.W[layer][weight][row,col] += h\n",
        "                    fxh = self.loss()\n",
        "                    self.dW[layer][weight][row, col] = (fxh-fx)/h\n",
        "                    self.W[layer][weight][row,col] -= h\n",
        "            for b_idx in range(self.W[layer][bias].size):\n",
        "                fx = self.loss()\n",
        "                self.W[layer][bias][b_idx] += h\n",
        "                fxh = self.loss()\n",
        "                self.dW[layer][bias][b_idx] = (fxh-fx)/h\n",
        "                self.W[layer][bias][b_idx] -= h    \n",
        "        \n",
        "    \n",
        "    def descent_gradient(self,lr=1e-3):\n",
        "        self.lr = lr\n",
        "        weight = 0\n",
        "        bias = 1\n",
        "        layers = range(len(self.W))\n",
        "        self.gradient()\n",
        "        for layer in layers:\n",
        "            self.W[layer][weight] -= self.dW[layer][weight]*self.lr\n",
        "            self.W[layer][bias] -= self.dW[layer][bias]*self.lr\n",
        "        \n",
        "    def fit(self,lr,epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"{epoch+1} 시작 =============================\")\n",
        "            self.descent_gradient(lr)\n",
        "            print(f\"{epoch+1} loss ============================= {self.loss()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SequentialModel(np.random.randn(100, 20), np.random.randn(100, 5), output_shape=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(300, 'sigmoid')\n",
        "model.add(150, 'relu')\n",
        "model.add(5, 'softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile('categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1410648524107128"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1410648524107128"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.loss_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Dense(100, activation='relu', input_shape=(10,)))\n",
        "model1.add(Dense(40))\n",
        "model1.add(Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 100)               1100      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 40)                4040      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 3)                 123       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5263 (20.56 KB)\n",
            "Trainable params: 5263 (20.56 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = np.random.randint(0, 4, 100)\n",
        "y_one = make_onehot(y)\n",
        "model = SequentialModel(np.random.randn(100, 10), y_one, 100)\n",
        "model.add(40, activation='relu')\n",
        "model.add(4, activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile('categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------\n",
            " Output Shape     Param #\n",
            "=========================\n",
            "(None, 100)   1100\n",
            "\n",
            "(None, 40)   4040\n",
            "\n",
            "(None, 4)   164\n",
            "\n",
            "=========================\n",
            "total parameters = 5304\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(epochs=2, lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.04229098158027"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test,y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.cumprod(X_train.shape[1:])[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_ = X_train.reshape(-1, 28*28)\n",
        "X_test_ = X_test.reshape(-1, 28*28)\n",
        "y_train_ = to_categorical(y_train)\n",
        "y_test_ = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1 = Sequential()\n",
        "input_layer = Dense(256, activation='relu', input_shape=(784,))\n",
        "layer1 = Dense(128, activation='relu')\n",
        "output_layer = Dense(10, activation='softmax')\n",
        "model1.add(input_layer)\n",
        "model1.add(layer1)\n",
        "model1.add(output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.9083 - accuracy: 0.8745\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4271 - accuracy: 0.9223\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3995 - accuracy: 0.9310\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3806 - accuracy: 0.9360\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4013 - accuracy: 0.9361\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3992 - accuracy: 0.9377\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4013 - accuracy: 0.9406\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4111 - accuracy: 0.9357\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4285 - accuracy: 0.9378\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4366 - accuracy: 0.9359\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x18e1b1dc2d0>"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.fit(X_train_, y_train_, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.9299\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6904891133308411, 0.9298999905586243]"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.evaluate(X_test_, y_test_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235146 (918.54 KB)\n",
            "Trainable params: 235146 (918.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = SequentialModel(X_train_, y_train_, 256,activation='relu' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.add(128, activation='relu')\n",
        "model2.add(10, activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.compile(loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[190], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[169], line 89\u001b[0m, in \u001b[0;36mSequentialModel.fit\u001b[1;34m(self, lr, epochs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m,lr,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 89\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescent_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[169], line 82\u001b[0m, in \u001b[0;36mSequentialModel.descent_gradient\u001b[1;34m(self, lr)\u001b[0m\n\u001b[0;32m     80\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     81\u001b[0m layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW))\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[layer][weight] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdW[layer][weight]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr\n",
            "Cell \u001b[1;32mIn[169], line 64\u001b[0m, in \u001b[0;36mSequentialModel.gradient\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rows):\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cols):\n\u001b[1;32m---> 64\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[layer][weight][row,col] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m h\n\u001b[0;32m     66\u001b[0m         fxh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss()\n",
            "Cell \u001b[1;32mIn[169], line 49\u001b[0m, in \u001b[0;36mSequentialModel.loss\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 49\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_func(y_hat, y)\n",
            "Cell \u001b[1;32mIn[169], line 31\u001b[0m, in \u001b[0;36mSequentialModel.predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW)):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[i][\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[i][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_dic\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat\n",
            "Cell \u001b[1;32mIn[148], line 5\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrelu\u001b[39m(x):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model2.fit(lr=1e-3, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = SequentialModel(X_train_, y_train_, 256,activation='relu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.add(128,activation='relu')\n",
        "model2.add(10,activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.compile(loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------\n",
            " Output Shape     Param #\n",
            "=========================\n",
            "(None, 256)   200960\n",
            "\n",
            "(None, 128)   32896\n",
            "\n",
            "(None, 10)   1290\n",
            "\n",
            "=========================\n",
            "total parameters = 235146\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.4893041917071164"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7061557769775391"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.predict_elapse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "332099.4126663208"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.forword_elapse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.random.randn(100000, 1000)\n",
        "w = np.random.randn(1000, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = np.random.randint(0, 1, 100000).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100000, 1)"
            ]
          },
          "execution_count": 226,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss(x, y):\n",
        "    epsilon = 1e-7\n",
        "    y_hat = np.dot(x, w)\n",
        "    y_hat = sigmoid(y_hat)\n",
        "    y_hat += epsilon\n",
        "    return -np.mean((1-y)*np.log(1-y_hat)+y*np.log(y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_87364\\2501666218.py:6: RuntimeWarning: invalid value encountered in log\n",
            "  return -np.mean((1-y)*np.log(1-y_hat)+y*np.log(y_hat))\n"
          ]
        }
      ],
      "source": [
        "s = time()\n",
        "dW = np.zeros_like(w)\n",
        "h = 1e-5\n",
        "rows = range(w.shape[0])\n",
        "cols = range(w.shape[1])\n",
        "\n",
        "for row in rows:\n",
        "    for col in cols:\n",
        "        fx = loss(x, y)\n",
        "        w[row, col] += h\n",
        "        fxh = loss(x, y)\n",
        "        dW[row, col] = (fxh-fx)/h\n",
        "        w[row, col] -= h\n",
        "e = time()\n",
        "elapse = e - s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "84.93325901031494"
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elapse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 1)"
            ]
          },
          "execution_count": 230,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dW.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_87364\\4257694624.py:2: RuntimeWarning: divide by zero encountered in log\n",
            "  output = -((1-y)*np.log(1-sigmoid(np.dot(x, w))) + y*np.log(sigmoid(np.dot(x, w))))\n"
          ]
        }
      ],
      "source": [
        "s = time()\n",
        "epsilon = 1e-7\n",
        "y_hat = sigmoid(np.dot(x, w))\n",
        "output = -((1-y)*np.log(1-y_hat+epsilon) + y*np.log(y_hat+epsilon))\n",
        "output = (sigmoid(output*1)*(1-sigmoid(output*1)))\n",
        "dX = np.dot(x.T, output)\n",
        "dW = np.dot(output, w.T)\n",
        "e = time()\n",
        "elapse_back = e - s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.412905216217041"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elapse_back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "205.6967450991714"
            ]
          },
          "execution_count": 238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elapse / elapse_back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 1.        ],\n",
              "       [0.21194156, 0.21194156, 0.57611688]])"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = np.array([[1,1,10000],[0,0,1]])\n",
        "softmax(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def linear(x):\n",
        "    return x\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.where(x>0,x,0)\n",
        "\n",
        "def tanh(x):\n",
        "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "\n",
        "# def softmax(x):\n",
        "#     x -= np.max(x,1).reshape(x.shape[0], -1)\n",
        "#     return np.exp(x)/np.sum(np.exp(x),1).reshape(x.shape[0], -1)\n",
        "# def softmax(x):\n",
        "#     exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "#     softmax_values = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "#     return softmax_values\n",
        "def softmax(x):\n",
        "    m = np.max(x,1).reshape(-1,1)\n",
        "    c = x - m\n",
        "    return np.exp(c)/np.sum(np.exp(c),1).reshape(-1,1)\n",
        "\n",
        "\n",
        "def rmse(y,y_hat):\n",
        "    return np.sqrt(np.mean(np.square(y-y_hat))) \n",
        "\n",
        "def binary_crossentropy(y,y_hat):\n",
        "    epsilon = 1e-7\n",
        "    return -np.mean((1-y)*np.log(1-y_hat+epsilon)+y*np.log(y_hat+epsilon))\n",
        "\n",
        "def categorical_crossentropy(y,y_hat):\n",
        "    epsilon = 1e-7\n",
        "    return -np.mean(y*np.log(y_hat+epsilon))\n",
        "\n",
        "def make_onehot(x):\n",
        "    result = np.zeros((x.size, np.max(x)+1))\n",
        "    for idx, val in enumerate(x):\n",
        "        result[idx, val] = 1\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "        \n",
        "    def forward(self,x):\n",
        "        return sigmoid(x)\n",
        "    \n",
        "    def backward(self,out):\n",
        "        dout = sigmoid(out)*(1-sigmoid(out))\n",
        "        return dout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReLU:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "    \n",
        "    def forward(self,x):\n",
        "        out = relu(x)\n",
        "        self.out = np.where(out>0,1,0)\n",
        "        return out\n",
        "        \n",
        "    def backward(self,out):\n",
        "        dout = self.out*out\n",
        "        return dout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Affine:\n",
        "    def __init__(self,w,b):\n",
        "        self.x = None\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "    \n",
        "    def forward(self,x):\n",
        "        self.x = x\n",
        "        self.out = np.dot(self.x,self.w) + self.b\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self,out):\n",
        "        self.dout = np.dot(out,self.w.T)#4,2\n",
        "        self.dW = np.dot(self.x.T,out)#2,5\n",
        "        self.db = np.sum(out,axis=0)#5\n",
        "        return self.dout    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Tanh:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "    \n",
        "    def forward(self,x):\n",
        "        return tanh(x)\n",
        "    \n",
        "    def backward(self,out):\n",
        "        dout = 1 - tanh(out)**2\n",
        "        return dout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.special import softmax as sx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "        self.y = None\n",
        "        self.y_hat = None\n",
        "        \n",
        "    def forward(self,x,y):\n",
        "        self.y = y\n",
        "        self.y_hat = softmax(x,axis=1)\n",
        "        self.loss_val = categorical_crossentropy(self.y,self.y_hat)\n",
        "        return self.loss_val\n",
        "    \n",
        "    def backward(self):\n",
        "        self.dout = (self.y_hat - self.y)/len(self.y)\n",
        "        return self.dout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigdiff(x):\n",
        "    return sigmoid(x)*(1-sigmoid(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = Sigmoid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.random.randn(3, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.56267131, 0.4013676 ],\n",
              "       [0.50809525, 0.42446157],\n",
              "       [0.47748601, 0.29274697]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "out = np.dot(s.forward(x), np.random.randn(2, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.24149717, 0.22191635],\n",
              "       [0.23967271, 0.22859352],\n",
              "       [0.24586912, 0.22795343]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.backward(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.array([[-5, 6], [2, 0], [-2, 3]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[0, 6],\n",
              "        [2, 0],\n",
              "        [0, 3]]),\n",
              " array([[0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1]]))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r = ReLU()\n",
        "r.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "dx = np.array([[100, -5], [-7, -7], [7, 10]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0, -5],\n",
              "       [-7,  0],\n",
              "       [ 0, 10]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r.backward(dx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "aff = Affine(np.random.randn(2, 5), np.zeros(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.38943362,  0.28096509,  1.66746912, -2.53166792,  1.29685724],\n",
              "       [ 0.27396675, -0.12862694, -0.36546848,  0.73702316, -0.60270728],\n",
              "       [ 0.14347556,  0.40175305,  5.2967082 , -6.70867056,  1.78850131],\n",
              "       [-0.9121753 ,  0.3823106 ,  0.6792196 , -1.75893874,  1.8006003 ]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aff.forward(np.random.randn(4, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 3.06397093,  1.53188906],\n",
              "       [ 1.89635172, -2.07023843],\n",
              "       [ 0.66255773,  2.3849432 ],\n",
              "       [-0.60099146, -4.89483662]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aff.backward(np.random.randn(4, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4, 2), (2, 5), (5,))"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aff.dout.shape, aff.dW.shape, aff.db.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.where(x>0,x,0)\n",
        "\n",
        "def softmax(x):\n",
        "    m = np.max(x,1).reshape(-1,1)\n",
        "    c = x - m\n",
        "    return np.exp(c)/np.sum(np.exp(c),1).reshape(-1,1)\n",
        "\n",
        "def tanh(x):\n",
        "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "\n",
        "def rmse(y,y_hat):\n",
        "    return np.sqrt(np.mean(np.square(y-y_hat))) \n",
        "\n",
        "def binary_crossentropy(y,y_hat):\n",
        "    epsilon = 1e-7\n",
        "    return -np.mean((1-y)*np.log(1-y_hat+epsilon)+y*np.log(y_hat+epsilon))\n",
        "\n",
        "def categorical_crossentropy(y_hat,y):\n",
        "    epsilon = 1e-7\n",
        "    return -np.mean(y*np.log(y_hat+epsilon))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "        \n",
        "    def forward(self,x):\n",
        "        return sigmoid(x)\n",
        "    \n",
        "    def backward(self,out):\n",
        "        dout = sigmoid(out)*(1-sigmoid(out))\n",
        "        return dout\n",
        "    \n",
        "class ReLU:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "    \n",
        "    def forward(self,x):\n",
        "        out = relu(x)\n",
        "        self.out = np.where(out>0,1,0)\n",
        "        return out\n",
        "        \n",
        "    def backward(self,out):\n",
        "        dout = self.out*out\n",
        "        return dout\n",
        "\n",
        "class Affine:\n",
        "    def __init__(self,w,b):\n",
        "        self.x = None\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "    \n",
        "    def forward(self,x):\n",
        "        self.x = x\n",
        "        self.out = np.dot(self.x,self.w) + self.b\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self,out):\n",
        "        self.dout = np.dot(out,self.w.T)#4,2\n",
        "        self.dW = np.dot(self.x.T,out)#2,5\n",
        "        self.db = np.sum(out,axis=0)#5\n",
        "        return self.dout    \n",
        "    \n",
        "class Tanh:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "    \n",
        "    def forward(self,x):\n",
        "        return tanh(x)\n",
        "    \n",
        "    def backward(self,out):\n",
        "        dout = 1 - tanh(out)**2\n",
        "        return dout\n",
        "    \n",
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "        self.y = None\n",
        "        self.y_hat = None\n",
        "        \n",
        "    def forward(self,x,y):\n",
        "        self.y = y\n",
        "        self.y_hat = softmax(x,axis=1)\n",
        "        self.loss_val = categorical_crossentropy(self.y,self.y_hat)\n",
        "        return self.loss_val\n",
        "    \n",
        "    def backward(self):\n",
        "        self.dout = (self.y_hat - self.y)/len(self.y)\n",
        "        return self.dout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net:\n",
        "    def __init__(self,input_shape):\n",
        "        self.x = None\n",
        "        self.y = None\n",
        "        self.input_shape = input_shape\n",
        "        self.layers = []\n",
        "        self.activation_dic = {\n",
        "            'relu':ReLU,\n",
        "            'sigmoid':Sigmoid,\n",
        "            'softmax':SoftmaxWithLoss,\n",
        "            'tanh':Tanh\n",
        "        }\n",
        "        self.grad = None\n",
        "        \n",
        "    def add(self,output_shape,activation):\n",
        "        if len(self.layers) == 0:\n",
        "            w = np.random.randn(self.input_shape,output_shape)\n",
        "            b = np.zeros(output_shape)\n",
        "            activation = self.activation_dic.get(activation)\n",
        "            self.layers.append([w,b,activation])\n",
        "        else:\n",
        "            input_shape = self.layers[-1][0].shape[1]\n",
        "            w = np.random.randn(input_shape,output_shape)\n",
        "            b = np.zeros(output_shape)\n",
        "            activation = self.activation_dic.get(activation)\n",
        "            self.layers.append([w,b,activation])\n",
        "    \n",
        "    def _build(self):\n",
        "        self.W = {}\n",
        "        for i, layer in enumerate(self.layers,1):\n",
        "            w = layer[0]\n",
        "            b = layer[1]\n",
        "            activation = layer[2]\n",
        "            self.W['Affine_'+str(i)] = Affine(w,b)\n",
        "            self.W['Activation_'+str(i)] = activation()\n",
        "        return f'Building Success!!'\n",
        "    \n",
        "    def compile(self,lr,loss,metrics):\n",
        "        loss_func_dic = {\n",
        "            'rmse':rmse,\n",
        "            'binary_crossentorpy':binary_crossentropy,\n",
        "            'categorical_crossentropy':categorical_crossentropy\n",
        "        } \n",
        "        \n",
        "        metrics_dic ={\n",
        "            'accuracy':'accuracy',\n",
        "            'rmse':'rmse'\n",
        "        }\n",
        "        \n",
        "        self.loss_func = loss_func_dic[loss]\n",
        "        self.metrics = metrics_dic[metrics]\n",
        "        self.lr = lr\n",
        "        \n",
        "    \n",
        "    def predict(self,x,y):\n",
        "        if self.grad == None:\n",
        "            self._build()\n",
        "        self.y = y\n",
        "        self.y_hat = x\n",
        "\n",
        "        for layer in list(self.W.items())[:-1]:\n",
        "            self.y_hat = layer[1].forward(self.y_hat)\n",
        "        self.loss_val = list(self.W.items())[-1][1].forward(self.y_hat,self.y)\n",
        "        return self.y_hat, self.loss_val\n",
        "    \n",
        "    def gradient(self,x,y):\n",
        "        self.y_hat = self.predict(x,y)[0]\n",
        "        self.y = y\n",
        "        self.grad = {}\n",
        "        last_layer = list(self.W.keys())[-1]\n",
        "        out = self.W.get(last_layer).backward()\n",
        "        for key in list(self.W.keys())[-2::-1]:\n",
        "            out = self.W.get(key).backward(out)\n",
        "        \n",
        "        idx = 1\n",
        "        for key in self.W.keys():\n",
        "            if 'Affine' in key:\n",
        "                self.grad['W'+str(idx)] = self.W.get(key).dW\n",
        "                self.grad['b'+str(idx)] = self.W.get(key).db\n",
        "                idx += 1\n",
        "                \n",
        "        return self.grad\n",
        "    \n",
        "    \n",
        "    \n",
        "    def loss(self,x,y):\n",
        "        y_hat, loss_val = self.predict(x,y)\n",
        "        # loss_val = categorical_crossentropy(y_hat,y)\n",
        "        accuracy = np.sum(np.argmax(y_hat,1) == np.argmax(y,1))/len(y)\n",
        "        return [accuracy, loss_val]        \n",
        "    \n",
        "    def summary(self):\n",
        "        total_parameters = 0\n",
        "        if self.grad == None:\n",
        "            self._build()\n",
        "        print(\"==============================================\")\n",
        "        print(\"-------------Output Shape---------param #------\")\n",
        "        for idx, layer in enumerate(self.layers,1):\n",
        "            print(f'----Affine_{idx}------(None, {layer[0].shape[1]}),-------{np.prod(layer[0].shape)}----')\n",
        "            total_parameters += np.prod(layer[0].shape) + layer[0].shape[1]\n",
        "        print(\"==============================================\")\n",
        "        print(f\"Total Parmerter # ---- {total_parameters}\")\n",
        "    \n",
        "    def fit(self,x,y,epochs=10):\n",
        "        for epoch in range(epochs):\n",
        "            self.grad = self.gradient(x,y)\n",
        "            print(f'{epoch+1} ====================> accuracy : {self.loss(x,y)[0]} loss : {self.loss(x,y)[1]}')\n",
        "            for idx, _ in enumerate(self.layers,1):\n",
        "                self.W.get('Affine_'+str(idx)).w -= self.lr*self.grad['W'+str(idx)]\n",
        "                self.W.get('Affine_'+str(idx)).b -= self.lr*self.grad['b'+str(idx)]\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Net(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(100, activation='Relu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[array([[ 4.50796424e-01, -5.00929339e-01,  2.05825472e+00,\n",
              "          -3.80416321e-01, -1.20361746e+00, -1.04143371e+00,\n",
              "           3.45821278e-01,  7.24775494e-01, -6.39350169e-01,\n",
              "           3.18077223e-01, -1.33124096e+00, -2.88492404e-01,\n",
              "           3.21537676e-01, -2.28877113e-02, -8.39977121e-01,\n",
              "           1.18586716e+00, -8.40727375e-01,  7.86241628e-01,\n",
              "           2.43817777e-01, -9.75119155e-01,  4.27529387e-01,\n",
              "          -5.10860857e-01, -5.82651088e-02,  4.12936912e-01,\n",
              "          -6.05740690e-01, -8.63884275e-01, -9.13760874e-01,\n",
              "           1.29221210e+00,  3.26497394e-01,  1.77356315e+00,\n",
              "          -4.81318687e-01,  1.26198024e-01, -5.01955485e-01,\n",
              "           1.38014738e+00,  1.44837732e+00,  1.08275830e-01,\n",
              "           8.93125771e-01,  1.18508747e+00, -1.13657461e+00,\n",
              "          -8.68016149e-01, -6.19008931e-01, -7.92826412e-01,\n",
              "          -4.99150532e-01,  1.71336134e+00,  3.18261551e-01,\n",
              "          -1.85403023e+00, -9.01099647e-01, -7.88068883e-01,\n",
              "           8.41074354e-01,  2.72980614e-01, -6.65741589e-01,\n",
              "          -2.30075048e+00,  1.04472660e+00,  9.04476057e-01,\n",
              "           4.92809224e-01,  7.68232100e-02,  4.91132593e-01,\n",
              "           1.42418669e+00, -1.70899439e+00, -2.44435102e-01,\n",
              "          -1.30888292e+00, -3.22853663e-01,  4.42702255e-01,\n",
              "          -1.99976829e+00,  9.48789253e-01,  4.52543339e-01,\n",
              "          -1.73096696e+00,  1.67797903e-01,  2.27028205e-01,\n",
              "           2.00604077e+00,  7.39723270e-01,  1.59512080e+00,\n",
              "          -7.84946509e-01, -1.82326759e+00,  9.39864346e-01,\n",
              "          -1.28294237e+00, -8.18123536e-01, -4.88809277e-01,\n",
              "          -2.34981944e-01, -1.50403048e+00,  2.20903582e-01,\n",
              "           2.92921377e-01, -5.90718982e-01,  9.55667022e-02,\n",
              "           3.57904680e-01, -1.80559899e-01, -2.14231840e+00,\n",
              "          -5.09110706e-01, -5.39365112e-01,  4.04602641e-01,\n",
              "          -8.27804480e-01,  4.73763137e-01,  2.12331764e-01,\n",
              "          -1.33853853e+00, -1.53705133e+00,  1.32166334e-01,\n",
              "           5.54221034e-01, -9.47282259e-01,  1.73892483e+00,\n",
              "           4.37692367e-01],\n",
              "         [ 5.72836580e-03, -1.33370754e+00, -1.68431474e+00,\n",
              "           1.40176978e+00, -6.61861347e-01, -9.47474136e-01,\n",
              "          -4.76178782e-01,  3.34384051e-01,  4.48444589e-01,\n",
              "          -7.09255300e-01, -1.08186241e+00, -1.21989080e+00,\n",
              "          -7.25651372e-01, -8.07168976e-02, -9.42809092e-01,\n",
              "           6.30981655e-01,  6.84267642e-01, -2.89603652e-01,\n",
              "          -4.87140011e-01, -1.10599503e+00,  3.54697494e-02,\n",
              "          -1.10888019e-02,  2.36174793e-02,  1.52224909e+00,\n",
              "           1.04576745e+00,  2.73407213e+00, -9.44413889e-01,\n",
              "           1.03667019e+00, -5.36750601e-01,  1.28890389e+00,\n",
              "           1.39602286e+00, -7.51315732e-01, -1.04368975e+00,\n",
              "          -4.93087090e-01,  6.50482734e-01,  5.10839619e-02,\n",
              "          -4.64188029e-02, -8.25586220e-02,  7.91322152e-01,\n",
              "          -4.72315099e-01, -2.10992450e+00, -2.73366429e-01,\n",
              "           4.38015120e-01, -1.36173108e+00, -1.50553292e+00,\n",
              "           5.88287558e-01, -1.20822387e+00, -3.35540767e-01,\n",
              "           1.03392762e+00,  1.37373079e+00, -4.33550384e-02,\n",
              "           6.32229056e-01, -4.89790543e-02, -7.79913274e-01,\n",
              "           3.12483751e-03, -1.90781866e+00,  1.87080508e-02,\n",
              "          -8.06640706e-01,  8.94565242e-01, -9.84166499e-01,\n",
              "          -9.46000261e-02,  9.97142188e-01,  1.28641757e+00,\n",
              "           1.68652315e+00,  1.48897882e+00,  6.82600316e-01,\n",
              "          -2.26168769e-01,  5.54876890e-01, -1.24346794e+00,\n",
              "           8.74622332e-01, -5.26932316e-01,  1.49705569e+00,\n",
              "          -1.23316540e+00, -1.41602524e-01, -3.58399530e-01,\n",
              "           3.85309299e-01, -1.44132259e+00, -1.22820038e+00,\n",
              "           5.87280983e-01,  3.25925336e-01, -1.29390911e+00,\n",
              "          -9.90836281e-01,  5.02915726e-01, -5.70537442e-01,\n",
              "          -1.77362146e+00, -2.02395463e+00, -7.82939301e-01,\n",
              "          -2.12572742e-01, -7.79944584e-03,  2.65111433e-01,\n",
              "           7.83193654e-01,  6.38360029e-01, -2.21579258e+00,\n",
              "          -3.53321948e-02,  8.37204631e-02,  6.21962345e-01,\n",
              "           2.19676964e-01, -2.99293112e-01, -5.09476512e-03,\n",
              "          -7.18333243e-01],\n",
              "         [-5.37435466e-01,  4.56354712e-01, -1.22101786e+00,\n",
              "          -1.06501373e+00, -6.59630491e-01,  5.06010104e-01,\n",
              "          -2.00640398e-01,  2.07498673e-01, -3.27447621e-01,\n",
              "           2.38431241e+00,  6.55890840e-02, -1.19881580e+00,\n",
              "          -8.96664509e-01,  9.34107351e-01, -3.82017048e-01,\n",
              "          -4.87057333e-01,  5.28042339e-02, -1.00884544e+00,\n",
              "           9.51273341e-02,  6.95174987e-01,  5.44766831e-02,\n",
              "           3.35483400e-01, -1.05534530e+00,  2.20360883e-02,\n",
              "          -5.40390733e-01, -1.16358603e+00,  5.45301961e-01,\n",
              "          -9.37756711e-01,  2.26176670e-01, -6.60477630e-01,\n",
              "          -2.56575243e-02, -7.35405692e-01,  6.16616274e-02,\n",
              "           1.81212519e+00,  6.03171566e-01,  1.53065217e-02,\n",
              "           3.21310337e-02,  3.20590508e-01,  7.93103913e-01,\n",
              "           1.51161025e+00,  3.07725874e-01,  7.69588569e-01,\n",
              "           9.39385356e-01,  1.96292077e+00, -1.55165024e+00,\n",
              "           1.48571182e+00,  1.72951929e-01,  4.78635505e-01,\n",
              "          -7.99115658e-02, -3.89054959e-01,  1.60849155e+00,\n",
              "          -5.77963179e-01, -1.87511803e-01,  1.95110634e-01,\n",
              "          -5.19218693e-01, -1.48339172e-02,  2.63710438e-01,\n",
              "           1.11336846e+00, -1.08619733e+00, -8.80351564e-01,\n",
              "           4.19729894e-01, -6.82854256e-01, -5.97554433e-01,\n",
              "           1.55450231e+00,  5.91975434e-02,  1.92632306e-01,\n",
              "          -8.06096769e-01,  4.71697303e-01, -9.04999421e-01,\n",
              "          -5.68372068e-01,  4.86944910e-01, -5.74947220e-01,\n",
              "           5.81778490e-01,  9.55093015e-01,  2.34081916e-01,\n",
              "          -4.07730051e-01,  6.29362661e-01,  5.89117617e-01,\n",
              "           3.59804627e-01, -1.70632765e-01,  1.44611324e+00,\n",
              "           9.52888732e-01, -1.19918449e+00,  6.44755343e-01,\n",
              "           1.60377231e+00, -6.30362915e-01, -5.24373336e-01,\n",
              "          -3.80277756e-01,  1.66641160e+00, -1.91730948e+00,\n",
              "           6.63161006e-01, -1.37693422e+00,  3.54418078e-01,\n",
              "           1.10740336e+00, -2.07121393e-01,  5.53103151e-01,\n",
              "          -1.33801088e+00,  2.26826137e+00, -1.89549836e+00,\n",
              "           3.62688165e-01],\n",
              "         [ 2.35760754e-02,  7.99555784e-01, -8.39994036e-01,\n",
              "          -1.25397359e+00, -2.13312231e+00, -1.05989093e-01,\n",
              "          -1.02744579e+00,  8.53344025e-01, -2.92539579e-01,\n",
              "           1.22961827e+00, -9.68321861e-01, -3.15023525e-01,\n",
              "           4.20098930e-01,  6.83701290e-01, -2.27477075e+00,\n",
              "          -1.03257609e-01,  1.02464094e+00,  2.97205794e-01,\n",
              "          -5.84601463e-03,  1.07560779e+00,  2.82596920e-01,\n",
              "          -8.77885855e-01, -1.01781209e+00,  6.01954672e-01,\n",
              "          -2.37799373e-01,  1.18314460e+00, -1.39870629e+00,\n",
              "           1.01281511e+00,  7.22294764e-01, -9.35321948e-01,\n",
              "           7.93894686e-01, -6.65366935e-01, -1.04250159e+00,\n",
              "           8.10424180e-01,  5.01441939e-01, -7.54485704e-01,\n",
              "          -1.08377909e+00,  2.42702692e-01,  5.73774757e-01,\n",
              "          -1.32574435e+00, -8.96542171e-01,  1.79828807e+00,\n",
              "          -3.37906755e-01,  8.15939171e-02,  6.19146429e-01,\n",
              "          -1.36092717e+00, -8.79581148e-01,  1.06810370e+00,\n",
              "          -6.07114549e-01,  1.12031595e-01, -1.20167866e+00,\n",
              "           3.56442605e-01, -1.35151743e+00,  1.89800088e+00,\n",
              "           4.68153026e-01, -1.19371290e+00,  6.21917697e-02,\n",
              "          -6.35281621e-01,  9.67145033e-01,  1.74020365e-01,\n",
              "          -1.01089869e+00,  7.34459268e-01,  6.74669710e-02,\n",
              "          -7.24455183e-01, -2.17824533e+00,  1.16224496e+00,\n",
              "           2.44620474e+00,  9.97066964e-02, -7.46471093e-01,\n",
              "           3.33057268e-01, -1.97036640e-01,  1.26541646e+00,\n",
              "           1.16125446e+00, -6.90463886e-01,  1.03235737e+00,\n",
              "           1.64868847e+00, -1.14015691e+00,  1.53478186e+00,\n",
              "          -1.18529364e+00, -3.66262850e-01,  1.96062618e-01,\n",
              "           9.06306674e-01,  2.10587661e-01, -1.39871944e+00,\n",
              "          -1.15880507e-01, -1.23896438e+00,  2.92696833e-01,\n",
              "          -2.06472009e-01, -1.34952031e+00,  5.33331987e-01,\n",
              "          -1.34506470e+00, -8.41420449e-01, -2.74652382e-01,\n",
              "           1.17148241e+00, -1.08356558e+00, -4.52225450e-01,\n",
              "          -9.40606071e-01,  9.57827766e-01,  6.04098747e-01,\n",
              "          -6.10966490e-01],\n",
              "         [ 1.38856151e-02,  6.03419494e-01,  1.21763768e+00,\n",
              "          -8.45463356e-01, -2.67843545e-01,  7.73456541e-01,\n",
              "           1.22731551e+00, -1.08954473e+00, -4.57404192e-01,\n",
              "          -1.54971666e+00,  8.98546469e-01, -3.80338366e-01,\n",
              "          -7.83126835e-01,  1.44662521e-02, -2.54788335e-01,\n",
              "           1.17846832e+00, -6.33349496e-01, -3.46283288e-01,\n",
              "          -1.38458416e+00,  8.38591351e-02,  8.06968457e-01,\n",
              "           1.28957145e+00,  4.77738237e-01, -3.72561452e-01,\n",
              "          -8.14557035e-01,  3.34525782e-01,  8.92769879e-01,\n",
              "          -1.24634128e+00,  1.17919721e+00,  1.42451395e-01,\n",
              "          -5.31868945e-01,  5.15431176e-01, -4.77976336e-01,\n",
              "          -3.29998990e-01,  8.08689809e-01,  1.08068169e+00,\n",
              "          -2.01932385e-01,  1.13426022e+00, -1.04693343e+00,\n",
              "          -6.45246717e-01, -1.07953795e+00,  8.24057970e-01,\n",
              "          -1.39516690e+00, -7.88832482e-01,  7.17286738e-01,\n",
              "           1.92354477e+00,  1.63608083e-01, -7.19421669e-01,\n",
              "           2.26126839e+00,  4.64922685e-01, -8.69271525e-02,\n",
              "           8.03738364e-01, -6.21639352e-01, -1.16023391e+00,\n",
              "           8.46636367e-01, -1.34798233e+00,  4.35443425e-01,\n",
              "           1.17958037e+00, -2.46591361e-01,  6.07791213e-01,\n",
              "           7.85642735e-01, -2.87091110e-01,  8.87639998e-01,\n",
              "          -4.92764888e-01, -1.18111202e+00, -1.13320237e+00,\n",
              "          -1.65474759e+00, -4.76680344e-01, -1.03908413e+00,\n",
              "           5.32695866e-01, -1.10320245e-02,  9.99225481e-01,\n",
              "           9.26739075e-02,  2.14485193e+00,  6.21865669e-01,\n",
              "           9.38893385e-01, -1.81720665e+00,  8.67950064e-01,\n",
              "          -5.72426717e-01, -1.60876113e-03,  1.08882181e+00,\n",
              "           1.94326636e-01, -1.59534280e+00,  1.16682251e+00,\n",
              "           4.30436834e-01,  3.64528612e-01, -9.31239025e-01,\n",
              "           1.01043421e-01, -1.49146857e+00,  1.04422099e+00,\n",
              "           7.97149745e-01,  5.41716309e-01,  1.71928576e+00,\n",
              "          -2.87411547e-01,  1.60420912e-01,  4.15300545e-01,\n",
              "          -2.57736367e-01,  5.72539672e-01,  1.42740064e+00,\n",
              "          -2.93186145e-01],\n",
              "         [-1.84147784e-01, -5.53370895e-02, -1.31441510e+00,\n",
              "           3.38784271e-01, -2.25359824e+00, -1.57553093e+00,\n",
              "           9.63648309e-02, -1.16600611e+00,  2.40254072e-01,\n",
              "           1.29770471e-01,  5.92458862e-02,  1.07355932e+00,\n",
              "           1.06511447e+00,  1.62551561e+00, -7.61962748e-01,\n",
              "           3.33584924e-01,  1.66867269e-01, -6.14554298e-02,\n",
              "           2.41499286e-01, -6.14785975e-01, -5.68061776e-01,\n",
              "           6.55507199e-01, -1.06323009e+00,  1.97483142e+00,\n",
              "          -6.95411680e-01, -6.69723795e-01,  3.95151204e-01,\n",
              "          -1.73674470e+00, -2.70894595e-01,  1.14813337e+00,\n",
              "          -6.57463572e-02, -2.50783046e-01, -3.74928366e-01,\n",
              "           5.96210349e-01, -1.11044317e+00, -2.52608299e+00,\n",
              "          -6.91408804e-01, -7.28922027e-01, -1.44912881e+00,\n",
              "          -1.62663931e+00,  8.08531486e-01, -6.16361085e-01,\n",
              "           1.82809532e-01,  4.94264336e-03, -2.71646694e+00,\n",
              "          -1.06921036e+00,  6.72898971e-01, -1.72084092e+00,\n",
              "           7.37559663e-01,  3.01715728e-01, -1.69295508e+00,\n",
              "           9.18822964e-04,  5.54924978e-01,  4.85542385e-01,\n",
              "           3.51005605e-01,  1.53289490e+00,  1.24575235e+00,\n",
              "          -3.59545664e-02,  6.04545344e-01, -5.45342334e-01,\n",
              "           1.00287437e-01, -5.66847755e-01,  5.49321716e-01,\n",
              "           5.30234856e-01, -5.91669248e-02,  5.52778766e-01,\n",
              "          -9.72537908e-02, -1.84089757e-01,  6.84994260e-01,\n",
              "          -2.41674846e-01,  9.12270931e-02, -2.06611409e+00,\n",
              "          -5.75797088e-01,  8.61749946e-01, -3.89963074e-01,\n",
              "          -1.14331623e+00, -5.66248353e-01,  4.33673985e-01,\n",
              "           3.16496099e-01,  1.04916074e+00,  2.59455511e-01,\n",
              "           2.31645917e+00, -8.01472734e-01, -1.74473347e+00,\n",
              "          -1.47692969e+00,  1.78699615e+00, -3.77179480e-01,\n",
              "           4.57076715e-01,  4.17665503e-02, -1.69567835e+00,\n",
              "          -4.83395430e-03, -2.68106086e-01,  9.22597216e-01,\n",
              "           1.48406866e-01, -9.25772290e-01,  3.75899591e-01,\n",
              "          -8.83534553e-01, -4.85259282e-01, -1.11029251e+00,\n",
              "          -1.72043612e+00],\n",
              "         [ 3.62103803e-01, -2.09692876e+00, -7.68750591e-01,\n",
              "          -1.90257906e+00,  7.65421006e-01,  1.30633511e+00,\n",
              "          -1.18498720e+00,  7.74561312e-01, -8.50587920e-01,\n",
              "           4.84649031e-01,  3.48067777e-01, -3.12425432e-03,\n",
              "           2.37694821e-01, -1.67555264e-01,  2.29732171e+00,\n",
              "          -4.31797034e-01, -1.01302010e+00, -1.16358823e-01,\n",
              "           1.84464138e-03,  4.61554705e-01, -5.68484350e-01,\n",
              "          -9.34468356e-01, -6.67091867e-01, -1.85744464e-01,\n",
              "          -2.86501455e+00,  6.46737808e-02, -4.85099737e-01,\n",
              "          -6.05419371e-01, -2.03343068e+00, -5.28415062e-01,\n",
              "          -1.96237704e+00,  6.20445626e-02,  7.00458320e-02,\n",
              "          -1.00506731e+00, -9.57764156e-01,  3.77826068e-01,\n",
              "          -1.03296981e+00, -9.64840565e-01,  8.04539120e-01,\n",
              "           9.36118655e-01, -1.08140642e+00,  1.55910641e+00,\n",
              "          -3.75029772e-03, -1.07937636e-01, -1.09084903e+00,\n",
              "           2.29597946e-01,  8.05519670e-01, -3.42376868e-01,\n",
              "           7.53131974e-01, -4.45146635e-01, -3.64819538e-01,\n",
              "           3.88442038e-01, -1.98864524e+00,  5.92639386e-01,\n",
              "          -7.37038009e-03, -1.03844147e+00, -2.68423396e+00,\n",
              "           2.03324525e+00, -1.36699666e-01, -9.42680894e-01,\n",
              "           8.19528694e-01, -8.69000445e-01,  1.54273050e-01,\n",
              "           1.52697254e+00, -6.21670156e-01, -7.33575061e-01,\n",
              "           6.45763932e-01, -7.35031161e-02, -4.68786965e-01,\n",
              "          -9.33656792e-01,  1.56207912e+00,  3.18858272e-01,\n",
              "           5.04921161e-01, -2.17239511e-01,  2.03765152e+00,\n",
              "           2.17992149e-01,  5.39805929e-03, -3.63176954e-01,\n",
              "           8.69725018e-01, -1.83893431e+00,  4.81021510e-01,\n",
              "           1.10102541e-01, -1.44134532e+00, -2.25823641e-01,\n",
              "           1.94402359e+00,  8.01699739e-01, -1.20294861e+00,\n",
              "           7.53189535e-01,  1.25368736e+00, -8.66195927e-01,\n",
              "           4.65659860e-01, -1.42661016e+00,  5.88263570e-02,\n",
              "          -1.44402489e+00,  1.61492663e+00,  3.06727744e-01,\n",
              "          -1.56741603e+00,  2.32832385e-01,  1.42783344e-01,\n",
              "          -3.26372292e-01],\n",
              "         [-1.00764608e+00, -1.02154574e+00,  1.19122071e-01,\n",
              "          -1.84047178e-02, -1.65406587e-01,  1.03672504e+00,\n",
              "           1.50030218e+00,  1.79358503e-01,  1.70361216e-03,\n",
              "           2.41682496e-01,  2.82877901e-02,  1.09157788e+00,\n",
              "          -7.97977706e-01,  2.37428552e-01, -8.81212168e-01,\n",
              "          -6.25878849e-01,  9.62470175e-01, -1.19144793e+00,\n",
              "           1.94329964e+00,  2.18933858e-01,  3.34212513e-02,\n",
              "          -3.13312704e-01, -3.53534832e-01, -1.49399201e+00,\n",
              "          -1.04858246e+00, -2.81571839e+00,  6.16557842e-01,\n",
              "           4.36060685e-01,  6.99235478e-01,  5.64751909e-01,\n",
              "           2.01097607e+00,  1.76613500e-01, -4.57208694e-01,\n",
              "           2.21832885e+00, -9.87271646e-02, -7.15156964e-02,\n",
              "           6.96928566e-01,  1.65954127e+00,  1.45765453e+00,\n",
              "          -6.19279776e-01,  9.65654358e-01,  9.46048634e-02,\n",
              "          -2.49034282e+00, -4.55147331e-01,  1.45473348e+00,\n",
              "           5.77086149e-01,  6.85874802e-01,  3.86316035e-01,\n",
              "          -2.26580493e-01,  6.72157156e-01,  2.18288176e+00,\n",
              "           4.04284750e-01, -1.25029969e+00,  6.74309941e-01,\n",
              "          -2.33850271e-01, -5.49918345e-01,  2.00206850e+00,\n",
              "           5.98065096e-02, -9.62552820e-01,  2.03385531e+00,\n",
              "          -1.11661715e+00,  1.66124165e+00,  2.62376020e-01,\n",
              "           1.91541515e-01,  5.65576745e-02, -6.03386077e-01,\n",
              "          -7.85190562e-01,  6.22891934e-01,  1.87833581e-01,\n",
              "           8.31710029e-01,  1.10195106e+00,  5.87657155e-01,\n",
              "          -7.96715422e-01, -1.27551694e+00, -1.02068513e+00,\n",
              "          -5.55680253e-01,  1.20945836e+00,  2.40596014e-01,\n",
              "           6.26581676e-01,  1.12861343e+00,  3.06967987e-01,\n",
              "           1.00047041e+00,  7.78410127e-01, -6.11595203e-01,\n",
              "           6.04118868e-01,  1.16534517e+00,  1.30608147e-01,\n",
              "          -7.82334715e-01, -8.24023895e-01, -1.28774200e+00,\n",
              "           3.99883736e-01,  1.57470530e+00,  6.41508412e-01,\n",
              "           3.34966302e+00, -1.02467746e+00, -1.12434767e-01,\n",
              "          -1.35724187e+00,  2.85762354e-01, -1.07910566e+00,\n",
              "          -1.23422773e+00],\n",
              "         [-5.98966259e-01, -9.96267875e-01, -8.97340107e-01,\n",
              "          -6.93688523e-01,  2.13316455e+00,  1.81073455e+00,\n",
              "          -5.93220129e-01,  6.49601203e-01, -4.48252703e-01,\n",
              "           9.37261044e-01, -1.02824850e+00, -8.99497617e-01,\n",
              "          -1.37441503e-01, -4.90480204e-01,  1.04703965e+00,\n",
              "           8.26723081e-01,  6.89208287e-01, -1.47511813e-01,\n",
              "          -2.60838325e+00, -3.76601930e-01,  1.92950044e+00,\n",
              "           3.52090519e-01, -1.59583305e+00, -1.30607607e+00,\n",
              "           6.15655021e-01,  1.35546705e-01,  9.00868618e-01,\n",
              "          -6.17666385e-01, -8.31041390e-01, -1.56631964e-01,\n",
              "          -8.36055605e-02, -7.53421890e-01, -1.21461093e+00,\n",
              "          -6.94815789e-01,  8.85826695e-01, -1.61553067e+00,\n",
              "          -2.10450836e+00,  2.99986552e-01, -5.38686902e-01,\n",
              "          -1.42449325e+00, -9.88130523e-01,  5.89182452e-01,\n",
              "           1.41032754e+00, -1.12222748e+00,  2.30979952e-01,\n",
              "           7.03358407e-01,  6.50096821e-01, -1.02484527e+00,\n",
              "          -7.27743967e-01,  4.85820509e-01, -5.40331308e-01,\n",
              "          -2.46939827e+00, -9.19515485e-01, -2.27102706e-01,\n",
              "          -8.30727007e-01,  1.04676881e+00, -4.69621484e-01,\n",
              "          -5.41333299e-01,  2.37181242e+00,  1.60917490e+00,\n",
              "          -3.37663656e-01, -2.59805294e-01,  6.81037281e-01,\n",
              "          -8.82945974e-01, -6.46315172e-01,  1.10136758e+00,\n",
              "          -2.08677975e-01, -5.66203732e-01,  6.22846759e-01,\n",
              "          -7.43333447e-01, -1.08448371e+00,  5.30500971e-01,\n",
              "          -3.14103061e-01, -1.45817375e-01, -2.64887377e-01,\n",
              "           1.55352980e+00, -1.13409549e+00,  5.27633914e-01,\n",
              "          -6.42263517e-01,  6.28858029e-01,  5.82930305e-01,\n",
              "          -4.39033090e-01,  2.86920814e-01,  8.63657341e-01,\n",
              "           3.31213007e-01, -2.66328706e-01,  1.56738477e-02,\n",
              "           2.07533338e-01, -1.49273920e+00,  9.84332731e-01,\n",
              "          -8.37892009e-01,  2.22889882e-01, -8.54903722e-01,\n",
              "          -3.57317979e-01, -3.78710119e-01,  2.14758093e-01,\n",
              "           3.92721719e-02,  1.47018513e+00,  7.68911634e-02,\n",
              "          -5.23735960e-01],\n",
              "         [ 1.52689900e+00,  5.80139388e-01, -1.45250915e+00,\n",
              "           3.04326665e-01, -1.48022921e-01,  5.29201094e-01,\n",
              "          -7.05801673e-02,  1.64077954e+00, -4.62713687e-01,\n",
              "          -1.72598768e+00,  8.51112280e-01,  3.61190811e-01,\n",
              "           6.19965287e-01,  3.72407196e-01,  1.80553859e-01,\n",
              "           3.20682050e-01,  1.07477471e+00,  1.96279730e+00,\n",
              "          -1.46564146e-01,  2.13000509e-01, -2.39787961e-01,\n",
              "          -1.63599541e+00, -5.28327539e-01, -9.53227336e-01,\n",
              "          -2.42357721e+00, -1.54309303e+00, -1.39710457e-01,\n",
              "          -2.43429978e-01, -4.44449529e-01, -3.70690571e-01,\n",
              "          -6.91289250e-01, -1.27013538e+00, -8.39056237e-01,\n",
              "           2.44753407e-01,  1.01081959e+00,  1.19771890e+00,\n",
              "           1.50991252e+00, -1.22528152e+00,  1.28174613e+00,\n",
              "           5.58427209e-01, -2.78876491e-01,  1.09619078e+00,\n",
              "           6.22916720e-01,  1.29296454e+00,  6.43853563e-01,\n",
              "          -5.86299027e-01, -8.21423113e-02, -5.59538395e-01,\n",
              "           1.79292534e-01,  7.19261547e-02,  1.14513886e-01,\n",
              "           8.88374746e-01, -7.72490175e-01,  2.10379733e-02,\n",
              "          -1.04193443e+00, -7.96628267e-01, -2.84186799e+00,\n",
              "          -1.27410526e+00, -7.96590628e-01,  2.67031898e-01,\n",
              "          -1.36664594e+00,  8.66947410e-01,  8.70016264e-01,\n",
              "          -6.77990222e-01,  2.87149682e-01,  6.72594732e-01,\n",
              "           6.35291863e-01,  7.23342394e-01,  8.45169023e-01,\n",
              "           1.92175768e-01,  7.86280503e-01, -1.62018553e-01,\n",
              "           1.10783520e+00,  1.25183180e+00,  1.06303203e+00,\n",
              "          -9.07052418e-01, -2.30370118e-01, -1.74384976e-01,\n",
              "           1.88541769e-01, -6.16209158e-01,  5.30705316e-01,\n",
              "          -2.10598629e+00,  1.49538570e+00, -9.97603867e-01,\n",
              "          -1.09283020e+00, -4.76829014e-01, -1.52566382e+00,\n",
              "          -1.73501642e-01,  4.49028255e-01, -1.18943193e-01,\n",
              "          -1.53077840e+00, -6.84332828e-01,  7.06794323e-01,\n",
              "          -1.68141196e+00, -6.65358464e-01, -4.55862284e-01,\n",
              "           1.11313449e+00,  4.32042016e-01, -9.89901499e-01,\n",
              "          -2.71249769e+00]]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  None]]"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(100, activation='sigmoid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[array([[ 4.50796424e-01, -5.00929339e-01,  2.05825472e+00,\n",
              "          -3.80416321e-01, -1.20361746e+00, -1.04143371e+00,\n",
              "           3.45821278e-01,  7.24775494e-01, -6.39350169e-01,\n",
              "           3.18077223e-01, -1.33124096e+00, -2.88492404e-01,\n",
              "           3.21537676e-01, -2.28877113e-02, -8.39977121e-01,\n",
              "           1.18586716e+00, -8.40727375e-01,  7.86241628e-01,\n",
              "           2.43817777e-01, -9.75119155e-01,  4.27529387e-01,\n",
              "          -5.10860857e-01, -5.82651088e-02,  4.12936912e-01,\n",
              "          -6.05740690e-01, -8.63884275e-01, -9.13760874e-01,\n",
              "           1.29221210e+00,  3.26497394e-01,  1.77356315e+00,\n",
              "          -4.81318687e-01,  1.26198024e-01, -5.01955485e-01,\n",
              "           1.38014738e+00,  1.44837732e+00,  1.08275830e-01,\n",
              "           8.93125771e-01,  1.18508747e+00, -1.13657461e+00,\n",
              "          -8.68016149e-01, -6.19008931e-01, -7.92826412e-01,\n",
              "          -4.99150532e-01,  1.71336134e+00,  3.18261551e-01,\n",
              "          -1.85403023e+00, -9.01099647e-01, -7.88068883e-01,\n",
              "           8.41074354e-01,  2.72980614e-01, -6.65741589e-01,\n",
              "          -2.30075048e+00,  1.04472660e+00,  9.04476057e-01,\n",
              "           4.92809224e-01,  7.68232100e-02,  4.91132593e-01,\n",
              "           1.42418669e+00, -1.70899439e+00, -2.44435102e-01,\n",
              "          -1.30888292e+00, -3.22853663e-01,  4.42702255e-01,\n",
              "          -1.99976829e+00,  9.48789253e-01,  4.52543339e-01,\n",
              "          -1.73096696e+00,  1.67797903e-01,  2.27028205e-01,\n",
              "           2.00604077e+00,  7.39723270e-01,  1.59512080e+00,\n",
              "          -7.84946509e-01, -1.82326759e+00,  9.39864346e-01,\n",
              "          -1.28294237e+00, -8.18123536e-01, -4.88809277e-01,\n",
              "          -2.34981944e-01, -1.50403048e+00,  2.20903582e-01,\n",
              "           2.92921377e-01, -5.90718982e-01,  9.55667022e-02,\n",
              "           3.57904680e-01, -1.80559899e-01, -2.14231840e+00,\n",
              "          -5.09110706e-01, -5.39365112e-01,  4.04602641e-01,\n",
              "          -8.27804480e-01,  4.73763137e-01,  2.12331764e-01,\n",
              "          -1.33853853e+00, -1.53705133e+00,  1.32166334e-01,\n",
              "           5.54221034e-01, -9.47282259e-01,  1.73892483e+00,\n",
              "           4.37692367e-01],\n",
              "         [ 5.72836580e-03, -1.33370754e+00, -1.68431474e+00,\n",
              "           1.40176978e+00, -6.61861347e-01, -9.47474136e-01,\n",
              "          -4.76178782e-01,  3.34384051e-01,  4.48444589e-01,\n",
              "          -7.09255300e-01, -1.08186241e+00, -1.21989080e+00,\n",
              "          -7.25651372e-01, -8.07168976e-02, -9.42809092e-01,\n",
              "           6.30981655e-01,  6.84267642e-01, -2.89603652e-01,\n",
              "          -4.87140011e-01, -1.10599503e+00,  3.54697494e-02,\n",
              "          -1.10888019e-02,  2.36174793e-02,  1.52224909e+00,\n",
              "           1.04576745e+00,  2.73407213e+00, -9.44413889e-01,\n",
              "           1.03667019e+00, -5.36750601e-01,  1.28890389e+00,\n",
              "           1.39602286e+00, -7.51315732e-01, -1.04368975e+00,\n",
              "          -4.93087090e-01,  6.50482734e-01,  5.10839619e-02,\n",
              "          -4.64188029e-02, -8.25586220e-02,  7.91322152e-01,\n",
              "          -4.72315099e-01, -2.10992450e+00, -2.73366429e-01,\n",
              "           4.38015120e-01, -1.36173108e+00, -1.50553292e+00,\n",
              "           5.88287558e-01, -1.20822387e+00, -3.35540767e-01,\n",
              "           1.03392762e+00,  1.37373079e+00, -4.33550384e-02,\n",
              "           6.32229056e-01, -4.89790543e-02, -7.79913274e-01,\n",
              "           3.12483751e-03, -1.90781866e+00,  1.87080508e-02,\n",
              "          -8.06640706e-01,  8.94565242e-01, -9.84166499e-01,\n",
              "          -9.46000261e-02,  9.97142188e-01,  1.28641757e+00,\n",
              "           1.68652315e+00,  1.48897882e+00,  6.82600316e-01,\n",
              "          -2.26168769e-01,  5.54876890e-01, -1.24346794e+00,\n",
              "           8.74622332e-01, -5.26932316e-01,  1.49705569e+00,\n",
              "          -1.23316540e+00, -1.41602524e-01, -3.58399530e-01,\n",
              "           3.85309299e-01, -1.44132259e+00, -1.22820038e+00,\n",
              "           5.87280983e-01,  3.25925336e-01, -1.29390911e+00,\n",
              "          -9.90836281e-01,  5.02915726e-01, -5.70537442e-01,\n",
              "          -1.77362146e+00, -2.02395463e+00, -7.82939301e-01,\n",
              "          -2.12572742e-01, -7.79944584e-03,  2.65111433e-01,\n",
              "           7.83193654e-01,  6.38360029e-01, -2.21579258e+00,\n",
              "          -3.53321948e-02,  8.37204631e-02,  6.21962345e-01,\n",
              "           2.19676964e-01, -2.99293112e-01, -5.09476512e-03,\n",
              "          -7.18333243e-01],\n",
              "         [-5.37435466e-01,  4.56354712e-01, -1.22101786e+00,\n",
              "          -1.06501373e+00, -6.59630491e-01,  5.06010104e-01,\n",
              "          -2.00640398e-01,  2.07498673e-01, -3.27447621e-01,\n",
              "           2.38431241e+00,  6.55890840e-02, -1.19881580e+00,\n",
              "          -8.96664509e-01,  9.34107351e-01, -3.82017048e-01,\n",
              "          -4.87057333e-01,  5.28042339e-02, -1.00884544e+00,\n",
              "           9.51273341e-02,  6.95174987e-01,  5.44766831e-02,\n",
              "           3.35483400e-01, -1.05534530e+00,  2.20360883e-02,\n",
              "          -5.40390733e-01, -1.16358603e+00,  5.45301961e-01,\n",
              "          -9.37756711e-01,  2.26176670e-01, -6.60477630e-01,\n",
              "          -2.56575243e-02, -7.35405692e-01,  6.16616274e-02,\n",
              "           1.81212519e+00,  6.03171566e-01,  1.53065217e-02,\n",
              "           3.21310337e-02,  3.20590508e-01,  7.93103913e-01,\n",
              "           1.51161025e+00,  3.07725874e-01,  7.69588569e-01,\n",
              "           9.39385356e-01,  1.96292077e+00, -1.55165024e+00,\n",
              "           1.48571182e+00,  1.72951929e-01,  4.78635505e-01,\n",
              "          -7.99115658e-02, -3.89054959e-01,  1.60849155e+00,\n",
              "          -5.77963179e-01, -1.87511803e-01,  1.95110634e-01,\n",
              "          -5.19218693e-01, -1.48339172e-02,  2.63710438e-01,\n",
              "           1.11336846e+00, -1.08619733e+00, -8.80351564e-01,\n",
              "           4.19729894e-01, -6.82854256e-01, -5.97554433e-01,\n",
              "           1.55450231e+00,  5.91975434e-02,  1.92632306e-01,\n",
              "          -8.06096769e-01,  4.71697303e-01, -9.04999421e-01,\n",
              "          -5.68372068e-01,  4.86944910e-01, -5.74947220e-01,\n",
              "           5.81778490e-01,  9.55093015e-01,  2.34081916e-01,\n",
              "          -4.07730051e-01,  6.29362661e-01,  5.89117617e-01,\n",
              "           3.59804627e-01, -1.70632765e-01,  1.44611324e+00,\n",
              "           9.52888732e-01, -1.19918449e+00,  6.44755343e-01,\n",
              "           1.60377231e+00, -6.30362915e-01, -5.24373336e-01,\n",
              "          -3.80277756e-01,  1.66641160e+00, -1.91730948e+00,\n",
              "           6.63161006e-01, -1.37693422e+00,  3.54418078e-01,\n",
              "           1.10740336e+00, -2.07121393e-01,  5.53103151e-01,\n",
              "          -1.33801088e+00,  2.26826137e+00, -1.89549836e+00,\n",
              "           3.62688165e-01],\n",
              "         [ 2.35760754e-02,  7.99555784e-01, -8.39994036e-01,\n",
              "          -1.25397359e+00, -2.13312231e+00, -1.05989093e-01,\n",
              "          -1.02744579e+00,  8.53344025e-01, -2.92539579e-01,\n",
              "           1.22961827e+00, -9.68321861e-01, -3.15023525e-01,\n",
              "           4.20098930e-01,  6.83701290e-01, -2.27477075e+00,\n",
              "          -1.03257609e-01,  1.02464094e+00,  2.97205794e-01,\n",
              "          -5.84601463e-03,  1.07560779e+00,  2.82596920e-01,\n",
              "          -8.77885855e-01, -1.01781209e+00,  6.01954672e-01,\n",
              "          -2.37799373e-01,  1.18314460e+00, -1.39870629e+00,\n",
              "           1.01281511e+00,  7.22294764e-01, -9.35321948e-01,\n",
              "           7.93894686e-01, -6.65366935e-01, -1.04250159e+00,\n",
              "           8.10424180e-01,  5.01441939e-01, -7.54485704e-01,\n",
              "          -1.08377909e+00,  2.42702692e-01,  5.73774757e-01,\n",
              "          -1.32574435e+00, -8.96542171e-01,  1.79828807e+00,\n",
              "          -3.37906755e-01,  8.15939171e-02,  6.19146429e-01,\n",
              "          -1.36092717e+00, -8.79581148e-01,  1.06810370e+00,\n",
              "          -6.07114549e-01,  1.12031595e-01, -1.20167866e+00,\n",
              "           3.56442605e-01, -1.35151743e+00,  1.89800088e+00,\n",
              "           4.68153026e-01, -1.19371290e+00,  6.21917697e-02,\n",
              "          -6.35281621e-01,  9.67145033e-01,  1.74020365e-01,\n",
              "          -1.01089869e+00,  7.34459268e-01,  6.74669710e-02,\n",
              "          -7.24455183e-01, -2.17824533e+00,  1.16224496e+00,\n",
              "           2.44620474e+00,  9.97066964e-02, -7.46471093e-01,\n",
              "           3.33057268e-01, -1.97036640e-01,  1.26541646e+00,\n",
              "           1.16125446e+00, -6.90463886e-01,  1.03235737e+00,\n",
              "           1.64868847e+00, -1.14015691e+00,  1.53478186e+00,\n",
              "          -1.18529364e+00, -3.66262850e-01,  1.96062618e-01,\n",
              "           9.06306674e-01,  2.10587661e-01, -1.39871944e+00,\n",
              "          -1.15880507e-01, -1.23896438e+00,  2.92696833e-01,\n",
              "          -2.06472009e-01, -1.34952031e+00,  5.33331987e-01,\n",
              "          -1.34506470e+00, -8.41420449e-01, -2.74652382e-01,\n",
              "           1.17148241e+00, -1.08356558e+00, -4.52225450e-01,\n",
              "          -9.40606071e-01,  9.57827766e-01,  6.04098747e-01,\n",
              "          -6.10966490e-01],\n",
              "         [ 1.38856151e-02,  6.03419494e-01,  1.21763768e+00,\n",
              "          -8.45463356e-01, -2.67843545e-01,  7.73456541e-01,\n",
              "           1.22731551e+00, -1.08954473e+00, -4.57404192e-01,\n",
              "          -1.54971666e+00,  8.98546469e-01, -3.80338366e-01,\n",
              "          -7.83126835e-01,  1.44662521e-02, -2.54788335e-01,\n",
              "           1.17846832e+00, -6.33349496e-01, -3.46283288e-01,\n",
              "          -1.38458416e+00,  8.38591351e-02,  8.06968457e-01,\n",
              "           1.28957145e+00,  4.77738237e-01, -3.72561452e-01,\n",
              "          -8.14557035e-01,  3.34525782e-01,  8.92769879e-01,\n",
              "          -1.24634128e+00,  1.17919721e+00,  1.42451395e-01,\n",
              "          -5.31868945e-01,  5.15431176e-01, -4.77976336e-01,\n",
              "          -3.29998990e-01,  8.08689809e-01,  1.08068169e+00,\n",
              "          -2.01932385e-01,  1.13426022e+00, -1.04693343e+00,\n",
              "          -6.45246717e-01, -1.07953795e+00,  8.24057970e-01,\n",
              "          -1.39516690e+00, -7.88832482e-01,  7.17286738e-01,\n",
              "           1.92354477e+00,  1.63608083e-01, -7.19421669e-01,\n",
              "           2.26126839e+00,  4.64922685e-01, -8.69271525e-02,\n",
              "           8.03738364e-01, -6.21639352e-01, -1.16023391e+00,\n",
              "           8.46636367e-01, -1.34798233e+00,  4.35443425e-01,\n",
              "           1.17958037e+00, -2.46591361e-01,  6.07791213e-01,\n",
              "           7.85642735e-01, -2.87091110e-01,  8.87639998e-01,\n",
              "          -4.92764888e-01, -1.18111202e+00, -1.13320237e+00,\n",
              "          -1.65474759e+00, -4.76680344e-01, -1.03908413e+00,\n",
              "           5.32695866e-01, -1.10320245e-02,  9.99225481e-01,\n",
              "           9.26739075e-02,  2.14485193e+00,  6.21865669e-01,\n",
              "           9.38893385e-01, -1.81720665e+00,  8.67950064e-01,\n",
              "          -5.72426717e-01, -1.60876113e-03,  1.08882181e+00,\n",
              "           1.94326636e-01, -1.59534280e+00,  1.16682251e+00,\n",
              "           4.30436834e-01,  3.64528612e-01, -9.31239025e-01,\n",
              "           1.01043421e-01, -1.49146857e+00,  1.04422099e+00,\n",
              "           7.97149745e-01,  5.41716309e-01,  1.71928576e+00,\n",
              "          -2.87411547e-01,  1.60420912e-01,  4.15300545e-01,\n",
              "          -2.57736367e-01,  5.72539672e-01,  1.42740064e+00,\n",
              "          -2.93186145e-01],\n",
              "         [-1.84147784e-01, -5.53370895e-02, -1.31441510e+00,\n",
              "           3.38784271e-01, -2.25359824e+00, -1.57553093e+00,\n",
              "           9.63648309e-02, -1.16600611e+00,  2.40254072e-01,\n",
              "           1.29770471e-01,  5.92458862e-02,  1.07355932e+00,\n",
              "           1.06511447e+00,  1.62551561e+00, -7.61962748e-01,\n",
              "           3.33584924e-01,  1.66867269e-01, -6.14554298e-02,\n",
              "           2.41499286e-01, -6.14785975e-01, -5.68061776e-01,\n",
              "           6.55507199e-01, -1.06323009e+00,  1.97483142e+00,\n",
              "          -6.95411680e-01, -6.69723795e-01,  3.95151204e-01,\n",
              "          -1.73674470e+00, -2.70894595e-01,  1.14813337e+00,\n",
              "          -6.57463572e-02, -2.50783046e-01, -3.74928366e-01,\n",
              "           5.96210349e-01, -1.11044317e+00, -2.52608299e+00,\n",
              "          -6.91408804e-01, -7.28922027e-01, -1.44912881e+00,\n",
              "          -1.62663931e+00,  8.08531486e-01, -6.16361085e-01,\n",
              "           1.82809532e-01,  4.94264336e-03, -2.71646694e+00,\n",
              "          -1.06921036e+00,  6.72898971e-01, -1.72084092e+00,\n",
              "           7.37559663e-01,  3.01715728e-01, -1.69295508e+00,\n",
              "           9.18822964e-04,  5.54924978e-01,  4.85542385e-01,\n",
              "           3.51005605e-01,  1.53289490e+00,  1.24575235e+00,\n",
              "          -3.59545664e-02,  6.04545344e-01, -5.45342334e-01,\n",
              "           1.00287437e-01, -5.66847755e-01,  5.49321716e-01,\n",
              "           5.30234856e-01, -5.91669248e-02,  5.52778766e-01,\n",
              "          -9.72537908e-02, -1.84089757e-01,  6.84994260e-01,\n",
              "          -2.41674846e-01,  9.12270931e-02, -2.06611409e+00,\n",
              "          -5.75797088e-01,  8.61749946e-01, -3.89963074e-01,\n",
              "          -1.14331623e+00, -5.66248353e-01,  4.33673985e-01,\n",
              "           3.16496099e-01,  1.04916074e+00,  2.59455511e-01,\n",
              "           2.31645917e+00, -8.01472734e-01, -1.74473347e+00,\n",
              "          -1.47692969e+00,  1.78699615e+00, -3.77179480e-01,\n",
              "           4.57076715e-01,  4.17665503e-02, -1.69567835e+00,\n",
              "          -4.83395430e-03, -2.68106086e-01,  9.22597216e-01,\n",
              "           1.48406866e-01, -9.25772290e-01,  3.75899591e-01,\n",
              "          -8.83534553e-01, -4.85259282e-01, -1.11029251e+00,\n",
              "          -1.72043612e+00],\n",
              "         [ 3.62103803e-01, -2.09692876e+00, -7.68750591e-01,\n",
              "          -1.90257906e+00,  7.65421006e-01,  1.30633511e+00,\n",
              "          -1.18498720e+00,  7.74561312e-01, -8.50587920e-01,\n",
              "           4.84649031e-01,  3.48067777e-01, -3.12425432e-03,\n",
              "           2.37694821e-01, -1.67555264e-01,  2.29732171e+00,\n",
              "          -4.31797034e-01, -1.01302010e+00, -1.16358823e-01,\n",
              "           1.84464138e-03,  4.61554705e-01, -5.68484350e-01,\n",
              "          -9.34468356e-01, -6.67091867e-01, -1.85744464e-01,\n",
              "          -2.86501455e+00,  6.46737808e-02, -4.85099737e-01,\n",
              "          -6.05419371e-01, -2.03343068e+00, -5.28415062e-01,\n",
              "          -1.96237704e+00,  6.20445626e-02,  7.00458320e-02,\n",
              "          -1.00506731e+00, -9.57764156e-01,  3.77826068e-01,\n",
              "          -1.03296981e+00, -9.64840565e-01,  8.04539120e-01,\n",
              "           9.36118655e-01, -1.08140642e+00,  1.55910641e+00,\n",
              "          -3.75029772e-03, -1.07937636e-01, -1.09084903e+00,\n",
              "           2.29597946e-01,  8.05519670e-01, -3.42376868e-01,\n",
              "           7.53131974e-01, -4.45146635e-01, -3.64819538e-01,\n",
              "           3.88442038e-01, -1.98864524e+00,  5.92639386e-01,\n",
              "          -7.37038009e-03, -1.03844147e+00, -2.68423396e+00,\n",
              "           2.03324525e+00, -1.36699666e-01, -9.42680894e-01,\n",
              "           8.19528694e-01, -8.69000445e-01,  1.54273050e-01,\n",
              "           1.52697254e+00, -6.21670156e-01, -7.33575061e-01,\n",
              "           6.45763932e-01, -7.35031161e-02, -4.68786965e-01,\n",
              "          -9.33656792e-01,  1.56207912e+00,  3.18858272e-01,\n",
              "           5.04921161e-01, -2.17239511e-01,  2.03765152e+00,\n",
              "           2.17992149e-01,  5.39805929e-03, -3.63176954e-01,\n",
              "           8.69725018e-01, -1.83893431e+00,  4.81021510e-01,\n",
              "           1.10102541e-01, -1.44134532e+00, -2.25823641e-01,\n",
              "           1.94402359e+00,  8.01699739e-01, -1.20294861e+00,\n",
              "           7.53189535e-01,  1.25368736e+00, -8.66195927e-01,\n",
              "           4.65659860e-01, -1.42661016e+00,  5.88263570e-02,\n",
              "          -1.44402489e+00,  1.61492663e+00,  3.06727744e-01,\n",
              "          -1.56741603e+00,  2.32832385e-01,  1.42783344e-01,\n",
              "          -3.26372292e-01],\n",
              "         [-1.00764608e+00, -1.02154574e+00,  1.19122071e-01,\n",
              "          -1.84047178e-02, -1.65406587e-01,  1.03672504e+00,\n",
              "           1.50030218e+00,  1.79358503e-01,  1.70361216e-03,\n",
              "           2.41682496e-01,  2.82877901e-02,  1.09157788e+00,\n",
              "          -7.97977706e-01,  2.37428552e-01, -8.81212168e-01,\n",
              "          -6.25878849e-01,  9.62470175e-01, -1.19144793e+00,\n",
              "           1.94329964e+00,  2.18933858e-01,  3.34212513e-02,\n",
              "          -3.13312704e-01, -3.53534832e-01, -1.49399201e+00,\n",
              "          -1.04858246e+00, -2.81571839e+00,  6.16557842e-01,\n",
              "           4.36060685e-01,  6.99235478e-01,  5.64751909e-01,\n",
              "           2.01097607e+00,  1.76613500e-01, -4.57208694e-01,\n",
              "           2.21832885e+00, -9.87271646e-02, -7.15156964e-02,\n",
              "           6.96928566e-01,  1.65954127e+00,  1.45765453e+00,\n",
              "          -6.19279776e-01,  9.65654358e-01,  9.46048634e-02,\n",
              "          -2.49034282e+00, -4.55147331e-01,  1.45473348e+00,\n",
              "           5.77086149e-01,  6.85874802e-01,  3.86316035e-01,\n",
              "          -2.26580493e-01,  6.72157156e-01,  2.18288176e+00,\n",
              "           4.04284750e-01, -1.25029969e+00,  6.74309941e-01,\n",
              "          -2.33850271e-01, -5.49918345e-01,  2.00206850e+00,\n",
              "           5.98065096e-02, -9.62552820e-01,  2.03385531e+00,\n",
              "          -1.11661715e+00,  1.66124165e+00,  2.62376020e-01,\n",
              "           1.91541515e-01,  5.65576745e-02, -6.03386077e-01,\n",
              "          -7.85190562e-01,  6.22891934e-01,  1.87833581e-01,\n",
              "           8.31710029e-01,  1.10195106e+00,  5.87657155e-01,\n",
              "          -7.96715422e-01, -1.27551694e+00, -1.02068513e+00,\n",
              "          -5.55680253e-01,  1.20945836e+00,  2.40596014e-01,\n",
              "           6.26581676e-01,  1.12861343e+00,  3.06967987e-01,\n",
              "           1.00047041e+00,  7.78410127e-01, -6.11595203e-01,\n",
              "           6.04118868e-01,  1.16534517e+00,  1.30608147e-01,\n",
              "          -7.82334715e-01, -8.24023895e-01, -1.28774200e+00,\n",
              "           3.99883736e-01,  1.57470530e+00,  6.41508412e-01,\n",
              "           3.34966302e+00, -1.02467746e+00, -1.12434767e-01,\n",
              "          -1.35724187e+00,  2.85762354e-01, -1.07910566e+00,\n",
              "          -1.23422773e+00],\n",
              "         [-5.98966259e-01, -9.96267875e-01, -8.97340107e-01,\n",
              "          -6.93688523e-01,  2.13316455e+00,  1.81073455e+00,\n",
              "          -5.93220129e-01,  6.49601203e-01, -4.48252703e-01,\n",
              "           9.37261044e-01, -1.02824850e+00, -8.99497617e-01,\n",
              "          -1.37441503e-01, -4.90480204e-01,  1.04703965e+00,\n",
              "           8.26723081e-01,  6.89208287e-01, -1.47511813e-01,\n",
              "          -2.60838325e+00, -3.76601930e-01,  1.92950044e+00,\n",
              "           3.52090519e-01, -1.59583305e+00, -1.30607607e+00,\n",
              "           6.15655021e-01,  1.35546705e-01,  9.00868618e-01,\n",
              "          -6.17666385e-01, -8.31041390e-01, -1.56631964e-01,\n",
              "          -8.36055605e-02, -7.53421890e-01, -1.21461093e+00,\n",
              "          -6.94815789e-01,  8.85826695e-01, -1.61553067e+00,\n",
              "          -2.10450836e+00,  2.99986552e-01, -5.38686902e-01,\n",
              "          -1.42449325e+00, -9.88130523e-01,  5.89182452e-01,\n",
              "           1.41032754e+00, -1.12222748e+00,  2.30979952e-01,\n",
              "           7.03358407e-01,  6.50096821e-01, -1.02484527e+00,\n",
              "          -7.27743967e-01,  4.85820509e-01, -5.40331308e-01,\n",
              "          -2.46939827e+00, -9.19515485e-01, -2.27102706e-01,\n",
              "          -8.30727007e-01,  1.04676881e+00, -4.69621484e-01,\n",
              "          -5.41333299e-01,  2.37181242e+00,  1.60917490e+00,\n",
              "          -3.37663656e-01, -2.59805294e-01,  6.81037281e-01,\n",
              "          -8.82945974e-01, -6.46315172e-01,  1.10136758e+00,\n",
              "          -2.08677975e-01, -5.66203732e-01,  6.22846759e-01,\n",
              "          -7.43333447e-01, -1.08448371e+00,  5.30500971e-01,\n",
              "          -3.14103061e-01, -1.45817375e-01, -2.64887377e-01,\n",
              "           1.55352980e+00, -1.13409549e+00,  5.27633914e-01,\n",
              "          -6.42263517e-01,  6.28858029e-01,  5.82930305e-01,\n",
              "          -4.39033090e-01,  2.86920814e-01,  8.63657341e-01,\n",
              "           3.31213007e-01, -2.66328706e-01,  1.56738477e-02,\n",
              "           2.07533338e-01, -1.49273920e+00,  9.84332731e-01,\n",
              "          -8.37892009e-01,  2.22889882e-01, -8.54903722e-01,\n",
              "          -3.57317979e-01, -3.78710119e-01,  2.14758093e-01,\n",
              "           3.92721719e-02,  1.47018513e+00,  7.68911634e-02,\n",
              "          -5.23735960e-01],\n",
              "         [ 1.52689900e+00,  5.80139388e-01, -1.45250915e+00,\n",
              "           3.04326665e-01, -1.48022921e-01,  5.29201094e-01,\n",
              "          -7.05801673e-02,  1.64077954e+00, -4.62713687e-01,\n",
              "          -1.72598768e+00,  8.51112280e-01,  3.61190811e-01,\n",
              "           6.19965287e-01,  3.72407196e-01,  1.80553859e-01,\n",
              "           3.20682050e-01,  1.07477471e+00,  1.96279730e+00,\n",
              "          -1.46564146e-01,  2.13000509e-01, -2.39787961e-01,\n",
              "          -1.63599541e+00, -5.28327539e-01, -9.53227336e-01,\n",
              "          -2.42357721e+00, -1.54309303e+00, -1.39710457e-01,\n",
              "          -2.43429978e-01, -4.44449529e-01, -3.70690571e-01,\n",
              "          -6.91289250e-01, -1.27013538e+00, -8.39056237e-01,\n",
              "           2.44753407e-01,  1.01081959e+00,  1.19771890e+00,\n",
              "           1.50991252e+00, -1.22528152e+00,  1.28174613e+00,\n",
              "           5.58427209e-01, -2.78876491e-01,  1.09619078e+00,\n",
              "           6.22916720e-01,  1.29296454e+00,  6.43853563e-01,\n",
              "          -5.86299027e-01, -8.21423113e-02, -5.59538395e-01,\n",
              "           1.79292534e-01,  7.19261547e-02,  1.14513886e-01,\n",
              "           8.88374746e-01, -7.72490175e-01,  2.10379733e-02,\n",
              "          -1.04193443e+00, -7.96628267e-01, -2.84186799e+00,\n",
              "          -1.27410526e+00, -7.96590628e-01,  2.67031898e-01,\n",
              "          -1.36664594e+00,  8.66947410e-01,  8.70016264e-01,\n",
              "          -6.77990222e-01,  2.87149682e-01,  6.72594732e-01,\n",
              "           6.35291863e-01,  7.23342394e-01,  8.45169023e-01,\n",
              "           1.92175768e-01,  7.86280503e-01, -1.62018553e-01,\n",
              "           1.10783520e+00,  1.25183180e+00,  1.06303203e+00,\n",
              "          -9.07052418e-01, -2.30370118e-01, -1.74384976e-01,\n",
              "           1.88541769e-01, -6.16209158e-01,  5.30705316e-01,\n",
              "          -2.10598629e+00,  1.49538570e+00, -9.97603867e-01,\n",
              "          -1.09283020e+00, -4.76829014e-01, -1.52566382e+00,\n",
              "          -1.73501642e-01,  4.49028255e-01, -1.18943193e-01,\n",
              "          -1.53077840e+00, -6.84332828e-01,  7.06794323e-01,\n",
              "          -1.68141196e+00, -6.65358464e-01, -4.55862284e-01,\n",
              "           1.11313449e+00,  4.32042016e-01, -9.89901499e-01,\n",
              "          -2.71249769e+00]]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  None],\n",
              " [array([[-2.00986028,  2.78455856,  1.16559505, ..., -0.85196899,\n",
              "          -0.48698736, -0.62807644],\n",
              "         [ 0.83203444,  0.09197177, -0.38530041, ..., -1.0939487 ,\n",
              "           0.01400316, -0.69017815],\n",
              "         [-0.02466401,  0.20964176,  0.0403148 , ..., -1.48206729,\n",
              "           0.25277543, -1.27583832],\n",
              "         ...,\n",
              "         [-0.07546266,  0.62713589,  1.06048574, ..., -0.39446862,\n",
              "          -0.82352951,  0.36766055],\n",
              "         [ 0.39986403, -0.14704049, -0.55863978, ..., -0.43743968,\n",
              "          -0.74232015,  0.05096646],\n",
              "         [ 0.21644985,  1.58667368,  1.61529624, ..., -0.46247025,\n",
              "          -1.22859855,  1.24347186]]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  __main__.Sigmoid]]"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================================\n",
            "-------------Output Shape---------param #------\n",
            "--------------(None, 100),-------1000----\n",
            "--------------(None, 10),-------1000----\n",
            "--------------(None, 10),-------100----\n",
            "==============================================\n",
            "Total Parmerter # ---- 2220\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Net(10)\n",
        "model.add(100, activation='relu')\n",
        "model.add(10, activation='relu')\n",
        "model.add(10, activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = model.predict(np.random.randn(7,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.random.randint(0, 10, 50)\n",
        "x = to_categorical(x)[:7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from time import time, sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 1/20 [00:01<00:19,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 2/20 [00:02<00:18,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 3/20 [00:03<00:17,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 4/20 [00:04<00:16,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 5/20 [00:05<00:15,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 6/20 [00:06<00:14,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 7/20 [00:07<00:13,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 8/20 [00:08<00:12,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 9/20 [00:09<00:11,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 10/20 [00:10<00:10,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 11/20 [00:11<00:09,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 12/20 [00:12<00:08,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 13/20 [00:13<00:07,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 14/20 [00:14<00:06,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 15/20 [00:15<00:05,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 16/20 [00:16<00:04,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 17/20 [00:17<00:03,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 18/20 [00:18<00:02,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 19/20 [00:19<00:01,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:20<00:00,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(20)):\n",
        "    sleep(1)\n",
        "    \n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Net(10)\n",
        "model.add(256, activation='relu')\n",
        "model.add(128, activation='relu')\n",
        "model.add(10, activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics='accuracy', lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 58.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 ====================> accuracy : 0.107 loss : 1.4277339134672187\n",
            "2 ====================> accuracy : 0.109 loss : 1.42518643814196\n",
            "3 ====================> accuracy : 0.115 loss : 1.420464669312911\n",
            "4 ====================> accuracy : 0.112 loss : 1.423689697057316\n",
            "5 ====================> accuracy : 0.111 loss : 1.424632739945217\n",
            "6 ====================> accuracy : 0.113 loss : 1.422521383205124\n",
            "7 ====================> accuracy : 0.113 loss : 1.4198110893464135\n",
            "8 ====================> accuracy : 0.113 loss : 1.4204242253450308\n",
            "9 ====================> accuracy : 0.11 loss : 1.4224579240919752\n",
            "10 ====================> accuracy : 0.111 loss : 1.4219838250428494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.fit(np.random.randn(1000, 10), to_categorical(np.random.randint(0, 10, 1000)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(-1, 784)/255\n",
        "X_test = X_test.reshape(-1, 784)/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Net(784)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model.add(256, activation='relu')\n",
        "model.add(128, activation='relu')\n",
        "model.add(10, activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics='accuracy', lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "softmax() got an unexpected keyword argument 'axis'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[41], line 106\u001b[0m, in \u001b[0;36mNet.fit\u001b[1;34m(self, x, y, epochs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,y,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m--> 106\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====================> accuracy : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x,y)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x,y)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers,\u001b[38;5;241m1\u001b[39m):\n",
            "Cell \u001b[1;32mIn[41], line 67\u001b[0m, in \u001b[0;36mNet.gradient\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,y):\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m {}\n",
            "Cell \u001b[1;32mIn[41], line 63\u001b[0m, in \u001b[0;36mNet.predict\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mitems())[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat \u001b[38;5;241m=\u001b[39m layer[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat)\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_val\n",
            "Cell \u001b[1;32mIn[40], line 61\u001b[0m, in \u001b[0;36mSoftmaxWithLoss.forward\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,y):\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat \u001b[38;5;241m=\u001b[39m \u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_val \u001b[38;5;241m=\u001b[39m categorical_crossentropy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_val\n",
            "\u001b[1;31mTypeError\u001b[0m: softmax() got an unexpected keyword argument 'axis'"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Net(784)\n",
        "model.add(256,activation='relu')\n",
        "model.add(128,activation='relu')\n",
        "model.add(10,activation='softmax')\n",
        "model.compile(lr=1e-2,loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "(X_train,y_train), (X_test,y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(-1,784)/255\n",
        "X_test = X_test.reshape(-1,784)/255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "softmax() got an unexpected keyword argument 'axis'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[41], line 106\u001b[0m, in \u001b[0;36mNet.fit\u001b[1;34m(self, x, y, epochs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,y,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m--> 106\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====================> accuracy : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x,y)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x,y)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers,\u001b[38;5;241m1\u001b[39m):\n",
            "Cell \u001b[1;32mIn[41], line 67\u001b[0m, in \u001b[0;36mNet.gradient\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,y):\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m {}\n",
            "Cell \u001b[1;32mIn[41], line 63\u001b[0m, in \u001b[0;36mNet.predict\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mitems())[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat \u001b[38;5;241m=\u001b[39m layer[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat)\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_val\n",
            "Cell \u001b[1;32mIn[40], line 61\u001b[0m, in \u001b[0;36mSoftmaxWithLoss.forward\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,y):\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat \u001b[38;5;241m=\u001b[39m \u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_val \u001b[38;5;241m=\u001b[39m categorical_crossentropy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_hat)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_val\n",
            "\u001b[1;31mTypeError\u001b[0m: softmax() got an unexpected keyword argument 'axis'"
          ]
        }
      ],
      "source": [
        "model.fit(X_train,y_train,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical, pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, save_model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((28, 28), 10)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "output_shape = y_train.shape[1]\n",
        "input_shape, output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        Flatten(input_shape=input_shape),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(output_shape, activation='softmax')\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = 'adam'\n",
        "loss = 'categorical_crossentropy'\n",
        "metrics = 'accuracy'\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 3s 2ms/step - loss: 0.4787 - accuracy: 0.8293 - val_loss: 0.4138 - val_accuracy: 0.8466\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3582 - accuracy: 0.8694 - val_loss: 0.3714 - val_accuracy: 0.8689\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3232 - accuracy: 0.8810 - val_loss: 0.3865 - val_accuracy: 0.8582\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2970 - accuracy: 0.8894 - val_loss: 0.3456 - val_accuracy: 0.8755\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2816 - accuracy: 0.8946 - val_loss: 0.3334 - val_accuracy: 0.8757\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2656 - accuracy: 0.8996 - val_loss: 0.3441 - val_accuracy: 0.8780\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2550 - accuracy: 0.9041 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2412 - accuracy: 0.9097 - val_loss: 0.3458 - val_accuracy: 0.8789\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2336 - accuracy: 0.9112 - val_loss: 0.3349 - val_accuracy: 0.8837\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2242 - accuracy: 0.9148 - val_loss: 0.3195 - val_accuracy: 0.8871\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1b783a6a050>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.special import expit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "(X_train, _), _ = mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 784)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "init1 = np.random.normal(loc=0, scale=1, size=(784, 256))\n",
        "\n",
        "layer1 = np.dot(X_train, init1)\n",
        "layer1 = expit(layer1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.00000000e+000, 0.00000000e+000, 1.00000000e+000, ...,\n",
              "        0.00000000e+000, 1.00000000e+000, 1.00000000e+000],\n",
              "       [6.06576244e-269, 1.00000000e+000, 1.00000000e+000, ...,\n",
              "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000],\n",
              "       [1.00000000e+000, 1.47257740e-052, 1.00000000e+000, ...,\n",
              "        0.00000000e+000, 1.00000000e+000, 1.00000000e+000],\n",
              "       ...,\n",
              "       [0.00000000e+000, 0.00000000e+000, 1.00000000e+000, ...,\n",
              "        0.00000000e+000, 1.00000000e+000, 0.00000000e+000],\n",
              "       [2.79119537e-264, 0.00000000e+000, 1.00000000e+000, ...,\n",
              "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000],\n",
              "       [1.00000000e+000, 5.57958465e-278, 5.40137600e-115, ...,\n",
              "        1.00000000e+000, 4.24194917e-262, 1.00000000e+000]])"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(layer1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "init1 = np.random.normal(loc=0, scale=.01, size=(784, 256))\n",
        "\n",
        "layer1 = np.dot(X_train, init1)\n",
        "layer1 = expit(layer1)\n",
        "plt.hist(layer1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAGdCAYAAAAbudkLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3HUlEQVR4nO3df1RU953/8ReCjEhhClIYqMTYRIkGknSxRbRbTVTQIxKbdHXLdo7usVhrImGV5miy3dCejaZRY1pNstaaaPxF9ltjm0ZDINVYqb8iDVtRo7Y1KyagVmFQ4g4UP98/urmbEUWHXwOX5+Oce45z73vufX9m+PHyw71zg4wxRgAAADbUJ9ANAAAAdBaCDgAAsC2CDgAAsC2CDgAAsC2CDgAAsC2CDgAAsC2CDgAAsC2CDgAAsK2QQDcQSFevXtXHH3+siIgIBQUFBbodAABwC4wxunTpkhISEtSnT+tzNr066Hz88cdKTEwMdBsAAKANqqqqNHDgwFZrenXQiYiIkPS3FyoyMjLA3QAAgFtRX1+vxMRE6/d4a3p10Pn0z1WRkZEEHQAAephbOe2Ek5EBAIBtEXQAAIBtEXQAAIBtEXQAAIBtEXQAAIBtEXQAAIBtEXQAAIBtEXQAAIBtEXQAAIBtEXQAAIBtEXQAAIBt+RV0XnrpJd1zzz3WvaHS09P11ltvWdtnzpypoKAgn2XkyJE++/B6vZo3b55iYmIUHh6u7OxsnTlzxqemtrZWbrdbTqdTTqdTbrdbdXV1PjWnT5/WlClTFB4erpiYGOXl5amxsdHP4QMAADvzK+gMHDhQzzzzjA4dOqRDhw7pgQce0IMPPqgjR45YNRMnTlR1dbW17Nixw2cf+fn52rZtm4qKilRWVqbLly8rKytLzc3NVk1OTo4qKipUXFys4uJiVVRUyO12W9ubm5s1efJkNTQ0qKysTEVFRdq6dasWLFjQ1tcBAADYkWmnqKgo8/Of/9wYY8yMGTPMgw8+eMPauro607dvX1NUVGSt++ijj0yfPn1McXGxMcaYo0ePGklm//79Vs2+ffuMJPPBBx8YY4zZsWOH6dOnj/noo4+smi1bthiHw2E8Hs8t9+7xeIwkv54DAAACy5/f320+R6e5uVlFRUVqaGhQenq6tf7dd99VbGyshg4dqtzcXJ07d87aVl5erqamJmVkZFjrEhISlJycrL1790qS9u3bJ6fTqbS0NKtm5MiRcjqdPjXJyclKSEiwajIzM+X1elVeXn7Dnr1er+rr630WAABgX34HncOHD+tzn/ucHA6H5syZo23btmn48OGSpEmTJmnTpk3auXOnli9frvfee08PPPCAvF6vJKmmpkahoaGKiory2WdcXJxqamqsmtjY2BbHjY2N9amJi4vz2R4VFaXQ0FCr5nqWLFlinffjdDqVmJjo7/ABAEAPEuLvE5KSklRRUaG6ujpt3bpVM2bM0O7duzV8+HBNnz7dqktOTtaIESM0aNAgbd++XQ899NAN92mMUVBQkPX4s/9uT821Fi1apPnz51uP6+vrCTsAANiY3zM6oaGhuvPOOzVixAgtWbJE9957r37yk59ctzY+Pl6DBg3SyZMnJUkul0uNjY2qra31qTt37pw1Q+NyuXT27NkW+zp//rxPzbUzN7W1tWpqamox0/NZDofDumLs0wUAANhXuz9Hxxhj/WnqWhcuXFBVVZXi4+MlSampqerbt69KS0utmurqalVWVmrUqFGSpPT0dHk8Hh08eNCqOXDggDwej09NZWWlqqurrZqSkhI5HA6lpqa2d0gAAMAmgowx5laLn3jiCU2aNEmJiYm6dOmSioqK9Mwzz6i4uFjp6ekqLCzUww8/rPj4eH344Yd64okndPr0aR07dkwRERGSpO9973t68803tW7dOkVHR6ugoEAXLlxQeXm5goODJf3tXJ+PP/5Yq1evliTNnj1bgwYN0q9//WtJfzsR+r777lNcXJyWLl2qixcvaubMmZo6dapWrlx5y4Ovr6+X0+mUx+NhdgcAgB7Cn9/ffp2jc/bsWbndblVXV8vpdOqee+5RcXGxJkyYoCtXrujw4cN69dVXVVdXp/j4eN1///167bXXrJAjSStWrFBISIimTZumK1euaNy4cVq3bp0VciRp06ZNysvLs67Oys7O1qpVq6ztwcHB2r59u+bOnavRo0crLCxMOTk5WrZsmT/DAQAANufXjI7dMKMDAEDP48/vb+51BQAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwA3kLI+JdAtAGgngg4AALAtgg4AALAtgg4AALAtgg4AALAtgg4AALAtgg4ABABXdAFdg6ADAABsi6ADAABsi6ADAK1w7aoIdAsA2oGgAwAAbIugAwAAbMuvoPPSSy/pnnvuUWRkpCIjI5Wenq633nrL2m6MUWFhoRISEhQWFqaxY8fqyJEjPvvwer2aN2+eYmJiFB4eruzsbJ05c8anpra2Vm63W06nU06nU263W3V1dT41p0+f1pQpUxQeHq6YmBjl5eWpsbHRz+EDAAA78yvoDBw4UM8884wOHTqkQ4cO6YEHHtCDDz5ohZlnn31Wzz33nFatWqX33ntPLpdLEyZM0KVLl6x95Ofna9u2bSoqKlJZWZkuX76srKwsNTc3WzU5OTmqqKhQcXGxiouLVVFRIbfbbW1vbm7W5MmT1dDQoLKyMhUVFWnr1q1asGBBe18PAABgJ6adoqKizM9//nNz9epV43K5zDPPPGNt+5//+R/jdDrNf/zHfxhjjKmrqzN9+/Y1RUVFVs1HH31k+vTpY4qLi40xxhw9etRIMvv377dq9u3bZySZDz74wBhjzI4dO0yfPn3MRx99ZNVs2bLFOBwO4/F4brl3j8djJPn1HAC9R/K6ZBO38/1O2zeAtvHn93ebz9Fpbm5WUVGRGhoalJ6erlOnTqmmpkYZGRlWjcPh0JgxY7R3715JUnl5uZqamnxqEhISlJycbNXs27dPTqdTaWlpVs3IkSPldDp9apKTk5WQkGDVZGZmyuv1qry8/IY9e71e1dfX+ywAAMC+/A46hw8f1uc+9zk5HA7NmTNH27Zt0/Dhw1VTUyNJiouL86mPi4uzttXU1Cg0NFRRUVGt1sTGxrY4bmxsrE/NtceJiopSaGioVXM9S5Yssc77cTqdSkxM9HP0ANA6PvEY6F78DjpJSUmqqKjQ/v379b3vfU8zZszQ0aNHre1BQUE+9caYFuuudW3N9erbUnOtRYsWyePxWEtVVVWrfQEAgJ7N76ATGhqqO++8UyNGjNCSJUt077336ic/+YlcLpcktZhROXfunDX74nK51NjYqNra2lZrzp492+K458+f96m59ji1tbVqampqMdPzWQ6Hw7pi7NMFAADYV7s/R8cYI6/Xq8GDB8vlcqm0tNTa1tjYqN27d2vUqFGSpNTUVPXt29enprq6WpWVlVZNenq6PB6PDh48aNUcOHBAHo/Hp6ayslLV1dVWTUlJiRwOh1JTU9s7JAAAYBMh/hQ/8cQTmjRpkhITE3Xp0iUVFRXp3XffVXFxsYKCgpSfn6/FixdryJAhGjJkiBYvXqz+/fsrJydHkuR0OjVr1iwtWLBAAwYMUHR0tAoKCpSSkqLx48dLkoYNG6aJEycqNzdXq1evliTNnj1bWVlZSkpKkiRlZGRo+PDhcrvdWrp0qS5evKiCggLl5uYySwMAACx+BZ2zZ8/K7XarurpaTqdT99xzj4qLizVhwgRJ0uOPP64rV65o7ty5qq2tVVpamkpKShQREWHtY8WKFQoJCdG0adN05coVjRs3TuvWrVNwcLBVs2nTJuXl5VlXZ2VnZ2vVqlXW9uDgYG3fvl1z587V6NGjFRYWppycHC1btqxdLwYAALCXIGOMCXQTgVJfXy+n0ymPx8NMEIAWUtan6PxtG1Rz/31+PefwjMMdVgegJX9+f3OvKwAAYFsEHQAAYFsEHQAAYFsEHQAAYFsEHQDoYK5dFYFuAcD/IugAAADbIugA6BDH7hoW6BYAoAWCDgAAsC2CDgAAsC2CDgAAsC2CDgAAsC2CDgAAsC2CDgAAsC2CDgBc4zc77wh0CwA6CEEHAADYFkEHQK93+8LtgW4BQCch6AAAANsi6ADAdSyfnhXoFgB0AIIOAPjhzMI9gW4BgB8IOgDQA3TlDBM3aIWdEHQAdCtc2g2gIxF0AACAbRF0AACAbRF0AACAbRF0AHSowsLCQLfQLXB1FtA9EHQAoIv1hM/o4dOiYRcEHQDoJbhsHL0RQQcAANgWQQcAANgWQQcAANgWQQcAANgWQQcAANgWQQcAANgWQQcAukqhM9AdAL0OQQdAj+faVRHoFgB0UwQdAPgsZl0AWyHoAEAHacutHXrC7SCAnoygAwAAbIugAwAAbMuvoLNkyRJ95StfUUREhGJjYzV16lQdP37cp2bmzJkKCgryWUaOHOlT4/V6NW/ePMXExCg8PFzZ2dk6c+aMT01tba3cbrecTqecTqfcbrfq6up8ak6fPq0pU6YoPDxcMTExysvLU2Njoz9DAtALpaxPCXQLALqIX0Fn9+7deuSRR7R//36Vlpbqr3/9qzIyMtTQ0OBTN3HiRFVXV1vLjh07fLbn5+dr27ZtKioqUllZmS5fvqysrCw1NzdbNTk5OaqoqFBxcbGKi4tVUVEht9ttbW9ubtbkyZPV0NCgsrIyFRUVaevWrVqwYEFbXgcAAGBDIf4UFxcX+zx+5ZVXFBsbq/Lycn3961+31jscDrlcruvuw+PxaO3atdqwYYPGjx8vSdq4caMSExP1zjvvKDMzU8eOHVNxcbH279+vtLQ0SdKaNWuUnp6u48ePKykpSSUlJTp69KiqqqqUkJAgSVq+fLlmzpypp59+WpGRkf4MDQAA2FC7ztHxeDySpOjoaJ/17777rmJjYzV06FDl5ubq3Llz1rby8nI1NTUpIyPDWpeQkKDk5GTt3btXkrRv3z45nU4r5EjSyJEj5XQ6fWqSk5OtkCNJmZmZ8nq9Ki8vv26/Xq9X9fX1PgsAALCvNgcdY4zmz5+vr33ta0pOTrbWT5o0SZs2bdLOnTu1fPlyvffee3rggQfk9XolSTU1NQoNDVVUVJTP/uLi4lRTU2PVxMbGtjhmbGysT01cXJzP9qioKIWGhlo111qyZIl1zo/T6VRiYmJbhw8AAHqANgedRx99VH/4wx+0ZcsWn/XTp0/X5MmTlZycrClTpuitt97SiRMntH379lb3Z4xRUFCQ9fiz/25PzWctWrRIHo/HWqqqqlrtCUDr2npSL59kDKCrtCnozJs3T2+88YZ27dqlgQMHtlobHx+vQYMG6eTJk5Ikl8ulxsZG1dbW+tSdO3fOmqFxuVw6e/Zsi32dP3/ep+bamZva2lo1NTW1mOn5lMPhUGRkpM8CoPc6s3BPoFsA0Mn8CjrGGD366KN6/fXXtXPnTg0ePPimz7lw4YKqqqoUHx8vSUpNTVXfvn1VWlpq1VRXV6uyslKjRo2SJKWnp8vj8ejgwYNWzYEDB+TxeHxqKisrVV1dbdWUlJTI4XAoNTXVn2EB6AZemLMz0C0AsCG/rrp65JFHtHnzZv3qV79SRESENaPidDoVFhamy5cvq7CwUA8//LDi4+P14Ycf6oknnlBMTIy+8Y1vWLWzZs3SggULNGDAAEVHR6ugoEApKSnWVVjDhg3TxIkTlZubq9WrV0uSZs+eraysLCUlJUmSMjIyNHz4cLndbi1dulQXL15UQUGBcnNzmakBAACS/JzReemll+TxeDR27FjFx8dby2uvvSZJCg4O1uHDh/Xggw9q6NChmjFjhoYOHap9+/YpIiLC2s+KFSs0depUTZs2TaNHj1b//v3161//WsHBwVbNpk2blJKSooyMDGVkZOiee+7Rhg0brO3BwcHavn27+vXrp9GjR2vatGmaOnWqli1b1t7XBAB6hNsXtn7uIwA/Z3SMMa1uDwsL09tvv33T/fTr108rV67UypUrb1gTHR2tjRs3trqf2267TW+++eZNjwcAt+KFOTv1yPU/AgxAD8W9rgAAgG0RdADgFnB/LKBnIugAAADbIugAAADbIugAAADbIugAAADbIugA6LGWT88KdAsAujmCDgDghrg1B3o6gg4AALAtgg4AALAtgg4AALAtgg4AALAtgg4AALAtgg4AtMHtC7fftObYXcMkSYWFhZ3cTScrdAa6A6DNCDoAAMC2CDoAeiXXropAtwCgCxB0gB7ozMI9gW4BAHoEgg4AALAtgg4AALAtgg4AALAtgg4AALAtgg4AALAtgg6Abmf59KweuW8A3Q9BBwAA2BZBBwAA2BZBBwAA2BZBBwDaqMffrBPoBQg6ANqlt98z6oU5OwPdAoBWEHQAAIBtEXQABNTtC7cHugVb+s3OOwLdAtAtEHQAAIBtEXQAoAtwLg8QGAQdAABgWwQdAABgWwQdAABgWwQdAABgWwQdAABgWwQdAGivQmegOwBwAwQdAF3mzMI9gW4BQC/jV9BZsmSJvvKVrygiIkKxsbGaOnWqjh8/7lNjjFFhYaESEhIUFhamsWPH6siRIz41Xq9X8+bNU0xMjMLDw5Wdna0zZ8741NTW1srtdsvpdMrpdMrtdquurs6n5vTp05oyZYrCw8MVExOjvLw8NTY2+jMkAN1AIG+OeeyuYQE7NoDO51fQ2b17tx555BHt379fpaWl+utf/6qMjAw1NDRYNc8++6yee+45rVq1Su+9955cLpcmTJigS5cuWTX5+fnatm2bioqKVFZWpsuXLysrK0vNzc1WTU5OjioqKlRcXKzi4mJVVFTI7XZb25ubmzV58mQ1NDSorKxMRUVF2rp1qxYsWNCe1wNAL8WdyAF7CvGnuLi42OfxK6+8otjYWJWXl+vrX/+6jDF6/vnn9eSTT+qhhx6SJK1fv15xcXHavHmzvvvd78rj8Wjt2rXasGGDxo8fL0nauHGjEhMT9c477ygzM1PHjh1TcXGx9u/fr7S0NEnSmjVrlJ6eruPHjyspKUklJSU6evSoqqqqlJCQIElavny5Zs6cqaefflqRkZHtfnEAdF9/u5cTszGWQqdU6Al0F0C3065zdDyev31TRUdHS5JOnTqlmpoaZWRkWDUOh0NjxozR3r17JUnl5eVqamryqUlISFBycrJVs2/fPjmdTivkSNLIkSPldDp9apKTk62QI0mZmZnyer0qLy+/br9er1f19fU+CwAAsK82Bx1jjObPn6+vfe1rSk5OliTV1NRIkuLi4nxq4+LirG01NTUKDQ1VVFRUqzWxsbEtjhkbG+tTc+1xoqKiFBoaatVca8mSJdY5P06nU4mJif4OG0Bn4uolAB2szUHn0Ucf1R/+8Adt2bKlxbagoCCfx8aYFuuudW3N9erbUvNZixYtksfjsZaqqqpWewIAAD1bm4LOvHnz9MYbb2jXrl0aOHCgtd7lcklSixmVc+fOWbMvLpdLjY2Nqq2tbbXm7NmzLY57/vx5n5prj1NbW6umpqYWMz2fcjgcioyM9FkAtB+XjQPorvwKOsYYPfroo3r99de1c+dODR482Gf74MGD5XK5VFpaaq1rbGzU7t27NWrUKElSamqq+vbt61NTXV2tyspKqyY9PV0ej0cHDx60ag4cOCCPx+NTU1lZqerqaqumpKREDodDqamp/gwLAADYlF9XXT3yyCPavHmzfvWrXykiIsKaUXE6nQoLC1NQUJDy8/O1ePFiDRkyREOGDNHixYvVv39/5eTkWLWzZs3SggULNGDAAEVHR6ugoEApKSnWVVjDhg3TxIkTlZubq9WrV0uSZs+eraysLCUlJUmSMjIyNHz4cLndbi1dulQXL15UQUGBcnNzmakBAACS/Aw6L730kiRp7NixPutfeeUVzZw5U5L0+OOP68qVK5o7d65qa2uVlpamkpISRUREWPUrVqxQSEiIpk2bpitXrmjcuHFat26dgoODrZpNmzYpLy/PujorOztbq1atsrYHBwdr+/btmjt3rkaPHq2wsDDl5ORo2bJlfr0AAADAvvwKOsaYm9YEBQWpsLCw1Q/f6tevn1auXKmVK1fesCY6OlobN25s9Vi33Xab3nzzzZv2BAAAeifudQUgIDrqBOaU9Skdsh8A9kTQAQAAtkXQAYBb5NpVEegWAPiJoAMAAGyLoAMAAGyLoAMAAGyLoAMAAGyLoAMAAGyLoAOgW+OGoQDag6ADADexfHpWoFsA0EYEHQAAYFsEHQAAYFsEHQAAYFsEHQCd5jc77wh0CwB6OYIOAACwLYIOAACwLYIOAACwLYIOAACwLYIOAACwLYIOgC7h2lUR6BYC4vaF2wPdAtCrEXSAXo5LwAHYGUEHAADYFkEHAADYFkEHAADYFkEHAADYFkEHAADYFkEHsCmupgIAgg4AALAxgg4AALAtgg6ATpeyPiXQLQDopQg6AADAtgg6ANDDvTBnZ6BbALotgg4A4LoKCwsD3QLQbgQdAABgWwQdAABgWwQdAABgWwQdAABgWwQdAABgWwQdAABgW34Hnd/+9reaMmWKEhISFBQUpF/+8pc+22fOnKmgoCCfZeTIkT41Xq9X8+bNU0xMjMLDw5Wdna0zZ8741NTW1srtdsvpdMrpdMrtdquurs6n5vTp05oyZYrCw8MVExOjvLw8NTY2+jskAABgU34HnYaGBt17771atWrVDWsmTpyo6upqa9mxY4fP9vz8fG3btk1FRUUqKyvT5cuXlZWVpebmZqsmJydHFRUVKi4uVnFxsSoqKuR2u63tzc3Nmjx5shoaGlRWVqaioiJt3bpVCxYs8HdIAABJrl0VgW4B6HAh/j5h0qRJmjRpUqs1DodDLpfruts8Ho/Wrl2rDRs2aPz48ZKkjRs3KjExUe+8844yMzN17NgxFRcXa//+/UpLS5MkrVmzRunp6Tp+/LiSkpJUUlKio0ePqqqqSgkJCZKk5cuXa+bMmXr66acVGRnp79AA4JYcu2uYNHVZoNsAcAs65Rydd999V7GxsRo6dKhyc3N17tw5a1t5ebmampqUkZFhrUtISFBycrL27t0rSdq3b5+cTqcVciRp5MiRcjqdPjXJyclWyJGkzMxMeb1elZeXd8awAABAD+P3jM7NTJo0Sf/wD/+gQYMG6dSpU/rBD36gBx54QOXl5XI4HKqpqVFoaKiioqJ8nhcXF6eamhpJUk1NjWJjY1vsOzY21qcmLi7OZ3tUVJRCQ0Otmmt5vV55vV7rcX19fbvGCgAAurcOn9GZPn26Jk+erOTkZE2ZMkVvvfWWTpw4oe3bt7f6PGOMgoKCrMef/Xd7aj5ryZIl1snNTqdTiYmJtzosAMBnLJ+eFegWgFvS6ZeXx8fHa9CgQTp58qQkyeVyqbGxUbW1tT51586ds2ZoXC6Xzp4922Jf58+f96m5duamtrZWTU1NLWZ6PrVo0SJ5PB5rqaqqavf4AABA99XpQefChQuqqqpSfHy8JCk1NVV9+/ZVaWmpVVNdXa3KykqNGjVKkpSeni6Px6ODBw9aNQcOHJDH4/GpqaysVHV1tVVTUlIih8Oh1NTU6/bicDgUGRnpswAAAPvy+xydy5cv649//KP1+NSpU6qoqFB0dLSio6NVWFiohx9+WPHx8frwww/1xBNPKCYmRt/4xjckSU6nU7NmzdKCBQs0YMAARUdHq6CgQCkpKdZVWMOGDdPEiROVm5ur1atXS5Jmz56trKwsJSUlSZIyMjI0fPhwud1uLV26VBcvXlRBQYFyc3MJMAAAQFIbgs6hQ4d0//33W4/nz58vSZoxY4ZeeuklHT58WK+++qrq6uoUHx+v+++/X6+99poiIiKs56xYsUIhISGaNm2arly5onHjxmndunUKDg62ajZt2qS8vDzr6qzs7Gyfz+4JDg7W9u3bNXfuXI0ePVphYWHKycnRsmVc8gkAAP7G76AzduxYGWNuuP3tt9++6T769eunlStXauXKlTesiY6O1saNG1vdz2233aY333zzpscDAAC9E/e6AgAAtkXQAQAAtkXQAQAoZX1KoFsAOgVBBwAA2BZBBwAA2BZBB4DFtasi0C0ALRy7a1igW0APRtABAAC2RdAB0Km4+WPX4vUGfBF0AACAbRF0AACAbRF0AKAL/WbnHYFuAehVCDoAAMC2CDoAAMC2CDoAuqXr3ZKgsLCw6xtBj8bXDAg6AADAtgg6ADrcC3N2BroFAJBE0AEAADZG0AEAALZF0AEAALZF0AEAG7ve1WtAb0LQAQAAtkXQAQAAtkXQAQAAtkXQAYAO0JabdXKDT6DzEXQAdFuuXRWBbgFAD0fQAQAAtkXQAQAAtkXQAQAAtkXQAQAAtkXQAQAAtkXQAQAAtkXQAQAAtkXQAQAAtkXQAQDYxu0Ltwe6BXQzBB0AAGBbBB0AAGBbBB0AAGBbBB0AAGBbBB0AAGBbBB0AAGBbfged3/72t5oyZYoSEhIUFBSkX/7ylz7bjTEqLCxUQkKCwsLCNHbsWB05csSnxuv1at68eYqJiVF4eLiys7N15swZn5ra2lq53W45nU45nU653W7V1dX51Jw+fVpTpkxReHi4YmJilJeXp8bGRn+HBAAAbMrvoNPQ0KB7771Xq1atuu72Z599Vs8995xWrVql9957Ty6XSxMmTNClS5esmvz8fG3btk1FRUUqKyvT5cuXlZWVpebmZqsmJydHFRUVKi4uVnFxsSoqKuR2u63tzc3Nmjx5shoaGlRWVqaioiJt3bpVCxYs8HdIALrQsbuGBboFAL1IiL9PmDRpkiZNmnTdbcYYPf/883ryySf10EMPSZLWr1+vuLg4bd68Wd/97nfl8Xi0du1abdiwQePHj5ckbdy4UYmJiXrnnXeUmZmpY8eOqbi4WPv371daWpokac2aNUpPT9fx48eVlJSkkpISHT16VFVVVUpISJAkLV++XDNnztTTTz+tyMjINr0gANBrFDqlQk+guwA6VYeeo3Pq1CnV1NQoIyPDWudwODRmzBjt3btXklReXq6mpiafmoSEBCUnJ1s1+/btk9PptEKOJI0cOVJOp9OnJjk52Qo5kpSZmSmv16vy8vLr9uf1elVfX++zAAD+z5mFewLdAtChOjTo1NTUSJLi4uJ81sfFxVnbampqFBoaqqioqFZrYmNjW+w/NjbWp+ba40RFRSk0NNSqudaSJUusc36cTqcSExPbMEoAANBTdMpVV0FBQT6PjTEt1l3r2prr1bel5rMWLVokj8djLVVVVa32BAAAerYODToul0uSWsyonDt3zpp9cblcamxsVG1tbas1Z8+ebbH/8+fP+9Rce5za2lo1NTW1mOn5lMPhUGRkpM8C2ElhYWGgWwCAbqVDg87gwYPlcrlUWlpqrWtsbNTu3bs1atQoSVJqaqr69u3rU1NdXa3KykqrJj09XR6PRwcPHrRqDhw4II/H41NTWVmp6upqq6akpEQOh0OpqakdOSwAANBD+X3V1eXLl/XHP/7Renzq1ClVVFQoOjpat912m/Lz87V48WINGTJEQ4YM0eLFi9W/f3/l5ORIkpxOp2bNmqUFCxZowIABio6OVkFBgVJSUqyrsIYNG6aJEycqNzdXq1evliTNnj1bWVlZSkpKkiRlZGRo+PDhcrvdWrp0qS5evKiCggLl5uYyUwMAACS1IegcOnRI999/v/V4/vz5kqQZM2Zo3bp1evzxx3XlyhXNnTtXtbW1SktLU0lJiSIiIqznrFixQiEhIZo2bZquXLmicePGad26dQoODrZqNm3apLy8POvqrOzsbJ/P7gkODtb27ds1d+5cjR49WmFhYcrJydGyZcv8fxUAAIAt+R10xo4dK2PMDbcHBQWpsLCw1XMF+vXrp5UrV2rlypU3rImOjtbGjRtb7eW2227Tm2++edOeAQBA78S9rgDAZlLWpwS6BaDbIOigV+PD0WAnv9l5R6BbALodgg4AALAtgg4AALAtgg4AALAtgg7QTfEpxwDQfgQdAABgWwQdAABgWwQdAOhh+FgE4NYRdAAAgG0RdIBuwrWrItAtwMaYBUJvRdABAAC2RdABAAC2RdABAAC2RdAB0DkKnYHuAAAIOgAAwL4IOgAAwLYIOgAAwLYIOoDNvDBnZ6BbAIBug6ADAABsi6ADdDPH7hoW6BZgY7cv3N6+HXA1HXoYgg4AoNMsn54V6BbQyxF0AAC2w7lq+BRBBwB6OWZdYGcEHcCOOI8CACQRdAAANsGJ/Lgegg5gE+2+mgYAbIigA6BH4SRTAP4g6AAAANsi6AAAANsi6AAAANsi6AAAANsi6ABAD5GyPiXQLQA9DkEHQM/Tiz8Q0bWrItAtAD0KQQcAepnCwsJAtwB0GYIO0I2cWbgn0C0AgK0QdAAAgG0RdAAAgG0RdIAO8pudd3T5Mbm/FXq8XnxiObpGhwedwsJCBQUF+Swul8vaboxRYWGhEhISFBYWprFjx+rIkSM++/B6vZo3b55iYmIUHh6u7OxsnTlzxqemtrZWbrdbTqdTTqdTbrdbdXV1HT0cAADQg3XKjM7dd9+t6upqazl8+LC17dlnn9Vzzz2nVatW6b333pPL5dKECRN06dIlqyY/P1/btm1TUVGRysrKdPnyZWVlZam5udmqycnJUUVFhYqLi1VcXKyKigq53e7OGA4AAOihQjplpyEhPrM4nzLG6Pnnn9eTTz6phx56SJK0fv16xcXFafPmzfrud78rj8ejtWvXasOGDRo/frwkaePGjUpMTNQ777yjzMxMHTt2TMXFxdq/f7/S0tIkSWvWrFF6erqOHz+upKSkzhgWAADoYTplRufkyZNKSEjQ4MGD9Y//+I/685//LEk6deqUampqlJGRYdU6HA6NGTNGe/fulSSVl5erqanJpyYhIUHJyclWzb59++R0Oq2QI0kjR46U0+m0aq7H6/Wqvr7eZwF6Iz5HBS/M2en3c5ZPz+qEToDO1eFBJy0tTa+++qrefvttrVmzRjU1NRo1apQuXLigmpoaSVJcXJzPc+Li4qxtNTU1Cg0NVVRUVKs1sbGxLY4dGxtr1VzPkiVLrHN6nE6nEhMT2zVWAADQvXV40Jk0aZIefvhhpaSkaPz48dq+/W9Xhaxfv96qCQoK8nmOMabFumtdW3O9+pvtZ9GiRfJ4PNZSVVV1S2MCAAA9U6dfXh4eHq6UlBSdPHnSOm/n2lmXc+fOWbM8LpdLjY2Nqq2tbbXm7NmzLY51/vz5FrNFn+VwOBQZGemzAAAA++r0oOP1enXs2DHFx8dr8ODBcrlcKi0ttbY3NjZq9+7dGjVqlCQpNTVVffv29amprq5WZWWlVZOeni6Px6ODBw9aNQcOHJDH47FqAADdE5//hK7U4VddFRQUaMqUKbrtttt07tw5/fu//7vq6+s1Y8YMBQUFKT8/X4sXL9aQIUM0ZMgQLV68WP3791dOTo4kyel0atasWVqwYIEGDBig6OhoFRQUWH8Kk6Rhw4Zp4sSJys3N1erVqyVJs2fPVlZWFldcAQD+ptAp6V8C3QUCrMODzpkzZ/Stb31Lf/nLX/SFL3xBI0eO1P79+zVo0CBJ0uOPP64rV65o7ty5qq2tVVpamkpKShQREWHtY8WKFQoJCdG0adN05coVjRs3TuvWrVNwcLBVs2nTJuXl5VlXZ2VnZ2vVqlUdPRwAANCDdXjQKSoqanV7UFCQCgsLW728tV+/flq5cqVWrlx5w5ro6Ght3LixrW0CvcLy6Vla8NqbgW4DAebaVaFDgW4CCBDudQUA6DX4LKDeh6ADAABsi6ADgP/lArAtgg7QA/xm5x2BbgHocG25DQXgL4IOAACwLYIO0AlcuyoC3QIAQAQdAABgYwQdAABgWwQdAABgWwQdoBtIWZ8S6BbQQ7X2KfP4G67u6t0IOgAAwLYIOgAAwLYIOgB6hNsXbg90C93KsbuGBboFoEcg6ACQxHlCAOyJoAPcRHe5/UJ3ux/V9fph1sW+usv3AeAvgg4A2FR3C8dAIBB0gF7izMI9gW4B6BTccgWtIegAPQw/1AHg1hF0AADdBucCoaMRdAB0e1xKDaCtCDoAAMC2CDoAAHQCZiK7B4IO0I1xM0LAf9zoFJ9F0AEA9Fh8ojduhqAD9CD8UAcA/xB0AACAbRF0gOvgb/xdg5M1AXQ2gg4AoNvx98+03OIEN0LQAQAgwG5fuD3QLdgWQQcQP2QAfwT8Ng2FzsAeHz0KQQcAANgWQQcAgG6GCyI6DkEHAADYFkEHHYIrHro3166KQLcAAAFB0IHt8EsdAPApgg7QGq7uALoFroxEWxF0gBuwy53Db/TBa3YZH9on4JeKA52MoANco6f8z5HbJ6Cn4Vw+BAJBBwAQUK3NKrUWjpZPz7r1g/Bn6F6rxwedF198UYMHD1a/fv2UmpqqPXv4H0NP11FT6V0x48FnXQCdp7teWMCffXuWHh10XnvtNeXn5+vJJ5/U+++/r7//+7/XpEmTdPr06UC3hg7S1h90n/1fYI8PI/xPFDbQEaGlsLCwy0KGX7NF6NZ6dNB57rnnNGvWLH3nO9/RsGHD9PzzzysxMVEvvfRSoFtDN9XW2SJ+6AFt5++dyHubW5l95mdQ24UEuoG2amxsVHl5uRYuXOizPiMjQ3v37r3uc7xer7xer/XY4/FIkurr6zuv0V7ikrfhpq/ju7vv1dgx/3XTfTU0XLX2dbXhst/vz9WGy7rkbdDl5mbV19fL6/Va+2houKqnH8rUvHX/T3f+9g/a/b99X/V+8n/H9H4ib5BXVxobVO81ami4qv9parK2f/TUXn3xh6MkqcW+29p385Xm6/Z9bQ/X1t1K3599Tn19vZKfelv/1O9/6xZFqmHUAJ+6W+37Rv3crIfLzW18zk3qOrPvdo21lbprv7Y6su+2vo43q7ve94Q/fX/2++2z+66vr5eWDFTDqAF6+qFMNWe03o/q62+pb69aPudW+762Lvmpt1X5w8y/7e8W9vHp93JrPnpqb4vvZcn3Z8uN+unNPn0tjDE3LzY91EcffWQkmd/97nc+659++mkzdOjQ6z7nqaeeMpJYWFhYWFhYbLBUVVXdNC/02BmdTwUFBfk8Nsa0WPepRYsWaf78+dbjq1ev6uLFixowYMANn9MZ6uvrlZiYqKqqKkVGRnbZcbuK3ccnMUa7YIw9n93HJzHG6zHG6NKlS0pISLhpbY8NOjExMQoODlZNTY3P+nPnzikuLu66z3E4HHI4HD7rPv/5z3dWizcVGRlp2y9ayf7jkxijXTDGns/u45MY47WcTuct1fXYk5FDQ0OVmpqq0tJSn/WlpaUaNWpUgLoCAADdSY+d0ZGk+fPny+12a8SIEUpPT9fPfvYznT59WnPmzAl0awAAoBvo0UFn+vTpunDhgn70ox+purpaycnJ2rFjhwYNGhTo1lrlcDj01FNPtfgzml3YfXwSY7QLxtjz2X18EmNsryBjbuXaLAAAgJ6nx56jAwAAcDMEHQAAYFsEHQAAYFsEHQAAYFsEnU7w4osvavDgwerXr59SU1O1Z8+eG9ZWV1crJydHSUlJ6tOnj/Lz87uu0XbwZ4yvv/66JkyYoC984QuKjIxUenq63n777S7stm38GWNZWZlGjx6tAQMGKCwsTHfddZdWrFjRhd22jT9j/Kzf/e53CgkJ0X333de5DXYAf8b47rvvKigoqMXywQcfdGHH/vH3PfR6vXryySc1aNAgORwO3XHHHXr55Ze7qNu28WeMM2fOvO57ePfdd3dhx/7z933ctGmT7r33XvXv31/x8fH653/+Z124cKGLum0bf8f4wgsvaNiwYQoLC1NSUpJeffXVth243Tedgo+ioiLTt29fs2bNGnP06FHz2GOPmfDwcPPf//3f160/deqUycvLM+vXrzf33Xefeeyxx7q24Tbwd4yPPfaY+fGPf2wOHjxoTpw4YRYtWmT69u1rfv/733dx57fO3zH+/ve/N5s3bzaVlZXm1KlTZsOGDaZ///5m9erVXdz5rfN3jJ+qq6szX/rSl0xGRoa59957u6bZNvJ3jLt27TKSzPHjx011dbW1/PWvf+3izm9NW97D7Oxsk5aWZkpLS82pU6fMgQMHWtwzsDvxd4x1dXU+711VVZWJjo42Tz31VNc27gd/x7hnzx7Tp08f85Of/MT8+c9/Nnv27DF33323mTp1ahd3fuv8HeOLL75oIiIiTFFRkfnTn/5ktmzZYj73uc+ZN954w+9jE3Q62Fe/+lUzZ84cn3V33XWXWbhw4U2fO2bMmB4RdNozxk8NHz7c/PCHP+zo1jpMR4zxG9/4hvn2t7/d0a11mLaOcfr06eZf//VfzVNPPdXtg46/Y/w06NTW1nZBd+3n7/jeeust43Q6zYULF7qivQ7R3u/Fbdu2maCgIPPhhx92Rnsdwt8xLl261HzpS1/yWffTn/7UDBw4sNN6bC9/x5ienm4KCgp81j322GNm9OjRfh+bP111oMbGRpWXlysjI8NnfUZGhvbu3RugrjpWR4zx6tWrunTpkqKjozujxXbriDG+//772rt3r8aMGdMZLbZbW8f4yiuv6E9/+pOeeuqpzm6x3drzPn75y19WfHy8xo0bp127dnVmm23WlvG98cYbGjFihJ599ll98Ytf1NChQ1VQUKArV650Rct+64jvxbVr12r8+PHd9oNk2zLGUaNG6cyZM9qxY4eMMTp79qx+8YtfaPLkyV3Rst/aMkav16t+/fr5rAsLC9PBgwfV1NTk1/EJOh3oL3/5i5qbm1vcVDQuLq7FzUd7qo4Y4/Lly9XQ0KBp06Z1Rovt1p4xDhw4UA6HQyNGjNAjjzyi73znO53Zapu1ZYwnT57UwoULtWnTJoWEdP8PVW/LGOPj4/Wzn/1MW7du1euvv66kpCSNGzdOv/3tb7uiZb+0ZXx//vOfVVZWpsrKSm3btk3PP/+8fvGLX+iRRx7pipb91t6fN9XV1Xrrrbe67feh1LYxjho1Sps2bdL06dMVGhoql8ulz3/+81q5cmVXtOy3towxMzNTP//5z1VeXi5jjA4dOqSXX35ZTU1N+stf/uLX8bv/T6seKCgoyOexMabFup6urWPcsmWLCgsL9atf/UqxsbGd1V6HaMsY9+zZo8uXL2v//v1auHCh7rzzTn3rW9/qzDbb5VbH2NzcrJycHP3whz/U0KFDu6q9DuHP+5iUlKSkpCTrcXp6uqqqqrRs2TJ9/etf79Q+28qf8V29elVBQUHatGmTdefn5557Tt/85jf1wgsvKCwsrNP7bYu2/rxZt26dPv/5z2vq1Kmd1FnH8WeMR48eVV5env7t3/5NmZmZqq6u1ve//33NmTNHa9eu7Yp228SfMf7gBz9QTU2NRo4cKWOM4uLiNHPmTD377LMKDg7267jM6HSgmJgYBQcHt0io586da5Fke6r2jPG1117TrFmz9J//+Z8aP358Z7bZLu0Z4+DBg5WSkqLc3Fz9y7/8iwoLCzux07bzd4yXLl3SoUOH9OijjyokJEQhISH60Y9+pP/6r/9SSEiIdu7c2VWt37KO+n4cOXKkTp482dHttVtbxhcfH68vfvGLVsiRpGHDhskYozNnznRqv23RnvfQGKOXX35ZbrdboaGhndlmu7RljEuWLNHo0aP1/e9/X/fcc48yMzP14osv6uWXX1Z1dXVXtO2XtowxLCxML7/8sj755BN9+OGHOn36tG6//XZFREQoJibGr+MTdDpQaGioUlNTVVpa6rO+tLRUo0aNClBXHautY9yyZYtmzpypzZs3d9u/I3+qo95HY4y8Xm9Ht9ch/B1jZGSkDh8+rIqKCmuZM2eOkpKSVFFRobS0tK5q/ZZ11Pv4/vvvKz4+vqPba7e2jG/06NH6+OOPdfnyZWvdiRMn1KdPHw0cOLBT+22L9ryHu3fv1h//+EfNmjWrM1tst7aM8ZNPPlGfPr6/vj+d5TDd8PaV7Xkf+/btq4EDByo4OFhFRUXKyspqMfab8vv0ZbTq00vo1q5da44ePWry8/NNeHi4dcb/woULjdvt9nnO+++/b95//32TmppqcnJyzPvvv2+OHDkSiPZvib9j3Lx5swkJCTEvvPCCz2WfdXV1gRrCTfk7xlWrVpk33njDnDhxwpw4ccK8/PLLJjIy0jz55JOBGsJNteVr9bN6wlVX/o5xxYoVZtu2bebEiROmsrLSLFy40EgyW7duDdQQWuXv+C5dumQGDhxovvnNb5ojR46Y3bt3myFDhpjvfOc7gRrCTbX16/Tb3/62SUtL6+p228TfMb7yyismJCTEvPjii+ZPf/qTKSsrMyNGjDBf/epXAzWEm/J3jMePHzcbNmwwJ06cMAcOHDDTp0830dHR5tSpU34fm6DTCV544QUzaNAgExoaav7u7/7O7N6929o2Y8YMM2bMGJ96SS2WQYMGdW3TfvJnjGPGjLnuGGfMmNH1jfvBnzH+9Kc/NXfffbfp37+/iYyMNF/+8pfNiy++aJqbmwPQ+a3z92v1s3pC0DHGvzH++Mc/NnfccYfp16+fiYqKMl/72tfM9u3bA9D1rfP3PTx27JgZP368CQsLMwMHDjTz5883n3zySRd37R9/x1hXV2fCwsLMz372sy7utO38HeNPf/pTM3z4cBMWFmbi4+PNP/3TP5kzZ850cdf+8WeMR48eNffdd58JCwszkZGR5sEHHzQffPBBm44bZEw3nOcCAADoAJyjAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbIugAwAAbOv/A8Odk0MjpJmEAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "init = 1/np.sqrt(np.prod(X_train.shape))\n",
        "init1 = np.random.normal(loc=0, scale=init, size=(784, 256))\n",
        "layer1 = np.dot(X_train, init1)\n",
        "layer1 = expit(layer1)\n",
        "plt.hist(layer1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "n_xavier = 1/np.prod(X_train.shape)\n",
        "init1 = np.random.normal(loc=0, scale=n_xavier, size=(784, 256))\n",
        "layer1 = np.dot(X_train, init1)\n",
        "layer1 = np.where(layer1 > 0, layer1, 0)\n",
        "plt.hist(layer1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cifar10_dic = {\n",
        "\"airplane\" : 0\n",
        ",\"automobile\" : 1\n",
        ",\"bird\" : 2\n",
        ",\"cat\" : 3\n",
        ",\"deer\" : 4\n",
        ",\"dog\" : 5\n",
        ",\"frog\" : 6\n",
        ",\"horse\" : 7\n",
        ",\"ship\" : 8\n",
        ",\"truck\" : 9\n",
        "}\n",
        "\n",
        "cifar10_dic = {v:k for k,v in cifar10_dic.items()} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "(X_train, y_train),(X_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "output_shape = y_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=input_shape))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(output_shape, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.losses.CategoricalFocalCrossentropy at 0x1b78a1310d0>"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.losses import CategoricalFocalCrossentropy\n",
        "CategoricalFocalCrossentropy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.8825 - accuracy: 0.3166 - val_loss: 1.7404 - val_accuracy: 0.3688\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6944 - accuracy: 0.3903 - val_loss: 1.6318 - val_accuracy: 0.4190\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6061 - accuracy: 0.4253 - val_loss: 1.5401 - val_accuracy: 0.4537\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5501 - accuracy: 0.4435 - val_loss: 1.5906 - val_accuracy: 0.4305\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5095 - accuracy: 0.4576 - val_loss: 1.5386 - val_accuracy: 0.4506\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4865 - accuracy: 0.4663 - val_loss: 1.5516 - val_accuracy: 0.4567\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4586 - accuracy: 0.4758 - val_loss: 1.4729 - val_accuracy: 0.4803\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4311 - accuracy: 0.4866 - val_loss: 1.5035 - val_accuracy: 0.4755\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4076 - accuracy: 0.4938 - val_loss: 1.4581 - val_accuracy: 0.4827\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3901 - accuracy: 0.5012 - val_loss: 1.4568 - val_accuracy: 0.4864\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3680 - accuracy: 0.5107 - val_loss: 1.4364 - val_accuracy: 0.4924\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3518 - accuracy: 0.5132 - val_loss: 1.4769 - val_accuracy: 0.4733\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3381 - accuracy: 0.5205 - val_loss: 1.4547 - val_accuracy: 0.4854\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3195 - accuracy: 0.5261 - val_loss: 1.4360 - val_accuracy: 0.4967\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3103 - accuracy: 0.5316 - val_loss: 1.4523 - val_accuracy: 0.4911\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2990 - accuracy: 0.5309 - val_loss: 1.4190 - val_accuracy: 0.4978\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2824 - accuracy: 0.5406 - val_loss: 1.4377 - val_accuracy: 0.4939\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2708 - accuracy: 0.5442 - val_loss: 1.4362 - val_accuracy: 0.4988\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2608 - accuracy: 0.5468 - val_loss: 1.4354 - val_accuracy: 0.4948\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2533 - accuracy: 0.5492 - val_loss: 1.4491 - val_accuracy: 0.4934\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2405 - accuracy: 0.5554 - val_loss: 1.4552 - val_accuracy: 0.4935\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2336 - accuracy: 0.5574 - val_loss: 1.4215 - val_accuracy: 0.5022\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2262 - accuracy: 0.5584 - val_loss: 1.4133 - val_accuracy: 0.5050\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2126 - accuracy: 0.5646 - val_loss: 1.4554 - val_accuracy: 0.4953\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2053 - accuracy: 0.5675 - val_loss: 1.5115 - val_accuracy: 0.4861\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1988 - accuracy: 0.5701 - val_loss: 1.4448 - val_accuracy: 0.4981\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1873 - accuracy: 0.5747 - val_loss: 1.4616 - val_accuracy: 0.4950\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1828 - accuracy: 0.5762 - val_loss: 1.4798 - val_accuracy: 0.4962\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1754 - accuracy: 0.5771 - val_loss: 1.4778 - val_accuracy: 0.4943\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1678 - accuracy: 0.5794 - val_loss: 1.4755 - val_accuracy: 0.4989\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1595 - accuracy: 0.5836 - val_loss: 1.4733 - val_accuracy: 0.4935\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1491 - accuracy: 0.5858 - val_loss: 1.4876 - val_accuracy: 0.4981\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1482 - accuracy: 0.5885 - val_loss: 1.5122 - val_accuracy: 0.4935\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1371 - accuracy: 0.5916 - val_loss: 1.4610 - val_accuracy: 0.5042\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1341 - accuracy: 0.5927 - val_loss: 1.4858 - val_accuracy: 0.4991\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1270 - accuracy: 0.5952 - val_loss: 1.5053 - val_accuracy: 0.4856\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1171 - accuracy: 0.5997 - val_loss: 1.4982 - val_accuracy: 0.4979\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1177 - accuracy: 0.5969 - val_loss: 1.5213 - val_accuracy: 0.4863\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1103 - accuracy: 0.5992 - val_loss: 1.5170 - val_accuracy: 0.4897\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1059 - accuracy: 0.6004 - val_loss: 1.5147 - val_accuracy: 0.4991\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0973 - accuracy: 0.6062 - val_loss: 1.5273 - val_accuracy: 0.4958\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0976 - accuracy: 0.6051 - val_loss: 1.4986 - val_accuracy: 0.4998\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0894 - accuracy: 0.6073 - val_loss: 1.5337 - val_accuracy: 0.4935\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0845 - accuracy: 0.6083 - val_loss: 1.4968 - val_accuracy: 0.4991\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0786 - accuracy: 0.6130 - val_loss: 1.5296 - val_accuracy: 0.4991\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0758 - accuracy: 0.6110 - val_loss: 1.5371 - val_accuracy: 0.4963\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0666 - accuracy: 0.6150 - val_loss: 1.5917 - val_accuracy: 0.4853\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0678 - accuracy: 0.6182 - val_loss: 1.5717 - val_accuracy: 0.4839\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0604 - accuracy: 0.6182 - val_loss: 1.5758 - val_accuracy: 0.4944\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0570 - accuracy: 0.6193 - val_loss: 1.5661 - val_accuracy: 0.4904\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0496 - accuracy: 0.6205 - val_loss: 1.5778 - val_accuracy: 0.4882\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0502 - accuracy: 0.6198 - val_loss: 1.5874 - val_accuracy: 0.4912\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0410 - accuracy: 0.6263 - val_loss: 1.6345 - val_accuracy: 0.4883\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0404 - accuracy: 0.6236 - val_loss: 1.5933 - val_accuracy: 0.4869\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0328 - accuracy: 0.6262 - val_loss: 1.6521 - val_accuracy: 0.4883\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0312 - accuracy: 0.6282 - val_loss: 1.6120 - val_accuracy: 0.4918\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0250 - accuracy: 0.6284 - val_loss: 1.6376 - val_accuracy: 0.4911\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0228 - accuracy: 0.6305 - val_loss: 1.5844 - val_accuracy: 0.4903\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0185 - accuracy: 0.6339 - val_loss: 1.6142 - val_accuracy: 0.4889\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0136 - accuracy: 0.6346 - val_loss: 1.6569 - val_accuracy: 0.4909\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0129 - accuracy: 0.6355 - val_loss: 1.6123 - val_accuracy: 0.4950\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0075 - accuracy: 0.6347 - val_loss: 1.6675 - val_accuracy: 0.4934\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0122 - accuracy: 0.6321 - val_loss: 1.6314 - val_accuracy: 0.4840\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9977 - accuracy: 0.6402 - val_loss: 1.6202 - val_accuracy: 0.5019\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9983 - accuracy: 0.6400 - val_loss: 1.6338 - val_accuracy: 0.4871\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9937 - accuracy: 0.6409 - val_loss: 1.6634 - val_accuracy: 0.4969\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9960 - accuracy: 0.6393 - val_loss: 1.6566 - val_accuracy: 0.4868\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9868 - accuracy: 0.6444 - val_loss: 1.6670 - val_accuracy: 0.4814\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9848 - accuracy: 0.6442 - val_loss: 1.7495 - val_accuracy: 0.4786\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9843 - accuracy: 0.6453 - val_loss: 1.6657 - val_accuracy: 0.4960\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9812 - accuracy: 0.6458 - val_loss: 1.7209 - val_accuracy: 0.4880\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9764 - accuracy: 0.6470 - val_loss: 1.6675 - val_accuracy: 0.4908\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9714 - accuracy: 0.6485 - val_loss: 1.7083 - val_accuracy: 0.4832\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9729 - accuracy: 0.6483 - val_loss: 1.6965 - val_accuracy: 0.4840\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.9641 - accuracy: 0.6513 - val_loss: 1.6789 - val_accuracy: 0.4934\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.9669 - accuracy: 0.6521 - val_loss: 1.6885 - val_accuracy: 0.4927\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.9612 - accuracy: 0.6525 - val_loss: 1.7554 - val_accuracy: 0.4831\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.9595 - accuracy: 0.6541 - val_loss: 1.7857 - val_accuracy: 0.4770\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9528 - accuracy: 0.6557 - val_loss: 1.7014 - val_accuracy: 0.4930\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9553 - accuracy: 0.6548 - val_loss: 1.7352 - val_accuracy: 0.4826\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9515 - accuracy: 0.6582 - val_loss: 1.7602 - val_accuracy: 0.4823\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9474 - accuracy: 0.6579 - val_loss: 1.7533 - val_accuracy: 0.4912\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9433 - accuracy: 0.6586 - val_loss: 1.7234 - val_accuracy: 0.4884\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9446 - accuracy: 0.6590 - val_loss: 1.7675 - val_accuracy: 0.4797\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9444 - accuracy: 0.6588 - val_loss: 1.7637 - val_accuracy: 0.4901\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9399 - accuracy: 0.6590 - val_loss: 1.7786 - val_accuracy: 0.4849\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9374 - accuracy: 0.6630 - val_loss: 1.7753 - val_accuracy: 0.4943\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9293 - accuracy: 0.6651 - val_loss: 1.7527 - val_accuracy: 0.4892\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9324 - accuracy: 0.6615 - val_loss: 1.7201 - val_accuracy: 0.4986\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9246 - accuracy: 0.6661 - val_loss: 1.7969 - val_accuracy: 0.4901\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9312 - accuracy: 0.6640 - val_loss: 1.7661 - val_accuracy: 0.4883\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9264 - accuracy: 0.6658 - val_loss: 1.8028 - val_accuracy: 0.4885\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9213 - accuracy: 0.6659 - val_loss: 1.8118 - val_accuracy: 0.4878\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9158 - accuracy: 0.6690 - val_loss: 1.8279 - val_accuracy: 0.4881\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.9180 - accuracy: 0.6687 - val_loss: 1.7666 - val_accuracy: 0.4898\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9130 - accuracy: 0.6708 - val_loss: 1.8118 - val_accuracy: 0.4909\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9135 - accuracy: 0.6681 - val_loss: 1.8272 - val_accuracy: 0.4833\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9152 - accuracy: 0.6707 - val_loss: 1.7893 - val_accuracy: 0.4878\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9067 - accuracy: 0.6734 - val_loss: 1.8661 - val_accuracy: 0.4823\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9050 - accuracy: 0.6729 - val_loss: 1.8295 - val_accuracy: 0.4818\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1b7aa8b6990>"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cifar_predict(x):\n",
        "    x1 = x.reshape(-1, 32, 32, 3)\n",
        "    answer = cifar10.dic.get(np.argmax(model.predict(x1)))\n",
        "    print(f'예측값은 {answer} 입니다.')\n",
        "    plt.imshow(x)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 1.8295 - accuracy: 0.4818\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.8294757604599, 0.48179998993873596]"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=input_shape))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(output_shape, activation='softmax'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 11s 6ms/step - loss: 4.6038 - accuracy: 0.2479 - val_loss: 2.0252 - val_accuracy: 0.2542\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 4.6624 - accuracy: 0.2471 - val_loss: 2.0428 - val_accuracy: 0.2513\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 4.6324 - accuracy: 0.2475 - val_loss: 2.0200 - val_accuracy: 0.2590\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 4.6286 - accuracy: 0.2528 - val_loss: 1.9987 - val_accuracy: 0.2740\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 4.6609 - accuracy: 0.2526 - val_loss: 2.0270 - val_accuracy: 0.2568\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 4.6106 - accuracy: 0.2529 - val_loss: 2.1306 - val_accuracy: 0.2233\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 4.5898 - accuracy: 0.2553 - val_loss: 2.0215 - val_accuracy: 0.2640\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 4.5690 - accuracy: 0.2524 - val_loss: 2.0135 - val_accuracy: 0.2609\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 4.5896 - accuracy: 0.2534 - val_loss: 2.0569 - val_accuracy: 0.2477\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 4.6568 - accuracy: 0.2547 - val_loss: 2.0550 - val_accuracy: 0.2567\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1b7b99a05d0>"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 1.9492 - accuracy: 0.2792\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.9491890668869019, 0.2791999876499176]"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model, save_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8852\\1226879807.py:1: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  save_model(model=model, filepath='model/model.h5')\n"
          ]
        }
      ],
      "source": [
        "save_model(model=model, filepath='model/model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "cifar_model = load_model('model/model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
